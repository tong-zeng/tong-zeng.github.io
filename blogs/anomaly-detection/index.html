<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tong Zeng">
<meta name="dcterms.date" content="2023-11-30">
<meta name="description" content="Finding unusual rare cases different from the majority">

<title>Tong Zeng - Anomaly Detection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../news/second-news/index.html" rel="next">
<link href="../../blogs/welcome/index.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Tong Zeng</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../#news" rel="" target="">
 <span class="menu-text">News</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../#publications" rel="" target="">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../blogs.html" rel="" target="" aria-current="page">
 <span class="menu-text">Blogs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/tong-zeng/tong-zeng.github.io" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/zeng_tong" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:tongzeng@vt.edu" rel="" target=""><i class="bi bi-envelope" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../blogs/clustering/index.html">Blogs</a></li><li class="breadcrumb-item"><a href="../../blogs/anomaly-detection/index.html">Anomaly Detection</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Anomaly Detection</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          Finding unusual rare cases different from the majority
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Anomaly Detection</div>
                <div class="quarto-category">Unsupervised Learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Tong Zeng </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 30, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blogs</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Blogs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/clustering/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/regression/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear and Nonlinear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/classification/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/probability/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability Theory and Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/welcome/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome to Machine Learning Blog</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/anomaly-detection/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">News</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../news/second-news/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Index</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../news/first-news/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Index</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Publications</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../publications/bib2yml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bib2yml</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">Methods</a>
  <ul>
  <li><a href="#categorization-of-ad-algorithms" id="toc-categorization-of-ad-algorithms" class="nav-link" data-scroll-target="#categorization-of-ad-algorithms">Categorization of AD Algorithms</a></li>
  <li><a href="#typical-ad-algorithms" id="toc-typical-ad-algorithms" class="nav-link" data-scroll-target="#typical-ad-algorithms">Typical AD Algorithms</a>
  <ul class="collapse">
  <li><a href="#isolation-forest" id="toc-isolation-forest" class="nav-link" data-scroll-target="#isolation-forest">Isolation Forest</a></li>
  <li><a href="#local-outlier-factor" id="toc-local-outlier-factor" class="nav-link" data-scroll-target="#local-outlier-factor">Local Outlier Factor</a></li>
  </ul></li>
  <li><a href="#evaluation-metrics" id="toc-evaluation-metrics" class="nav-link" data-scroll-target="#evaluation-metrics">Evaluation Metrics</a></li>
  </ul></li>
  <li><a href="#dataset" id="toc-dataset" class="nav-link" data-scroll-target="#dataset">Dataset</a>
  <ul>
  <li><a href="#load-the-data" id="toc-load-the-data" class="nav-link" data-scroll-target="#load-the-data">Load the Data</a></li>
  <li><a href="#descriptive-statistics" id="toc-descriptive-statistics" class="nav-link" data-scroll-target="#descriptive-statistics">Descriptive Statistics</a></li>
  <li><a href="#data-distribution" id="toc-data-distribution" class="nav-link" data-scroll-target="#data-distribution">Data Distribution</a></li>
  <li><a href="#d-visualization" id="toc-d-visualization" class="nav-link" data-scroll-target="#d-visualization">3D Visualization</a></li>
  </ul></li>
  <li><a href="#experiments" id="toc-experiments" class="nav-link" data-scroll-target="#experiments">Experiments</a>
  <ul>
  <li><a href="#preprocessing" id="toc-preprocessing" class="nav-link" data-scroll-target="#preprocessing">Preprocessing</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">Training</a></li>
  <li><a href="#performance-evaluation" id="toc-performance-evaluation" class="nav-link" data-scroll-target="#performance-evaluation">Performance Evaluation</a></li>
  </ul></li>
  <li><a href="#discussion-and-conclusion" id="toc-discussion-and-conclusion" class="nav-link" data-scroll-target="#discussion-and-conclusion">Discussion and Conclusion</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/tong-zeng/tong-zeng.github.io/blob/main/blogs/anomaly-detection/index.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<div class="column-screen">
<img src="img/anomaly.jpg" class="content-header-full-img img-fluid">
<p style="text-align:right; font-size:0.66em">
Image source: https://www.freepik.com
</p>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Anomaly detection (AD), also known as outlier detection, refers to the process of identifying patterns, events, or observations in a given dataset that deviate significantly from the norm or expected behavior. In other words, it involves finding instances that are unusual, rare, or different from the majority of the data. These instances are often referred to as anomalies, outliers, or novelties.</p>
<p>The primary goal of anomaly detection is to distinguish normal patterns from abnormal ones, which can have various applications in different domains. By identifying anomalies, one can uncover potential issues, errors, fraud, or unusual events that may require further investigation or action.</p>
<p>This concept has various applications in real world acorss different domains. For example:</p>
<ol type="1">
<li><p>Network Security: Anomaly detection is applied to network traffic to identify abnormal patterns that may suggest a cyber attack or unauthorized access. Unusual spikes in data transfer or irregular access patterns could be indicative of security breaches.</p></li>
<li><p>Healthcare Monitoring: In healthcare, anomaly detection can be employed to identify unusual patterns in patient data, such as vital signs or laboratory results. This can help in early detection of diseases or abnormalities.</p></li>
<li><p>Fraud Detection in Finance: Anomaly detection is commonly used in the financial sector to identify unusual patterns in transactions that may indicate fraudulent activities, such as credit card fraud or insider trading.</p>
<p>…<br>
</p></li>
</ol>
<div id="fig-applications" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/applications.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Illustration of Anomaly Detection Applications</figcaption>
</figure>
</div>
<p>Anomaly detection is a crucial aspect of data analysis in many fields, helping to improve security, reduce fraud, enhance system reliability, and provide early warnings for potential issues.</p>
</section>
<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods">Methods</h2>
<section id="categorization-of-ad-algorithms" class="level3">
<h3 class="anchored" data-anchor-id="categorization-of-ad-algorithms">Categorization of AD Algorithms</h3>
<p>Considering the significant importance of anomaly detection, lots of efforts has been made to improve the performance of anomaly detection. Several techniques could be employed for anomaly detection, and the choice of method often depends on the characterizations of dataset and the specific requirements of the application. Here are some common techniques that could be utilized for anomaly detection:</p>
<p><strong>Rule-Based Methods</strong>: These methods rely on the domain-specific rules that are generated from domain experts’ knowledge to define explicit rules or conditions to identify anomalies. In many domains, experts can define rules based on their understanding of the system or process. These rules may take the form of if-then statements that describe conditions under which a data point is considered anomalous. For example: If a financial transaction is significantly larger than typical transactions, consider it suspicious.</p>
<p><strong>Statistical Methods</strong>: These methods can be boardly categorized into absolute socre-based methods and relative score-based methods. - Absolute score-based methods: In absolute score-based methods, the anomaly score is calculated based on the absolute value of a statistical measure. For example, in Z-Score, the distance of a data point from the mean is expressed in terms of standard deviations. High absolute Z-scores indicate points far from the mean, and these are considered anomalies. - Relative score-based methods: In relative score-based methods, the anomaly score is interpreted relative to the distribution of the data. Instead of using fixed absolute thresholds, percentage-based thresholds may be employed. For example, identifying the top 1% or 5% of data points as anomalies.</p>
<div id="fig-statistical-methods" class="quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 100.0%;justify-content: center;">
<div id="fig-Detecting-Outliers-with-z-Scores" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/zscore.png" class="img-fluid figure-img" data-ref-parent="fig-statistical-methods"></p>
<figcaption class="figure-caption">(a) Detecting Outliers with z-Scores</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 100.0%;justify-content: center;">
<div id="fig-Detecting-Outliers-with-IQR" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/quartile.png" class="img-fluid figure-img" data-ref-parent="fig-statistical-methods"></p>
<figcaption class="figure-caption">(b) Detecting Outliers with IQR</figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: Statistical Methods for Outliers Detection. source: <a href="topics/data-science/handling-outliers-in-data-science/">https://www.scaler.com/</a></figcaption><p></p>
</figure>
</div>
<p><strong>Clustering Methods</strong>: Clustering methods involve grouping data points into clusters based on their similarity and then identifying anomalies as data points that do not conform to these clusters. Commonly used methods such as DBSCAN, K-Means etc. - DBSCAN is a density-based clustering algorithm that groups together data points that are close to each other and have a sufficient number of neighbors. Points that do not belong to any cluster or are in sparser regions of the data are considered anomalies (noise). - K-Means partitions the dataset into a predetermined number of clusters (k) based on the mean of data points in each cluster. Data points that do not fit well into any cluster or are far from the cluster centers may be considered anomalies.</p>
<p><strong>Machine Learning Methods</strong>: Machine learning-based methods for anomaly detection involve training models to learn patterns in normal data and then identifying instances that deviate significantly from these learned patterns. For example, Isolation Forest is an ensemble method that works by isolating anomalies in a dataset. It does this by randomly selecting a feature and then creating a split between the minimum and maximum values of that feature. Anomalies are expected to be isolated with fewer splits.</p>
<p><strong>Deep Learning Methods</strong>: Deep learning-based methods for anomaly detection leverage neural networks, particularly deep architectures, to model complex patterns and representations in data. For example, Autoencoders are neural networks trained to encode input data into a compressed representation and then decode it back to the original form. Anomalies are identified by measuring the difference between the input and the reconstructed output. Instances with high reconstruction errors are considered anomalies.</p>
<p>Experts often recommend considering the nature of the data and the specific goals of anomaly detection when choosing between these categories. There is no one-size-fits-all approach, and the choice may depend on factors such as the data distribution, the presence of outliers, and the desired trade-off between false positives and false negatives. Additionally, combining multiple methods or using hybrid approaches is common for improved robustness and accuracy in real-world applications.</p>
</section>
<section id="typical-ad-algorithms" class="level3">
<h3 class="anchored" data-anchor-id="typical-ad-algorithms">Typical AD Algorithms</h3>
<p>As mentioned above, there are many anomaly detection algorithms available. In this post, we will choose two algorithms that are used more in sklearn for our anomaly detection experiments. They are described as follows:</p>
<section id="isolation-forest" class="level4">
<h4 class="anchored" data-anchor-id="isolation-forest">Isolation Forest</h4>
<p>The Isolation Forest algorithm is an unsupervised method for detecting anomalies by leveraging the characteristics of anomalies, specifically their scarcity and distinctiveness. Since anomalies are both infrequent and different from the majority of data points, they are more prone to isolation. This algorithm individually isolates each data point and categorizes them as outliers or inliers based on the time it takes to separate them. The separation process is influenced by the number of points within the proximity of a given point. If an attempt is made to isolate a point that is clearly not an outlier, it will likely be surrounded by many points, making isolation challenging. Conversely, if the point is indeed an outlier, it will be isolated easily as it tends to be solitary in the dataset. An illustration of the algorithm is listed below:</p>
<div id="fig-if" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/if.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Illustration of Isolation Forest Method. source: <a href="https://doi.org/10.3390/rs12101678" class="uri">https://doi.org/10.3390/rs12101678</a></figcaption>
</figure>
</div>
</section>
<section id="local-outlier-factor" class="level4">
<h4 class="anchored" data-anchor-id="local-outlier-factor">Local Outlier Factor</h4>
<p>The Local Outlier Factor (LOF) algorithm is an unsupervised approach for identifying anomalies by assessing the local density variation of a specific data point in relation to its neighboring points. This computation involves examining the density of a point’s neighbors and contrasting it with the density of subsequent neighboring points. In essence, LOF identifies outliers by detecting instances where the density surrounding an object significantly differs from the density around its neighboring points. LOF labels samples as outliers if they exhibit notably lower density compared to their neighboring points.</p>
</section>
</section>
<section id="evaluation-metrics" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-metrics">Evaluation Metrics</h3>
<p>Anomaly detection can essentially be viewed as a binary classification task that distinguishes data points into two categories: normal and outliers. Therefore, common evaluation metrics in classification tasks can also be used for anomaly detection.</p>
<p>In this post, we will use the precision, recall and <span class="math inline">F_1</span> are as indicators for model performance evaluation.</p>
<p>According to wikipedia, the definition of these metrics as following :</p>
<p>Precision is the fraction of relevant instances among the retrieved instances. Written as a formula:</p>
<p><span class="math display">
{\displaystyle {\text{Precision}}={\frac {\text{Relevant retrieved instances}}{\text{All retrieved instances}}}}
</span></p>
<p>Recall is the fraction of relevant instances that were retrieved. Written as a formula:</p>
<p><span class="math display">
{\displaystyle {\text{Recall}}={\frac {\text{Relevant retrieved instances}}{\text{All relevant instances}}}}
</span></p>
<p><span class="math inline">F_1</span> score is the harmonic mean of the precision and recall. Written as a formula:</p>
<p><span class="math display">
{\displaystyle F_{1}={\frac {2}{\mathrm {recall} ^{-1}+\mathrm {precision} ^{-1}}}=2{\frac {\mathrm {precision} \cdot \mathrm {recall} }{\mathrm {precision} +\mathrm {recall} }}={\frac {2\mathrm {tp} }{2\mathrm {tp} +\mathrm {fp} +\mathrm {fn} }}}
</span></p>
<p>where <span class="math inline">tp</span> is the true positives, <span class="math inline">fp</span> is the false positive, and <span class="math inline">fn</span> is the false negative.</p>
</section>
</section>
<section id="dataset" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="dataset">Dataset</h2>
<p>In this section, we will load the libraries, analysis the dataset and get insights from the data distribution through data visualization. The procedures are listed below:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="load-the-data" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="load-the-data">Load the Data</h3>
<div class="cell page-columns page-full" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>nRowsRead <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/creditcard_10k.csv'</span>, delimiter<span class="op">=</span><span class="st">','</span>, nrows <span class="op">=</span> nRowsRead)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display column-page" data-execution_count="2">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Time</th>
<th data-quarto-table-cell-role="th">V1</th>
<th data-quarto-table-cell-role="th">V2</th>
<th data-quarto-table-cell-role="th">V3</th>
<th data-quarto-table-cell-role="th">V4</th>
<th data-quarto-table-cell-role="th">V5</th>
<th data-quarto-table-cell-role="th">V6</th>
<th data-quarto-table-cell-role="th">V7</th>
<th data-quarto-table-cell-role="th">V8</th>
<th data-quarto-table-cell-role="th">V9</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">V21</th>
<th data-quarto-table-cell-role="th">V22</th>
<th data-quarto-table-cell-role="th">V23</th>
<th data-quarto-table-cell-role="th">V24</th>
<th data-quarto-table-cell-role="th">V25</th>
<th data-quarto-table-cell-role="th">V26</th>
<th data-quarto-table-cell-role="th">V27</th>
<th data-quarto-table-cell-role="th">V28</th>
<th data-quarto-table-cell-role="th">Amount</th>
<th data-quarto-table-cell-role="th">Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>-1.359807</td>
<td>-0.072781</td>
<td>2.536347</td>
<td>1.378155</td>
<td>-0.338321</td>
<td>0.462388</td>
<td>0.239599</td>
<td>0.098698</td>
<td>0.363787</td>
<td>...</td>
<td>-0.018307</td>
<td>0.277838</td>
<td>-0.110474</td>
<td>0.066928</td>
<td>0.128539</td>
<td>-0.189115</td>
<td>0.133558</td>
<td>-0.021053</td>
<td>149.62</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0</td>
<td>1.191857</td>
<td>0.266151</td>
<td>0.166480</td>
<td>0.448154</td>
<td>0.060018</td>
<td>-0.082361</td>
<td>-0.078803</td>
<td>0.085102</td>
<td>-0.255425</td>
<td>...</td>
<td>-0.225775</td>
<td>-0.638672</td>
<td>0.101288</td>
<td>-0.339846</td>
<td>0.167170</td>
<td>0.125895</td>
<td>-0.008983</td>
<td>0.014724</td>
<td>2.69</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>-1.358354</td>
<td>-1.340163</td>
<td>1.773209</td>
<td>0.379780</td>
<td>-0.503198</td>
<td>1.800499</td>
<td>0.791461</td>
<td>0.247676</td>
<td>-1.514654</td>
<td>...</td>
<td>0.247998</td>
<td>0.771679</td>
<td>0.909412</td>
<td>-0.689281</td>
<td>-0.327642</td>
<td>-0.139097</td>
<td>-0.055353</td>
<td>-0.059752</td>
<td>378.66</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>-0.966272</td>
<td>-0.185226</td>
<td>1.792993</td>
<td>-0.863291</td>
<td>-0.010309</td>
<td>1.247203</td>
<td>0.237609</td>
<td>0.377436</td>
<td>-1.387024</td>
<td>...</td>
<td>-0.108300</td>
<td>0.005274</td>
<td>-0.190321</td>
<td>-1.175575</td>
<td>0.647376</td>
<td>-0.221929</td>
<td>0.062723</td>
<td>0.061458</td>
<td>123.50</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2</td>
<td>-1.158233</td>
<td>0.877737</td>
<td>1.548718</td>
<td>0.403034</td>
<td>-0.407193</td>
<td>0.095921</td>
<td>0.592941</td>
<td>-0.270533</td>
<td>0.817739</td>
<td>...</td>
<td>-0.009431</td>
<td>0.798278</td>
<td>-0.137458</td>
<td>0.141267</td>
<td>-0.206010</td>
<td>0.502292</td>
<td>0.219422</td>
<td>0.215153</td>
<td>69.99</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">995</td>
<td>751</td>
<td>-0.654892</td>
<td>0.608319</td>
<td>1.585102</td>
<td>-3.009429</td>
<td>0.037593</td>
<td>-1.954023</td>
<td>1.335977</td>
<td>-0.612858</td>
<td>0.690254</td>
<td>...</td>
<td>-0.078527</td>
<td>-0.064194</td>
<td>-0.107350</td>
<td>0.961776</td>
<td>-0.067760</td>
<td>-0.549465</td>
<td>-0.232588</td>
<td>-0.108261</td>
<td>3.90</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">996</td>
<td>752</td>
<td>-2.101171</td>
<td>-0.227365</td>
<td>1.624668</td>
<td>-0.291123</td>
<td>1.902446</td>
<td>-1.483921</td>
<td>-0.275117</td>
<td>0.085964</td>
<td>-0.563098</td>
<td>...</td>
<td>-0.313782</td>
<td>-0.804784</td>
<td>-0.474101</td>
<td>0.008102</td>
<td>0.259725</td>
<td>0.032376</td>
<td>0.323580</td>
<td>0.034622</td>
<td>1.78</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">997</td>
<td>753</td>
<td>-1.248163</td>
<td>0.315246</td>
<td>3.708935</td>
<td>0.687280</td>
<td>-0.873071</td>
<td>1.091287</td>
<td>0.297707</td>
<td>-0.633135</td>
<td>1.102317</td>
<td>...</td>
<td>-0.824013</td>
<td>0.057907</td>
<td>-0.282351</td>
<td>0.630774</td>
<td>0.283506</td>
<td>-0.204264</td>
<td>0.097555</td>
<td>-0.670480</td>
<td>30.00</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">998</td>
<td>755</td>
<td>1.374134</td>
<td>-1.767210</td>
<td>-0.433352</td>
<td>-2.229552</td>
<td>0.331135</td>
<td>3.924775</td>
<td>-2.049947</td>
<td>1.001403</td>
<td>-1.183310</td>
<td>...</td>
<td>-0.252942</td>
<td>-0.461534</td>
<td>-0.030890</td>
<td>0.997119</td>
<td>0.384299</td>
<td>-0.187538</td>
<td>0.068817</td>
<td>0.038009</td>
<td>82.37</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">999</td>
<td>755</td>
<td>-2.497436</td>
<td>1.402769</td>
<td>0.184840</td>
<td>-2.504117</td>
<td>-0.111803</td>
<td>-0.902909</td>
<td>0.110183</td>
<td>-3.655788</td>
<td>2.231761</td>
<td>...</td>
<td>2.777155</td>
<td>-0.664909</td>
<td>0.594689</td>
<td>0.330380</td>
<td>0.064190</td>
<td>-0.110533</td>
<td>0.672165</td>
<td>0.114739</td>
<td>8.00</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>1000 rows × 31 columns</p>
</div>
</div>
</div>
</section>
<section id="descriptive-statistics" class="level3">
<h3 class="anchored" data-anchor-id="descriptive-statistics">Descriptive Statistics</h3>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'No Frauds'</span>, <span class="bu">round</span>(df[<span class="st">'Class'</span>].value_counts()[<span class="dv">0</span>]<span class="op">/</span><span class="bu">len</span>(df) <span class="op">*</span> <span class="dv">100</span>,<span class="dv">2</span>), <span class="st">'</span><span class="sc">% o</span><span class="st">f the dataset'</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Frauds'</span>, <span class="bu">round</span>(df[<span class="st">'Class'</span>].value_counts()[<span class="dv">1</span>]<span class="op">/</span><span class="bu">len</span>(df) <span class="op">*</span> <span class="dv">100</span>,<span class="dv">2</span>), <span class="st">'</span><span class="sc">% o</span><span class="st">f the dataset'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>No Frauds 99.8 % of the dataset
Frauds 0.2 % of the dataset</code></pre>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>fraud <span class="op">=</span> <span class="bu">len</span>(df[df[<span class="st">'Class'</span>] <span class="op">==</span> <span class="dv">1</span>]) <span class="op">/</span> <span class="bu">len</span>(df) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>nofraud <span class="op">=</span> <span class="bu">len</span>(df[df[<span class="st">'Class'</span>] <span class="op">==</span> <span class="dv">0</span>]) <span class="op">/</span> <span class="bu">len</span>(df) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>fraud_percentage <span class="op">=</span> [nofraud, fraud]</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>plt.pie(fraud_percentage,labels <span class="op">=</span> [<span class="st">'Fraud'</span>,<span class="st">'No Fraud'</span>], autopct<span class="op">=</span><span class="st">'</span><span class="sc">%1.1f%%</span><span class="st">'</span>, colors<span class="op">=</span>[<span class="st">'deepskyblue'</span>, <span class="st">'tomato'</span>])</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>fig.patch.set_facecolor(<span class="st">'white'</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>fig.patch.set_alpha(<span class="dv">0</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Number of Fraud Cases'</span>)<span class="op">;</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/cell-5-output-1.png" width="441" height="409" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="data-distribution" class="level3">
<h3 class="anchored" data-anchor-id="data-distribution">Data Distribution</h3>
<p>As we can see from the outputs above, the dataset is highly unbalanced, the frauds data points only accounts for 0.2% which makes the anomaly detection challenge compare to most supervised learning.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'default'</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>sns.pairplot(df[[<span class="st">"Amount"</span>, <span class="st">"Time"</span>]], aspect<span class="op">=</span><span class="fl">1.5</span>, height<span class="op">=</span><span class="fl">2.6</span>, kind<span class="op">=</span><span class="st">"scatter"</span>, diag_kind<span class="op">=</span><span class="st">"hist"</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">'font'</span>, <span class="op">**</span>{<span class="st">'size'</span>: <span class="dv">13</span>})</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The <code>Amount</code> are highly skewed, but the data points are almost equally distributed over the time. We then examine the relationship between the variables by plotting the correlation heatmap as below:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'default'</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>df_corr <span class="op">=</span> df.corr()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">8.8</span>,<span class="dv">7</span>))</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>sns.heatmap(df_corr, cmap<span class="op">=</span><span class="st">"YlGnBu"</span>) </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(font_scale<span class="op">=</span><span class="dv">2</span>,style<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">'font'</span>, <span class="op">**</span>{<span class="st">'size'</span>: <span class="dv">13</span>})</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Heatmap correlation'</span>, fontsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="d-visualization" class="level3">
<h3 class="anchored" data-anchor-id="d-visualization">3D Visualization</h3>
<p>In order to get a better understanding of the dataset, we can use PCA to transform the data into 3 dimensions and mark the outliers in the 3D space.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>num_df <span class="op">=</span> df.columns[<span class="dv">0</span>:<span class="dv">30</span>]</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>outliers <span class="op">=</span> df.loc[df[<span class="st">'Class'</span>]<span class="op">==</span><span class="dv">1</span>]</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>outlier_index<span class="op">=</span><span class="bu">list</span>(outliers.index)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> scaler.fit_transform(df[num_df])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>pca_model <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca_model.fit_transform(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fig-cap-location-top" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'default'</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>))</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>ax.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>], zs<span class="op">=</span>X_pca[:, <span class="dv">2</span>], s<span class="op">=</span><span class="dv">3</span>, lw<span class="op">=</span><span class="dv">1</span>, label<span class="op">=</span><span class="st">"inliers"</span>,c<span class="op">=</span><span class="st">"deepskyblue"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>ax.scatter(X_pca[outlier_index,<span class="dv">0</span>],X_pca[outlier_index,<span class="dv">1</span>], X_pca[outlier_index,<span class="dv">2</span>], s<span class="op">=</span><span class="dv">60</span>, lw<span class="op">=</span><span class="dv">2</span>, marker<span class="op">=</span><span class="st">"*"</span>, c<span class="op">=</span><span class="st">"tomato"</span>, label<span class="op">=</span><span class="st">"outliers"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="dv">2</span>, prop<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">8</span>})</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>ax.zaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-3d" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-3d-output-1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Visualization of Outliers in 3D Space</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="experiments" class="level2">
<h2 class="anchored" data-anchor-id="experiments">Experiments</h2>
<section id="preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="preprocessing">Preprocessing</h3>
<p>We first load the libraries, and prepare the data for modeling.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report,accuracy_score, confusion_matrix</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> IsolationForest</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> LocalOutlierFactor</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> OneClassSVM</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/creditcard_10k.csv'</span>, delimiter<span class="op">=</span><span class="st">','</span>, nrows <span class="op">=</span> <span class="dv">10000</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> df.columns.tolist()</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> columns <span class="cf">if</span> c <span class="kw">not</span> <span class="kw">in</span> [<span class="st">"Class"</span>]]</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">"Class"</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>state <span class="op">=</span> np.random.RandomState(<span class="dv">666</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[columns]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> df[target]</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.shape)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Y.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(9999, 30)
(9999,)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>Fraud <span class="op">=</span> df[df[<span class="st">'Class'</span>]<span class="op">==</span><span class="dv">1</span>]</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>Valid <span class="op">=</span> df[df[<span class="st">'Class'</span>]<span class="op">==</span><span class="dv">0</span>]</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>outlier_ratio <span class="op">=</span> <span class="bu">len</span>(Fraud)<span class="op">/</span><span class="bu">float</span>(<span class="bu">len</span>(Valid))</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Fraud: </span><span class="sc">{</span><span class="bu">len</span>(Fraud)<span class="sc">}</span><span class="ss">, Valid: </span><span class="sc">{</span><span class="bu">len</span>(Valid)<span class="sc">}</span><span class="ss">, ratio:</span><span class="sc">{</span>outlier_ratio<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fraud: 38, Valid: 9961, ratio:0.0038148780242947497</code></pre>
</div>
</div>
</section>
<section id="training" class="level3">
<h3 class="anchored" data-anchor-id="training">Training</h3>
<p>We can now define the models. We are going to use <code>OneClassSVM</code> as the baseline, and focus on <code>IsolationForest</code> and <code>LocalOutlierFactor</code> for anomaly detection.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>classifiers <span class="op">=</span> {</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Isolation Forest"</span>: IsolationForest(</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>        max_samples<span class="op">=</span><span class="bu">len</span>(X),</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>        contamination<span class="op">=</span>outlier_ratio,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">666</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>        verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Local Outlier Factor"</span>: LocalOutlierFactor(</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>        n_neighbors<span class="op">=</span><span class="dv">50</span>, </span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>        algorithm<span class="op">=</span><span class="st">'auto'</span>, </span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        leaf_size<span class="op">=</span><span class="dv">50</span>, metric<span class="op">=</span><span class="st">'minkowski'</span>,</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>        p<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>        metric_params<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        contamination<span class="op">=</span>outlier_ratio</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Support Vector Machine"</span>: OneClassSVM(</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>        kernel<span class="op">=</span><span class="st">'rbf'</span>, </span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        degree<span class="op">=</span><span class="dv">5</span>, </span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>        gamma<span class="op">=</span><span class="fl">0.1</span>,nu<span class="op">=</span><span class="fl">0.05</span>,</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>        max_iter<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Training begins …</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit_predict(classifier_name):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    n_outliers <span class="op">=</span> <span class="bu">len</span>(Fraud)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    classifier <span class="op">=</span> classifiers[classifier_name]</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> classifier_name <span class="op">==</span> <span class="st">"Local Outlier Factor"</span>:</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> classifier.fit_predict(X)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        scores_prediction <span class="op">=</span> classifier.negative_outlier_factor_</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> classifier_name <span class="op">==</span> <span class="st">"Support Vector Machine"</span>:</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        classifier.fit(X)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> classifier.predict(X)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:    </span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        classifier.fit(X)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        scores_prediction <span class="op">=</span> classifier.decision_function(X)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> classifier.predict(X)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 0 for Valid, 1 for Fraud</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    y_pred[y_pred <span class="op">==</span> <span class="dv">1</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    y_pred[y_pred <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    n_errors <span class="op">=</span> (y_pred <span class="op">!=</span> Y).<span class="bu">sum</span>()</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>classifier_name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>n_errors<span class="sc">}</span><span class="ss"> prediction errors"</span>)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>y_pred_if <span class="op">=</span> fit_predict(<span class="st">"Isolation Forest"</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>y_pred_lof <span class="op">=</span> fit_predict(<span class="st">"Local Outlier Factor"</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>y_pred_svm <span class="op">=</span> fit_predict(<span class="st">"Support Vector Machine"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Isolation Forest: 51 prediction errors
Local Outlier Factor: 75 prediction errors
Support Vector Machine: 5529 prediction errors</code></pre>
</div>
</div>
<p>Training completed! At first glance, SVM performs very bad, it has 5528 prediction errors which means the accuracy is less than 50%. The <code>Isolation Forest</code> and <code>Local Outlier Factor</code> are looks good, with accuracy more than 99%. However, the accuracy is not enough for assessment, because in some application, it is very costly to miss any outlier but it can tolerance to classify a normal data point as outlier. However, in other cases it might be very expensive to treat a normal data point as outlier, but wouldn’t be a big problem to miss a outlier.</p>
</section>
<section id="performance-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="performance-evaluation">Performance Evaluation</h3>
<p>In this section, we will evaluate the model performance with the precision, recall and <span class="math inline">F_1</span> score, as long as a visualization of the confusion matrix.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate(y_pred):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print("Accuracy Score:")</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(accuracy_score(Y,y_pred))</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print("Classification Report:")</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(classification_report(Y,y_pred))</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_confusion_matrix(y_pred):</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    plt.style.use(<span class="st">'default'</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(Y,y_pred)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="fl">1.1</span>,<span class="fl">1.1</span>))</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> disp.plot(ax<span class="op">=</span>ax)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>evaluate(y_pred_lof)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> display_confusion_matrix(y_pred_lof)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00      9961
           1       0.03      0.03      0.03        38

    accuracy                           0.99      9999
   macro avg       0.51      0.51      0.51      9999
weighted avg       0.99      0.99      0.99      9999
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/cell-17-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>evaluate(y_pred_if)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> display_confusion_matrix(y_pred_if)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00      9961
           1       0.33      0.34      0.34        38

    accuracy                           0.99      9999
   macro avg       0.67      0.67      0.67      9999
weighted avg       0.99      0.99      0.99      9999
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/cell-18-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="cell tbl-column-body" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>evaluate(y_pred_svm)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> display_confusion_matrix(y_pred_svm)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       1.00      0.45      0.62      9961
           1       0.00      0.42      0.01        38

    accuracy                           0.45      9999
   macro avg       0.50      0.43      0.31      9999
weighted avg       0.99      0.45      0.61      9999
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/cell-19-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>In our dataset, there are 38 frauds in total. From the performance report and confusion matrix, we can infer that: <code>local outlier factor</code> only detects 1 fraud data point, while <code>isolation forest</code> predicts 12 frauds successfully. In this sense, <code>isolation forest</code> has much better performance.</p>
</section>
</section>
<section id="discussion-and-conclusion" class="level2">
<h2 class="anchored" data-anchor-id="discussion-and-conclusion">Discussion and Conclusion</h2>
<p>In this post, we introduced the anomaly detection and its application across different domains, then we discussed the categorization of AD Algorithms, followed by a detailed explaination of <code>isolation forest</code> and <code>local outlier factor</code>. After some exploratory data analysis and data preprocessing, we trained machine learning models to detect the outliers. Our performance evaluation shows that <code>isolation forest</code> has the best performance.</p>
<p>As expected, the <code>OneClassSVM</code> doesn’t perform well for outlier detection, as it is very sensitive to outliers. This algorithm is best suited for applications where the training set is not contaminated by outliers.</p>
<p>The <code>isolation forest</code> and <code>local outlier factor</code> are much better than <code>OneClassSVM</code>, and performs reasonably well. However, the <code>isolation forest</code> has slightly better performance and it also runs faster than <code>local outlier factor</code> in our experiments.</p>
<p>In summary, when choosing between <code>isolation forest</code> and Local <code>local outlier factor</code>, you should consider the nature of your data, the types of outliers you expect, and the computational resources available. It’s often beneficial to experiment with both algorithms on your specific dataset and assess their performance using appropriate evaluation metrics. Ensemble approaches that combine the strengths of both methods may also be considered for more robust outlier detection.</p>


<!-- -->

</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../blogs/welcome/index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Welcome to Machine Learning Blog</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../news/second-news/index.html" class="pagination-link">
        <span class="nav-page-text">Index</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb26" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Anomaly Detection"</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Tong Zeng"</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-11-30"</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Anomaly Detection, Unsupervised Learning]</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "img/anomaly.jpg"</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> Finding unusual rare cases different from the majority</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>::: column-screen</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="al">![](img/anomaly.jpg)</span>{.content-header-full-img}</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;p</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-align:right; font-size:0.66em"</span><span class="kw">&gt;</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>Image source: https://www.freepik.com</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/p&gt;</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>Anomaly detection (AD), also known as outlier detection, refers to the process of identifying patterns, events, or observations in a given dataset that deviate significantly from the norm or expected behavior. In other words, it involves finding instances that are unusual, rare, or different from the majority of the data. These instances are often referred to as anomalies, outliers, or novelties.</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>The primary goal of anomaly detection is to distinguish normal patterns from abnormal ones, which can have various applications in different domains. By identifying anomalies, one can uncover potential issues, errors, fraud, or unusual events that may require further investigation or action.</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>This concept has various applications in real world acorss different domains. For example:</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Network Security: Anomaly detection is applied to network traffic to identify abnormal patterns that may suggest a cyber attack or unauthorized access. Unusual spikes in data transfer or irregular access patterns could be indicative of security breaches.</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Healthcare Monitoring: In healthcare, anomaly detection can be employed to identify unusual patterns in patient data, such as vital signs or laboratory results. This can help in early detection of diseases or abnormalities.</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Fraud Detection in Finance: Anomaly detection is commonly used in the financial sector to identify unusual patterns in transactions that may indicate fraudulent activities, such as credit card fraud or insider trading.</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>    ...\</span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a><span class="al">![Illustration of Anomaly Detection Applications](img/applications.png)</span>{#fig-applications fig-align="center"}</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>Anomaly detection is a crucial aspect of data analysis in many fields, helping to improve security, reduce fraud, enhance system reliability, and provide early warnings for potential issues.</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a><span class="fu">## Methods</span></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a><span class="fu">### Categorization of AD Algorithms</span></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>Considering the significant importance of anomaly detection, lots of efforts has been made to improve the performance of anomaly detection. Several techniques could be employed for anomaly detection, and the choice of method often depends on the characterizations of dataset and the specific requirements of the application. Here are some common techniques that could be utilized for anomaly detection:</span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a>**Rule-Based Methods**: These methods rely on the domain-specific rules that are generated from domain experts' knowledge to define explicit rules or conditions to identify anomalies. In many domains, experts can define rules based on their understanding of the system or process. These rules may take the form of if-then statements that describe conditions under which a data point is considered anomalous. For example: If a financial transaction is significantly larger than typical transactions, consider it suspicious.</span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a>**Statistical Methods**: These methods can be boardly categorized into absolute socre-based methods and relative score-based methods. - Absolute score-based methods: In absolute score-based methods, the anomaly score is calculated based on the absolute value of a statistical measure. For example, in Z-Score, the distance of a data point from the mean is expressed in terms of standard deviations. High absolute Z-scores indicate points far from the mean, and these are considered anomalies. - Relative score-based methods: In relative score-based methods, the anomaly score is interpreted relative to the distribution of the data. Instead of using fixed absolute thresholds, percentage-based thresholds may be employed. For example, identifying the top 1% or 5% of data points as anomalies.</span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a>::: {#fig-statistical-methods layout-ncol="1"}</span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a><span class="al">![Detecting Outliers with z-Scores](img/zscore.png)</span>{#fig-Detecting-Outliers-with-z-Scores}</span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a><span class="al">![Detecting Outliers with IQR](img/quartile.png)</span>{#fig-Detecting-Outliers-with-IQR}</span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a>Statistical Methods for Outliers Detection. source: <span class="co">[</span><span class="ot">https://www.scaler.com/</span><span class="co">](topics/data-science/handling-outliers-in-data-science/)</span></span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a>**Clustering Methods**: Clustering methods involve grouping data points into clusters based on their similarity and then identifying anomalies as data points that do not conform to these clusters. Commonly used methods such as DBSCAN, K-Means etc. - DBSCAN is a density-based clustering algorithm that groups together data points that are close to each other and have a sufficient number of neighbors. Points that do not belong to any cluster or are in sparser regions of the data are considered anomalies (noise). - K-Means partitions the dataset into a predetermined number of clusters (k) based on the mean of data points in each cluster. Data points that do not fit well into any cluster or are far from the cluster centers may be considered anomalies.</span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a>**Machine Learning Methods**: Machine learning-based methods for anomaly detection involve training models to learn patterns in normal data and then identifying instances that deviate significantly from these learned patterns. For example, Isolation Forest is an ensemble method that works by isolating anomalies in a dataset. It does this by randomly selecting a feature and then creating a split between the minimum and maximum values of that feature. Anomalies are expected to be isolated with fewer splits.</span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a>**Deep Learning Methods**: Deep learning-based methods for anomaly detection leverage neural networks, particularly deep architectures, to model complex patterns and representations in data. For example, Autoencoders are neural networks trained to encode input data into a compressed representation and then decode it back to the original form. Anomalies are identified by measuring the difference between the input and the reconstructed output. Instances with high reconstruction errors are considered anomalies.</span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a>Experts often recommend considering the nature of the data and the specific goals of anomaly detection when choosing between these categories. There is no one-size-fits-all approach, and the choice may depend on factors such as the data distribution, the presence of outliers, and the desired trade-off between false positives and false negatives. Additionally, combining multiple methods or using hybrid approaches is common for improved robustness and accuracy in real-world applications.</span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a><span class="fu">### Typical AD Algorithms</span></span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a>As mentioned above, there are many anomaly detection algorithms available. In this post, we will choose two algorithms that are used more in sklearn for our anomaly detection experiments. They are described as follows:</span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Isolation Forest</span></span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a>The Isolation Forest algorithm is an unsupervised method for detecting anomalies by leveraging the characteristics of anomalies, specifically their scarcity and distinctiveness. Since anomalies are both infrequent and different from the majority of data points, they are more prone to isolation. This algorithm individually isolates each data point and categorizes them as outliers or inliers based on the time it takes to separate them. The separation process is influenced by the number of points within the proximity of a given point. If an attempt is made to isolate a point that is clearly not an outlier, it will likely be surrounded by many points, making isolation challenging. Conversely, if the point is indeed an outlier, it will be isolated easily as it tends to be solitary in the dataset. An illustration of the algorithm is listed below:</span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a><span class="al">![Illustration of Isolation Forest Method. source: &lt;https://doi.org/10.3390/rs12101678&gt;](img/if.png)</span>{#fig-if fig-align="center"}</span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Local Outlier Factor</span></span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a>The Local Outlier Factor (LOF) algorithm is an unsupervised approach for identifying anomalies by assessing the local density variation of a specific data point in relation to its neighboring points. This computation involves examining the density of a point's neighbors and contrasting it with the density of subsequent neighboring points. In essence, LOF identifies outliers by detecting instances where the density surrounding an object significantly differs from the density around its neighboring points. LOF labels samples as outliers if they exhibit notably lower density compared to their neighboring points.</span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a><span class="fu">### Evaluation Metrics</span></span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a>Anomaly detection can essentially be viewed as a binary classification task that distinguishes data points into two categories: normal and outliers. Therefore, common evaluation metrics in classification tasks can also be used for anomaly detection.</span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a>In this post, we will use the precision, recall and $F_1$ are as indicators for model performance evaluation.</span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a>According to wikipedia, the definition of these metrics as following :</span>
<span id="cb26-84"><a href="#cb26-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-85"><a href="#cb26-85" aria-hidden="true" tabindex="-1"></a>Precision is the fraction of relevant instances among the retrieved instances. Written as a formula:</span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-88"><a href="#cb26-88" aria-hidden="true" tabindex="-1"></a>{\displaystyle {\text{Precision}}={\frac {\text{Relevant retrieved instances}}{\text{All retrieved instances}}}}</span>
<span id="cb26-89"><a href="#cb26-89" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a>Recall is the fraction of relevant instances that were retrieved. Written as a formula:</span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-93"><a href="#cb26-93" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-94"><a href="#cb26-94" aria-hidden="true" tabindex="-1"></a>{\displaystyle {\text{Recall}}={\frac {\text{Relevant retrieved instances}}{\text{All relevant instances}}}}</span>
<span id="cb26-95"><a href="#cb26-95" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-96"><a href="#cb26-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-97"><a href="#cb26-97" aria-hidden="true" tabindex="-1"></a>$F_1$ score is the harmonic mean of the precision and recall. Written as a formula:</span>
<span id="cb26-98"><a href="#cb26-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-99"><a href="#cb26-99" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-100"><a href="#cb26-100" aria-hidden="true" tabindex="-1"></a>{\displaystyle F_{1}={\frac {2}{\mathrm {recall} ^{-1}+\mathrm {precision} ^{-1}}}=2{\frac {\mathrm {precision} \cdot \mathrm {recall} }{\mathrm {precision} +\mathrm {recall} }}={\frac {2\mathrm {tp} }{2\mathrm {tp} +\mathrm {fp} +\mathrm {fn} }}}</span>
<span id="cb26-101"><a href="#cb26-101" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-102"><a href="#cb26-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-103"><a href="#cb26-103" aria-hidden="true" tabindex="-1"></a>where $tp$ is the true positives, $fp$ is the false positive, and $fn$ is the false negative.</span>
<span id="cb26-104"><a href="#cb26-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-105"><a href="#cb26-105" aria-hidden="true" tabindex="-1"></a><span class="fu">## Dataset</span></span>
<span id="cb26-106"><a href="#cb26-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-107"><a href="#cb26-107" aria-hidden="true" tabindex="-1"></a>In this section, we will load the libraries, analysis the dataset and get insights from the data distribution through data visualization. The procedures are listed below:</span>
<span id="cb26-108"><a href="#cb26-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-111"><a href="#cb26-111" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-112"><a href="#cb26-112" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb26-113"><a href="#cb26-113" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb26-114"><a href="#cb26-114" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-115"><a href="#cb26-115" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb26-116"><a href="#cb26-116" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb26-117"><a href="#cb26-117" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-118"><a href="#cb26-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-119"><a href="#cb26-119" aria-hidden="true" tabindex="-1"></a><span class="fu">### Load the Data</span></span>
<span id="cb26-120"><a href="#cb26-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-123"><a href="#cb26-123" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-124"><a href="#cb26-124" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-column: page</span></span>
<span id="cb26-125"><a href="#cb26-125" aria-hidden="true" tabindex="-1"></a>nRowsRead <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb26-126"><a href="#cb26-126" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/creditcard_10k.csv'</span>, delimiter<span class="op">=</span><span class="st">','</span>, nrows <span class="op">=</span> nRowsRead)</span>
<span id="cb26-127"><a href="#cb26-127" aria-hidden="true" tabindex="-1"></a>df</span>
<span id="cb26-128"><a href="#cb26-128" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-129"><a href="#cb26-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-130"><a href="#cb26-130" aria-hidden="true" tabindex="-1"></a><span class="fu">### Descriptive Statistics</span></span>
<span id="cb26-131"><a href="#cb26-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-134"><a href="#cb26-134" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-135"><a href="#cb26-135" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'No Frauds'</span>, <span class="bu">round</span>(df[<span class="st">'Class'</span>].value_counts()[<span class="dv">0</span>]<span class="op">/</span><span class="bu">len</span>(df) <span class="op">*</span> <span class="dv">100</span>,<span class="dv">2</span>), <span class="st">'</span><span class="sc">% o</span><span class="st">f the dataset'</span>)</span>
<span id="cb26-136"><a href="#cb26-136" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Frauds'</span>, <span class="bu">round</span>(df[<span class="st">'Class'</span>].value_counts()[<span class="dv">1</span>]<span class="op">/</span><span class="bu">len</span>(df) <span class="op">*</span> <span class="dv">100</span>,<span class="dv">2</span>), <span class="st">'</span><span class="sc">% o</span><span class="st">f the dataset'</span>)</span>
<span id="cb26-137"><a href="#cb26-137" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-138"><a href="#cb26-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-141"><a href="#cb26-141" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-142"><a href="#cb26-142" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb26-143"><a href="#cb26-143" aria-hidden="true" tabindex="-1"></a>fraud <span class="op">=</span> <span class="bu">len</span>(df[df[<span class="st">'Class'</span>] <span class="op">==</span> <span class="dv">1</span>]) <span class="op">/</span> <span class="bu">len</span>(df) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb26-144"><a href="#cb26-144" aria-hidden="true" tabindex="-1"></a>nofraud <span class="op">=</span> <span class="bu">len</span>(df[df[<span class="st">'Class'</span>] <span class="op">==</span> <span class="dv">0</span>]) <span class="op">/</span> <span class="bu">len</span>(df) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb26-145"><a href="#cb26-145" aria-hidden="true" tabindex="-1"></a>fraud_percentage <span class="op">=</span> [nofraud, fraud]</span>
<span id="cb26-146"><a href="#cb26-146" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb26-147"><a href="#cb26-147" aria-hidden="true" tabindex="-1"></a>plt.pie(fraud_percentage,labels <span class="op">=</span> [<span class="st">'Fraud'</span>,<span class="st">'No Fraud'</span>], autopct<span class="op">=</span><span class="st">'</span><span class="sc">%1.1f%%</span><span class="st">'</span>, colors<span class="op">=</span>[<span class="st">'deepskyblue'</span>, <span class="st">'tomato'</span>])</span>
<span id="cb26-148"><a href="#cb26-148" aria-hidden="true" tabindex="-1"></a>fig.patch.set_facecolor(<span class="st">'white'</span>)</span>
<span id="cb26-149"><a href="#cb26-149" aria-hidden="true" tabindex="-1"></a>fig.patch.set_alpha(<span class="dv">0</span>)</span>
<span id="cb26-150"><a href="#cb26-150" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Number of Fraud Cases'</span>)<span class="op">;</span></span>
<span id="cb26-151"><a href="#cb26-151" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-152"><a href="#cb26-152" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-153"><a href="#cb26-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-154"><a href="#cb26-154" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Distribution</span></span>
<span id="cb26-155"><a href="#cb26-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-156"><a href="#cb26-156" aria-hidden="true" tabindex="-1"></a>As we can see from the outputs above, the dataset is highly unbalanced, the frauds data points only accounts for 0.2% which makes the anomaly detection challenge compare to most supervised learning.</span>
<span id="cb26-157"><a href="#cb26-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-160"><a href="#cb26-160" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-161"><a href="#cb26-161" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'default'</span>)</span>
<span id="cb26-162"><a href="#cb26-162" aria-hidden="true" tabindex="-1"></a>sns.pairplot(df[[<span class="st">"Amount"</span>, <span class="st">"Time"</span>]], aspect<span class="op">=</span><span class="fl">1.5</span>, height<span class="op">=</span><span class="fl">2.6</span>, kind<span class="op">=</span><span class="st">"scatter"</span>, diag_kind<span class="op">=</span><span class="st">"hist"</span>)</span>
<span id="cb26-163"><a href="#cb26-163" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">'font'</span>, <span class="op">**</span>{<span class="st">'size'</span>: <span class="dv">13</span>})</span>
<span id="cb26-164"><a href="#cb26-164" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-165"><a href="#cb26-165" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-166"><a href="#cb26-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-167"><a href="#cb26-167" aria-hidden="true" tabindex="-1"></a>The <span class="in">`Amount`</span> are highly skewed, but the data points are almost equally distributed over the time. We then examine the relationship between the variables by plotting the correlation heatmap as below:</span>
<span id="cb26-168"><a href="#cb26-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-171"><a href="#cb26-171" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-172"><a href="#cb26-172" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb26-173"><a href="#cb26-173" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'default'</span>)</span>
<span id="cb26-174"><a href="#cb26-174" aria-hidden="true" tabindex="-1"></a>df_corr <span class="op">=</span> df.corr()</span>
<span id="cb26-175"><a href="#cb26-175" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">8.8</span>,<span class="dv">7</span>))</span>
<span id="cb26-176"><a href="#cb26-176" aria-hidden="true" tabindex="-1"></a>sns.heatmap(df_corr, cmap<span class="op">=</span><span class="st">"YlGnBu"</span>) </span>
<span id="cb26-177"><a href="#cb26-177" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(font_scale<span class="op">=</span><span class="dv">2</span>,style<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb26-178"><a href="#cb26-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-179"><a href="#cb26-179" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">'font'</span>, <span class="op">**</span>{<span class="st">'size'</span>: <span class="dv">13</span>})</span>
<span id="cb26-180"><a href="#cb26-180" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Heatmap correlation'</span>, fontsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb26-181"><a href="#cb26-181" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-182"><a href="#cb26-182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-183"><a href="#cb26-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-184"><a href="#cb26-184" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3D Visualization</span></span>
<span id="cb26-185"><a href="#cb26-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-186"><a href="#cb26-186" aria-hidden="true" tabindex="-1"></a>In order to get a better understanding of the dataset, we can use PCA to transform the data into 3 dimensions and mark the outliers in the 3D space.</span>
<span id="cb26-187"><a href="#cb26-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-190"><a href="#cb26-190" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-191"><a href="#cb26-191" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb26-192"><a href="#cb26-192" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb26-193"><a href="#cb26-193" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb26-194"><a href="#cb26-194" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb26-195"><a href="#cb26-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-196"><a href="#cb26-196" aria-hidden="true" tabindex="-1"></a>num_df <span class="op">=</span> df.columns[<span class="dv">0</span>:<span class="dv">30</span>]</span>
<span id="cb26-197"><a href="#cb26-197" aria-hidden="true" tabindex="-1"></a>outliers <span class="op">=</span> df.loc[df[<span class="st">'Class'</span>]<span class="op">==</span><span class="dv">1</span>]</span>
<span id="cb26-198"><a href="#cb26-198" aria-hidden="true" tabindex="-1"></a>outlier_index<span class="op">=</span><span class="bu">list</span>(outliers.index)</span>
<span id="cb26-199"><a href="#cb26-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-200"><a href="#cb26-200" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb26-201"><a href="#cb26-201" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> scaler.fit_transform(df[num_df])</span>
<span id="cb26-202"><a href="#cb26-202" aria-hidden="true" tabindex="-1"></a>pca_model <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb26-203"><a href="#cb26-203" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca_model.fit_transform(X)</span>
<span id="cb26-204"><a href="#cb26-204" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-205"><a href="#cb26-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-208"><a href="#cb26-208" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-209"><a href="#cb26-209" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-3d</span></span>
<span id="cb26-210"><a href="#cb26-210" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap-location: top</span></span>
<span id="cb26-211"><a href="#cb26-211" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Visualization of Outliers in 3D Space</span></span>
<span id="cb26-212"><a href="#cb26-212" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'default'</span>)</span>
<span id="cb26-213"><a href="#cb26-213" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>))</span>
<span id="cb26-214"><a href="#cb26-214" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb26-215"><a href="#cb26-215" aria-hidden="true" tabindex="-1"></a>ax.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>], zs<span class="op">=</span>X_pca[:, <span class="dv">2</span>], s<span class="op">=</span><span class="dv">3</span>, lw<span class="op">=</span><span class="dv">1</span>, label<span class="op">=</span><span class="st">"inliers"</span>,c<span class="op">=</span><span class="st">"deepskyblue"</span>)</span>
<span id="cb26-216"><a href="#cb26-216" aria-hidden="true" tabindex="-1"></a>ax.scatter(X_pca[outlier_index,<span class="dv">0</span>],X_pca[outlier_index,<span class="dv">1</span>], X_pca[outlier_index,<span class="dv">2</span>], s<span class="op">=</span><span class="dv">60</span>, lw<span class="op">=</span><span class="dv">2</span>, marker<span class="op">=</span><span class="st">"*"</span>, c<span class="op">=</span><span class="st">"tomato"</span>, label<span class="op">=</span><span class="st">"outliers"</span>)</span>
<span id="cb26-217"><a href="#cb26-217" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="dv">2</span>, prop<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">8</span>})</span>
<span id="cb26-218"><a href="#cb26-218" aria-hidden="true" tabindex="-1"></a>ax.zaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb26-219"><a href="#cb26-219" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb26-220"><a href="#cb26-220" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb26-221"><a href="#cb26-221" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-222"><a href="#cb26-222" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-223"><a href="#cb26-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-224"><a href="#cb26-224" aria-hidden="true" tabindex="-1"></a><span class="fu">## Experiments</span></span>
<span id="cb26-225"><a href="#cb26-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-226"><a href="#cb26-226" aria-hidden="true" tabindex="-1"></a><span class="fu">### Preprocessing</span></span>
<span id="cb26-227"><a href="#cb26-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-228"><a href="#cb26-228" aria-hidden="true" tabindex="-1"></a>We first load the libraries, and prepare the data for modeling.</span>
<span id="cb26-229"><a href="#cb26-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-232"><a href="#cb26-232" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-233"><a href="#cb26-233" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report,accuracy_score, confusion_matrix</span>
<span id="cb26-234"><a href="#cb26-234" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> IsolationForest</span>
<span id="cb26-235"><a href="#cb26-235" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> LocalOutlierFactor</span>
<span id="cb26-236"><a href="#cb26-236" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> OneClassSVM</span>
<span id="cb26-237"><a href="#cb26-237" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb26-238"><a href="#cb26-238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-239"><a href="#cb26-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-242"><a href="#cb26-242" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-243"><a href="#cb26-243" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/creditcard_10k.csv'</span>, delimiter<span class="op">=</span><span class="st">','</span>, nrows <span class="op">=</span> <span class="dv">10000</span>)</span>
<span id="cb26-244"><a href="#cb26-244" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> df.columns.tolist()</span>
<span id="cb26-245"><a href="#cb26-245" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> columns <span class="cf">if</span> c <span class="kw">not</span> <span class="kw">in</span> [<span class="st">"Class"</span>]]</span>
<span id="cb26-246"><a href="#cb26-246" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">"Class"</span></span>
<span id="cb26-247"><a href="#cb26-247" aria-hidden="true" tabindex="-1"></a>state <span class="op">=</span> np.random.RandomState(<span class="dv">666</span>)</span>
<span id="cb26-248"><a href="#cb26-248" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[columns]</span>
<span id="cb26-249"><a href="#cb26-249" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> df[target]</span>
<span id="cb26-250"><a href="#cb26-250" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.shape)</span>
<span id="cb26-251"><a href="#cb26-251" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Y.shape)</span>
<span id="cb26-252"><a href="#cb26-252" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-253"><a href="#cb26-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-256"><a href="#cb26-256" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-257"><a href="#cb26-257" aria-hidden="true" tabindex="-1"></a>Fraud <span class="op">=</span> df[df[<span class="st">'Class'</span>]<span class="op">==</span><span class="dv">1</span>]</span>
<span id="cb26-258"><a href="#cb26-258" aria-hidden="true" tabindex="-1"></a>Valid <span class="op">=</span> df[df[<span class="st">'Class'</span>]<span class="op">==</span><span class="dv">0</span>]</span>
<span id="cb26-259"><a href="#cb26-259" aria-hidden="true" tabindex="-1"></a>outlier_ratio <span class="op">=</span> <span class="bu">len</span>(Fraud)<span class="op">/</span><span class="bu">float</span>(<span class="bu">len</span>(Valid))</span>
<span id="cb26-260"><a href="#cb26-260" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Fraud: </span><span class="sc">{</span><span class="bu">len</span>(Fraud)<span class="sc">}</span><span class="ss">, Valid: </span><span class="sc">{</span><span class="bu">len</span>(Valid)<span class="sc">}</span><span class="ss">, ratio:</span><span class="sc">{</span>outlier_ratio<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-261"><a href="#cb26-261" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-262"><a href="#cb26-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-263"><a href="#cb26-263" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training</span></span>
<span id="cb26-264"><a href="#cb26-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-265"><a href="#cb26-265" aria-hidden="true" tabindex="-1"></a>We can now define the models. We are going to use <span class="in">`OneClassSVM`</span> as the baseline, and focus on <span class="in">`IsolationForest`</span> and <span class="in">`LocalOutlierFactor`</span> for anomaly detection.</span>
<span id="cb26-266"><a href="#cb26-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-269"><a href="#cb26-269" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-270"><a href="#cb26-270" aria-hidden="true" tabindex="-1"></a>classifiers <span class="op">=</span> {</span>
<span id="cb26-271"><a href="#cb26-271" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Isolation Forest"</span>: IsolationForest(</span>
<span id="cb26-272"><a href="#cb26-272" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb26-273"><a href="#cb26-273" aria-hidden="true" tabindex="-1"></a>        max_samples<span class="op">=</span><span class="bu">len</span>(X),</span>
<span id="cb26-274"><a href="#cb26-274" aria-hidden="true" tabindex="-1"></a>        contamination<span class="op">=</span>outlier_ratio,</span>
<span id="cb26-275"><a href="#cb26-275" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">666</span>,</span>
<span id="cb26-276"><a href="#cb26-276" aria-hidden="true" tabindex="-1"></a>        verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb26-277"><a href="#cb26-277" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb26-278"><a href="#cb26-278" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Local Outlier Factor"</span>: LocalOutlierFactor(</span>
<span id="cb26-279"><a href="#cb26-279" aria-hidden="true" tabindex="-1"></a>        n_neighbors<span class="op">=</span><span class="dv">50</span>, </span>
<span id="cb26-280"><a href="#cb26-280" aria-hidden="true" tabindex="-1"></a>        algorithm<span class="op">=</span><span class="st">'auto'</span>, </span>
<span id="cb26-281"><a href="#cb26-281" aria-hidden="true" tabindex="-1"></a>        leaf_size<span class="op">=</span><span class="dv">50</span>, metric<span class="op">=</span><span class="st">'minkowski'</span>,</span>
<span id="cb26-282"><a href="#cb26-282" aria-hidden="true" tabindex="-1"></a>        p<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb26-283"><a href="#cb26-283" aria-hidden="true" tabindex="-1"></a>        metric_params<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb26-284"><a href="#cb26-284" aria-hidden="true" tabindex="-1"></a>        contamination<span class="op">=</span>outlier_ratio</span>
<span id="cb26-285"><a href="#cb26-285" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb26-286"><a href="#cb26-286" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Support Vector Machine"</span>: OneClassSVM(</span>
<span id="cb26-287"><a href="#cb26-287" aria-hidden="true" tabindex="-1"></a>        kernel<span class="op">=</span><span class="st">'rbf'</span>, </span>
<span id="cb26-288"><a href="#cb26-288" aria-hidden="true" tabindex="-1"></a>        degree<span class="op">=</span><span class="dv">5</span>, </span>
<span id="cb26-289"><a href="#cb26-289" aria-hidden="true" tabindex="-1"></a>        gamma<span class="op">=</span><span class="fl">0.1</span>,nu<span class="op">=</span><span class="fl">0.05</span>,</span>
<span id="cb26-290"><a href="#cb26-290" aria-hidden="true" tabindex="-1"></a>        max_iter<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb26-291"><a href="#cb26-291" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-292"><a href="#cb26-292" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-293"><a href="#cb26-293" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-294"><a href="#cb26-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-295"><a href="#cb26-295" aria-hidden="true" tabindex="-1"></a>Training begins ...</span>
<span id="cb26-296"><a href="#cb26-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-299"><a href="#cb26-299" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-300"><a href="#cb26-300" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit_predict(classifier_name):</span>
<span id="cb26-301"><a href="#cb26-301" aria-hidden="true" tabindex="-1"></a>    n_outliers <span class="op">=</span> <span class="bu">len</span>(Fraud)</span>
<span id="cb26-302"><a href="#cb26-302" aria-hidden="true" tabindex="-1"></a>    classifier <span class="op">=</span> classifiers[classifier_name]</span>
<span id="cb26-303"><a href="#cb26-303" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> classifier_name <span class="op">==</span> <span class="st">"Local Outlier Factor"</span>:</span>
<span id="cb26-304"><a href="#cb26-304" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> classifier.fit_predict(X)</span>
<span id="cb26-305"><a href="#cb26-305" aria-hidden="true" tabindex="-1"></a>        scores_prediction <span class="op">=</span> classifier.negative_outlier_factor_</span>
<span id="cb26-306"><a href="#cb26-306" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> classifier_name <span class="op">==</span> <span class="st">"Support Vector Machine"</span>:</span>
<span id="cb26-307"><a href="#cb26-307" aria-hidden="true" tabindex="-1"></a>        classifier.fit(X)</span>
<span id="cb26-308"><a href="#cb26-308" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> classifier.predict(X)</span>
<span id="cb26-309"><a href="#cb26-309" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:    </span>
<span id="cb26-310"><a href="#cb26-310" aria-hidden="true" tabindex="-1"></a>        classifier.fit(X)</span>
<span id="cb26-311"><a href="#cb26-311" aria-hidden="true" tabindex="-1"></a>        scores_prediction <span class="op">=</span> classifier.decision_function(X)</span>
<span id="cb26-312"><a href="#cb26-312" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> classifier.predict(X)</span>
<span id="cb26-313"><a href="#cb26-313" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 0 for Valid, 1 for Fraud</span></span>
<span id="cb26-314"><a href="#cb26-314" aria-hidden="true" tabindex="-1"></a>    y_pred[y_pred <span class="op">==</span> <span class="dv">1</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb26-315"><a href="#cb26-315" aria-hidden="true" tabindex="-1"></a>    y_pred[y_pred <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb26-316"><a href="#cb26-316" aria-hidden="true" tabindex="-1"></a>    n_errors <span class="op">=</span> (y_pred <span class="op">!=</span> Y).<span class="bu">sum</span>()</span>
<span id="cb26-317"><a href="#cb26-317" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>classifier_name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>n_errors<span class="sc">}</span><span class="ss"> prediction errors"</span>)</span>
<span id="cb26-318"><a href="#cb26-318" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y_pred</span>
<span id="cb26-319"><a href="#cb26-319" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-320"><a href="#cb26-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-323"><a href="#cb26-323" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-324"><a href="#cb26-324" aria-hidden="true" tabindex="-1"></a>y_pred_if <span class="op">=</span> fit_predict(<span class="st">"Isolation Forest"</span>)</span>
<span id="cb26-325"><a href="#cb26-325" aria-hidden="true" tabindex="-1"></a>y_pred_lof <span class="op">=</span> fit_predict(<span class="st">"Local Outlier Factor"</span>)</span>
<span id="cb26-326"><a href="#cb26-326" aria-hidden="true" tabindex="-1"></a>y_pred_svm <span class="op">=</span> fit_predict(<span class="st">"Support Vector Machine"</span>)</span>
<span id="cb26-327"><a href="#cb26-327" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-328"><a href="#cb26-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-329"><a href="#cb26-329" aria-hidden="true" tabindex="-1"></a>Training completed! At first glance, SVM performs very bad, it has 5528 prediction errors which means the accuracy is less than 50%. The <span class="in">`Isolation Forest`</span> and <span class="in">`Local Outlier Factor`</span> are looks good, with accuracy more than 99%. However, the accuracy is not enough for assessment, because in some application, it is very costly to miss any outlier but it can tolerance to classify a normal data point as outlier. However, in other cases it might be very expensive to treat a normal data point as outlier, but wouldn't be a big problem to miss a outlier.</span>
<span id="cb26-330"><a href="#cb26-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-331"><a href="#cb26-331" aria-hidden="true" tabindex="-1"></a><span class="fu">### Performance Evaluation</span></span>
<span id="cb26-332"><a href="#cb26-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-333"><a href="#cb26-333" aria-hidden="true" tabindex="-1"></a>In this section, we will evaluate the model performance with the precision, recall and $F_1$ score, as long as a visualization of the confusion matrix.</span>
<span id="cb26-334"><a href="#cb26-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-337"><a href="#cb26-337" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-338"><a href="#cb26-338" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate(y_pred):</span>
<span id="cb26-339"><a href="#cb26-339" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print("Accuracy Score:")</span></span>
<span id="cb26-340"><a href="#cb26-340" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(accuracy_score(Y,y_pred))</span></span>
<span id="cb26-341"><a href="#cb26-341" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print("Classification Report:")</span></span>
<span id="cb26-342"><a href="#cb26-342" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(classification_report(Y,y_pred))</span>
<span id="cb26-343"><a href="#cb26-343" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-344"><a href="#cb26-344" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_confusion_matrix(y_pred):</span>
<span id="cb26-345"><a href="#cb26-345" aria-hidden="true" tabindex="-1"></a>    plt.style.use(<span class="st">'default'</span>)</span>
<span id="cb26-346"><a href="#cb26-346" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(Y,y_pred)</span>
<span id="cb26-347"><a href="#cb26-347" aria-hidden="true" tabindex="-1"></a>    disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm)</span>
<span id="cb26-348"><a href="#cb26-348" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="fl">1.1</span>,<span class="fl">1.1</span>))</span>
<span id="cb26-349"><a href="#cb26-349" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> disp.plot(ax<span class="op">=</span>ax)</span>
<span id="cb26-350"><a href="#cb26-350" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-351"><a href="#cb26-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-354"><a href="#cb26-354" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-355"><a href="#cb26-355" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb26-356"><a href="#cb26-356" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb26-357"><a href="#cb26-357" aria-hidden="true" tabindex="-1"></a>evaluate(y_pred_lof)</span>
<span id="cb26-358"><a href="#cb26-358" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> display_confusion_matrix(y_pred_lof)</span>
<span id="cb26-359"><a href="#cb26-359" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-360"><a href="#cb26-360" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-361"><a href="#cb26-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-364"><a href="#cb26-364" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-365"><a href="#cb26-365" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb26-366"><a href="#cb26-366" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb26-367"><a href="#cb26-367" aria-hidden="true" tabindex="-1"></a>evaluate(y_pred_if)</span>
<span id="cb26-368"><a href="#cb26-368" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> display_confusion_matrix(y_pred_if)</span>
<span id="cb26-369"><a href="#cb26-369" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-370"><a href="#cb26-370" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-371"><a href="#cb26-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-374"><a href="#cb26-374" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-375"><a href="#cb26-375" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb26-376"><a href="#cb26-376" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb26-377"><a href="#cb26-377" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-column: body</span></span>
<span id="cb26-378"><a href="#cb26-378" aria-hidden="true" tabindex="-1"></a>evaluate(y_pred_svm)</span>
<span id="cb26-379"><a href="#cb26-379" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> display_confusion_matrix(y_pred_svm)</span>
<span id="cb26-380"><a href="#cb26-380" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-381"><a href="#cb26-381" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-382"><a href="#cb26-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-383"><a href="#cb26-383" aria-hidden="true" tabindex="-1"></a>In our dataset, there are 38 frauds in total. From the performance report and confusion matrix, we can infer that: <span class="in">`local outlier factor`</span> only detects 1 fraud data point, while <span class="in">`isolation forest`</span> predicts 12 frauds successfully. In this sense, <span class="in">`isolation forest`</span> has much better performance.</span>
<span id="cb26-384"><a href="#cb26-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-385"><a href="#cb26-385" aria-hidden="true" tabindex="-1"></a><span class="fu">## Discussion and Conclusion</span></span>
<span id="cb26-386"><a href="#cb26-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-387"><a href="#cb26-387" aria-hidden="true" tabindex="-1"></a>In this post, we introduced the anomaly detection and its application across different domains, then we discussed the categorization of AD Algorithms, followed by a detailed explaination of <span class="in">`isolation forest`</span> and <span class="in">`local outlier factor`</span>. After some exploratory data analysis and data preprocessing, we trained machine learning models to detect the outliers. Our performance evaluation shows that <span class="in">`isolation forest`</span> has the best performance.</span>
<span id="cb26-388"><a href="#cb26-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-389"><a href="#cb26-389" aria-hidden="true" tabindex="-1"></a>As expected, the <span class="in">`OneClassSVM`</span> doesn't perform well for outlier detection, as it is very sensitive to outliers. This algorithm is best suited for applications where the training set is not contaminated by outliers.</span>
<span id="cb26-390"><a href="#cb26-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-391"><a href="#cb26-391" aria-hidden="true" tabindex="-1"></a>The <span class="in">`isolation forest`</span> and <span class="in">`local outlier factor`</span> are much better than <span class="in">`OneClassSVM`</span>, and performs reasonably well. However, the <span class="in">`isolation forest`</span> has slightly better performance and it also runs faster than <span class="in">`local outlier factor`</span> in our experiments.</span>
<span id="cb26-392"><a href="#cb26-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-393"><a href="#cb26-393" aria-hidden="true" tabindex="-1"></a>In summary, when choosing between <span class="in">`isolation forest`</span> and Local <span class="in">`local outlier factor`</span>, you should consider the nature of your data, the types of outliers you expect, and the computational resources available. It's often beneficial to experiment with both algorithms on your specific dataset and assess their performance using appropriate evaluation metrics. Ensemble approaches that combine the strengths of both methods may also be considered for more robust outlier detection.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">Copyright 2023, Tong Zeng</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>