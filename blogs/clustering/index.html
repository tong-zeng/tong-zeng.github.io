<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tong Zeng">
<meta name="dcterms.date" content="2023-11-26">
<meta name="description" content="Application of clustering for customer segmentation">

<title>Tong Zeng - Clustering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../blogs/regression/index.html" rel="next">
<link href="../../blogs.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script type="text/javascript">
window.PlotlyConfig = {MathJaxConfig: 'local'};
if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
if (typeof require !== 'undefined') {
require.undef("plotly");
requirejs.config({
    paths: {
        'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']
    }
});
require(['plotly'], function(Plotly) {
    window._Plotly = Plotly;
});
}
</script>


  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Tong Zeng</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../#news" rel="" target="">
 <span class="menu-text">News</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../#publications" rel="" target="">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../blogs.html" rel="" target="" aria-current="page">
 <span class="menu-text">Blogs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/tong-zeng/tong-zeng.github.io" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/zeng_tong" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:tongzeng@vt.edu" rel="" target=""><i class="bi bi-envelope" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../blogs/clustering/index.html">Blogs</a></li><li class="breadcrumb-item"><a href="../../blogs/clustering/index.html">Clustering</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Clustering</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          Application of clustering for customer segmentation
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Clustering</div>
                <div class="quarto-category">Unsupervised Learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Tong Zeng </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 26, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blogs</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Blogs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/clustering/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/regression/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear and Nonlinear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/classification/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/probability/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability Theory and Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/welcome/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome to Machine Learning Blog</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/anomaly-detection/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">News</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../news/second-news/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Index</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../news/first-news/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Index</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Publications</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../publications/bib2yml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bib2yml</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul>
  <li><a href="#unsupervised-learning" id="toc-unsupervised-learning" class="nav-link" data-scroll-target="#unsupervised-learning"><strong>Unsupervised Learning</strong></a></li>
  </ul></li>
  <li><a href="#clustering-in-machine-learning" id="toc-clustering-in-machine-learning" class="nav-link" data-scroll-target="#clustering-in-machine-learning">Clustering in Machine Learning</a></li>
  <li><a href="#clustering-algorithms" id="toc-clustering-algorithms" class="nav-link" data-scroll-target="#clustering-algorithms">Clustering Algorithms</a>
  <ul>
  <li><a href="#applications-in-customer-segmentation" id="toc-applications-in-customer-segmentation" class="nav-link" data-scroll-target="#applications-in-customer-segmentation">Applications in <strong>Customer Segmentation</strong></a></li>
  </ul></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">Methods</a>
  <ul>
  <li><a href="#k-means" id="toc-k-means" class="nav-link" data-scroll-target="#k-means">K-Means</a></li>
  <li><a href="#dbscan" id="toc-dbscan" class="nav-link" data-scroll-target="#dbscan">DBSCAN</a></li>
  </ul></li>
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">Data</a>
  <ul>
  <li><a href="#exploratory-data-analysis" id="toc-exploratory-data-analysis" class="nav-link" data-scroll-target="#exploratory-data-analysis">Exploratory Data Analysis</a>
  <ul class="collapse">
  <li><a href="#descriptive-statistics" id="toc-descriptive-statistics" class="nav-link" data-scroll-target="#descriptive-statistics">Descriptive Statistics</a></li>
  <li><a href="#data-visualization" id="toc-data-visualization" class="nav-link" data-scroll-target="#data-visualization">Data Visualization</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#experiments" id="toc-experiments" class="nav-link" data-scroll-target="#experiments">Experiments</a></li>
  <li><a href="#discussion-and-conclusion" id="toc-discussion-and-conclusion" class="nav-link" data-scroll-target="#discussion-and-conclusion">Discussion and Conclusion</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/tong-zeng/tong-zeng.github.io/blob/main/blogs/clustering/index.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<div class="column-screen">
<img src="img/clustering.jpg" class="content-header-full-img img-fluid">
<p style="text-align:right; font-size:0.66em">
Image source: https://www.freepik.com
</p>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>What is clustering? Clustering in machine learning is an unsupervised learning technique that involves grouping a set of data points or objects into subsets, called clusters, based on the inherent patterns or similarities among the data<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. For example, if we have a dataset containing information about mall customers, including attributes such as ‘Age,’ ‘Income,’ and ‘Spending Score,’ we input this dataset into the clustering algorithm. The algorithm then generates several clusters, considering the dataset’s characteristics and the parameters of the specific clustering algorithm employed.</p>
<section id="unsupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="unsupervised-learning"><strong>Unsupervised Learning</strong></h3>
<p>As clustering is the a typical type of unsupervised learning alglrithm, it is important to first understand what unsupervised learning.</p>
<p>Unsupervised learning is the conceptual counterpart of supervised learning. It is a category of machine learning where the algorithm is tasked with finding patterns or structures in input data without explicit guidance or labeled output. Unlike supervised learning, there are no predefined target labels for the algorithm to learn from. The goal is to explore the inherent structure within the data, making it a form of self-discovery.</p>
<p>In unsupervised learning, the algorithm seeks to identify relationships, groupings, or representations within the data to uncover hidden patterns or insights. This can involve tasks such as clustering, where similar data points are grouped together, or dimensionality reduction, where the goal is to reduce the number of features while preserving essential information.</p>
</section>
</section>
<section id="clustering-in-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="clustering-in-machine-learning">Clustering in Machine Learning</h2>
<p>Similar to unsupervised learning, the primary objective of clustering is to organize the data in such a way that items within the same cluster are more similar to each other than to those in other clusters. Clustering does not rely on predefined labels for the data; instead, it discovers the structure within the data itself. Some of the examples of clustering application are listed below:</p>
<ul>
<li><strong>Customer Segmentation:</strong> Grouping customers based on their purchasing behavior, preferences, or demographic information. For example,an e-commerce company might use clustering to identify segments of customers with similar buying patterns, allowing for targeted marketing strategies.</li>
<li><strong>Document Clustering:</strong> Organizing a collection of documents into groups based on their content or topic. For example, news articles on a website can be clustered into topics such as sports, politics, and entertainment.</li>
<li><strong>Anomaly Detection:</strong> Identifying unusual or unexpected patterns in data that do not conform to normal behavior. For example, monitoring network traffic and clustering unusual patterns to detect potential security threats.</li>
<li><strong>Social Network Analysis:</strong> Identifying communities or groups within a social network based on interactions between users. For example, Clustering users on a social media platform based on their connections and shared interests.</li>
</ul>
<p>Clustering is a versatile technique in machine learning that finds applications across various domains, contributing to data exploration, pattern discovery, and decision-making based on inherent similarities within the data.</p>
</section>
<section id="clustering-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="clustering-algorithms">Clustering Algorithms</h2>
<p>As listed above, clustering could be applied in various applications. Different applications have different data characteristics which might require different clustering algorithms. Typically, the clustering algorithms could be categorized into five types<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>:</p>
<ul>
<li><p><strong>Connectivity-based clustering:</strong></p>
<p>Connectivity-based clustering focuses on the relationships or connections between data points in the feature space. It often involves methods that identify clusters based on the concept of connectivity which is essentially the distances between data points. One notable connectivity-based clustering algorithm is Hierarchical Agglomerative Clustering (HAC).</p></li>
<li><p><strong>Centroid-based clustering:</strong></p>
<p>Centroid-based clustering is a type of clustering algorithm that organizes data points into clusters based on the proximity to the centroid of each cluster. The centroid is a representative point that minimizes the sum of squared distances from itself to all points in the cluster. This type of clustering is commonly used in applications where clusters can be well approximated by their central points. One typical centroid-based clustering is K-Means Clustering.</p></li>
<li><p><strong>Distribution-based clustering:</strong></p>
<p>Distribution-based clustering, also known as model-based clustering, is a type of clustering algorithm that assumes that the data is generated from a mixture of probability distributions. The fundamental idea is that the data points are modeled as being generated from a combination of several underlying probability distributions, and the goal of the algorithm is to identify these distributions and assign data points to the most likely one. One popular algorithm in the category of distribution-based clustering is the Gaussian Mixture Model (GMM).</p></li>
<li><p><strong>Density-based clustering:</strong></p>
<p>Density-based clustering is a type of clustering algorithm that groups data points based on their density in the feature space. Unlike centroid-based clustering, which relies on the notion of central points, density-based clustering identifies dense regions of points and separates them from sparser regions. A prominent example of a density-based clustering algorithm is DBSCAN (Density-Based Spatial Clustering of Applications with Noise).</p></li>
<li><p><strong>Grid-based clustering:</strong></p>
<p>Grid-based clustering is a type of clustering algorithm that divides the data space into a set of cells, forming a grid structure. The primary idea is to use this grid to efficiently organize and analyze the data points, identifying dense regions or clusters based on the distribution of points within the cells. Grid-based clustering methods are particularly useful when dealing with large datasets or datasets with varying point densities. One well-known example of a grid-based clustering algorithm is STING (STatistical INformation Grid).</p></li>
</ul>
<section id="applications-in-customer-segmentation" class="level3">
<h3 class="anchored" data-anchor-id="applications-in-customer-segmentation">Applications in <strong>Customer Segmentation</strong></h3>
<p>In the section above, we briefly described five different types of clustering algorithms, but given the space, we can’t discuss them all in details in this post. We plan to use the two most popular algorithms, K-Means as well as DBSCAN to solve a real world problem, namely and as mentioned before, the Customer Segmentation.</p>
<p>In this Customer Segmentation task, we will use a data about the customers like the Customer ID, age, gender, income etc, the goal is break down the customers into a few distinct subgroups, so that, we can use the subgroups to understand the customers better and further apply different marketing strategy on different subgroups.</p>
</section>
</section>
<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods">Methods</h2>
<p>In this post, we’re going to use two of the most popular clustering algorithms, namely K-Means and DBSCAN for customer segmentation. The description of these two algorithms will be covered in this section.</p>
<section id="k-means" class="level3">
<h3 class="anchored" data-anchor-id="k-means">K-Means</h3>
<p>K-Means is a popular clustering algorithm that partitions a dataset into <span class="math inline">K</span> distinct, non-overlapping subsets (clusters). Each data point belongs to the cluster with the nearest mean, serving as the prototype of the cluster. The algorithm minimizes the intra-cluster variance, aiming to create cohesive and well-separated clusters.</p>
<p>The optimization objective (loss function) introduced above could be expressed as<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>:</p>
<p><span class="math display">
{\displaystyle J= \sum_{i=1}^{k}\sum_{j=1}^{n}\left\|\ {x_j} -c_{i}\right\|^{2}}
</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">J</span> is the objective function which minimize the total squared distance of data points to their assigned cluster centroids.</p></li>
<li><p><span class="math inline">k</span> is the number of clusters.</p></li>
<li><p><span class="math inline">n</span> is the number of data points.</p></li>
<li><p><span class="math inline">x_j</span> is a data point.</p></li>
<li><p><span class="math inline">c_i</span> is the centroid of cluster <span class="math inline">i</span>.</p></li>
</ul>
</section>
<section id="dbscan" class="level3">
<h3 class="anchored" data-anchor-id="dbscan">DBSCAN</h3>
<p>DBSCAN is a density-based clustering algorithm that partitions a dataset into clusters based on the density of data points. Unlike K-Means, DBSCAN does not require specifying the number of clusters beforehand and can discover clusters of arbitrary shapes. It is particularly effective at identifying clusters in datasets with varying densities and handling noise.</p>
<p>DBSCAN optimizes the following loss function<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For any possible clustering <span class="math inline">{\displaystyle C=\{C_{1},\ldots ,C_{l}\}}</span> out of the set of all clusterings <span class="math inline">{\displaystyle {\mathcal {C}}}</span> it minimizes the number of clusters under the condition that every pair of points in a cluster is density-reachable, which corresponds to the original two properties “maximality” and “connectivity” of a cluster:</p>
<p><span class="math display">
{\displaystyle \min _{C\subset {\mathcal {C}},~d_{db}(p,q)\leq \varepsilon ~\forall p,q\in C_{i}~\forall C_{i}\in C}|C|}
</span></p>
<p>where <span class="math inline">{\displaystyle d_{db}(p,q)}</span> gives the smallest <span class="math inline">{\displaystyle \varepsilon }</span> such that two points <span class="math inline">p</span> and <span class="math inline">q</span> are density-connected.</p>
<p style="text-align: right; font-size: 0.6em">
</p><p>source: <a href="https://en.wikipedia.org/wiki/DBSCAN" class="uri">https://en.wikipedia.org/wiki/DBSCAN</a></p>
<p></p>
</div>
</div>
<p>For both the K-Means<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> and DBSCAN<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, we will use the implementation in the scikit-learn library.</p>
</section>
</section>
<section id="data" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="data">Data</h2>
<p>The data used in this post is the Mall Customers Data hosted on Github<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. The dataset is distributed in csv file and consist of 5 columns. The columns name and its meaning are explained as below:</p>
<ul>
<li><p>CustomerID: A string represents the identification number of the customer.</p></li>
<li><p>Gender: A categorical variable consist of two levels, male or female.</p></li>
<li><p>Age: An integer variable denotes the age of a customer.</p></li>
<li><p>Annual Income: An integer variable represents the annual income in kilo $.</p></li>
<li><p>Spending Score: An integer variable the customer being assigned based on their behavior and purchasing data.</p></li>
</ul>
<section id="exploratory-data-analysis" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="exploratory-data-analysis">Exploratory Data Analysis</h3>
<p>Import the libraries we might use in this blog:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, load the data and rename the columns to get more readable names:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data/Mall_Customers.csv"</span>).rename(columns<span class="op">=</span>{</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Genre"</span>:<span class="st">"Gender"</span>, </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Annual Income (k$)"</span>:<span class="st">"AnnualIncome"</span>,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Spending Score (1-100)"</span>:<span class="st">"SpendingScore"</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CustomerID</th>
<th data-quarto-table-cell-role="th">Gender</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">AnnualIncome</th>
<th data-quarto-table-cell-role="th">SpendingScore</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>Male</td>
<td>19</td>
<td>15</td>
<td>39</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>Male</td>
<td>21</td>
<td>15</td>
<td>81</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>Female</td>
<td>20</td>
<td>16</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>Female</td>
<td>23</td>
<td>16</td>
<td>77</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>Female</td>
<td>31</td>
<td>17</td>
<td>40</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<section id="descriptive-statistics" class="level4">
<h4 class="anchored" data-anchor-id="descriptive-statistics">Descriptive Statistics</h4>
<p>Let’s take a look at the descriptive statistics:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CustomerID</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">AnnualIncome</th>
<th data-quarto-table-cell-role="th">SpendingScore</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>200.000000</td>
<td>200.000000</td>
<td>200.000000</td>
<td>200.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>100.500000</td>
<td>38.850000</td>
<td>60.560000</td>
<td>50.200000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>57.879185</td>
<td>13.969007</td>
<td>26.264721</td>
<td>25.823522</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>1.000000</td>
<td>18.000000</td>
<td>15.000000</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>50.750000</td>
<td>28.750000</td>
<td>41.500000</td>
<td>34.750000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>100.500000</td>
<td>36.000000</td>
<td>61.500000</td>
<td>50.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>150.250000</td>
<td>49.000000</td>
<td>78.000000</td>
<td>73.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>200.000000</td>
<td>70.000000</td>
<td>137.000000</td>
<td>99.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df.isnull().<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>CustomerID       0
Gender           0
Age              0
AnnualIncome     0
SpendingScore    0
dtype: int64</code></pre>
</div>
</div>
<p>There are no missing data, it is good for demonstration purpose since we can more focused on core parts, but please keep in mind that it is unlikely the scenario in real life applications where we put significant amount of time to clean and preprocessing the data before analysis and modeling stage.</p>
</section>
<section id="data-visualization" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="data-visualization">Data Visualization</h4>
<p>There is one category filed named <code>Gender</code>, it has two levels, male and female. There distribution of these two types are as follows:</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>gender_level_count <span class="op">=</span> df[<span class="st">'Gender'</span>].value_counts()</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">'Male'</span>,<span class="st">'Female'</span>]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>plt.pie(gender_level_count, labels<span class="op">=</span>labels, autopct<span class="op">=</span><span class="st">'%.0f</span><span class="sc">%%</span><span class="st">'</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="index_files/figure-html/cell-6-output-1.png" width="389" height="389" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>There are slightly little more male than female. Let’s then, analysis the other three numerical fields:</p>
<div class="cell page-columns page-full" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>sns.pairplot(df[[<span class="st">"Gender"</span>, <span class="st">"Age"</span>, <span class="st">"AnnualIncome"</span>, <span class="st">"SpendingScore"</span>]], hue<span class="op">=</span><span class="st">'Gender'</span>, aspect<span class="op">=</span><span class="fl">1.5</span>, height<span class="op">=</span><span class="fl">2.85</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display column-page">
<p><img src="index_files/figure-html/cell-7-output-1.png" width="1319" height="808"></p>
</div>
</div>
<p><br></p>
<p>The plot above separates the data into male and female group and display the male group data distribution in blue and female group in yellow.</p>
<p>The diagonal represents the data distribution of the corresponding field, we can infer that:</p>
<ul>
<li>The distribution of all these fields is not perfectly normal distributed, but has a bell shape with one peak and descents at both left and right side.</li>
<li>There is not significant subgroups if we only looks at one field.</li>
</ul>
<p>If we examine each field individually:</p>
<ul>
<li><p>Age group near 30-40 has the highest density.</p></li>
<li><p>Most of customers have income 40-90k.</p></li>
<li><p>Most of customers have spending score around 50.</p></li>
</ul>
<p>If we check the subplots in pairs, we can find that there are no significant relationship between the pairs, except for the relationship between <code>Annual Income</code> and <code>Spending Score</code> , the data points are clearly divided into five subgroups.</p>
</section>
</section>
</section>
<section id="experiments" class="level2">
<h2 class="anchored" data-anchor-id="experiments">Experiments</h2>
<p>We now start clustering analysis with K-Means algorithm, we will use the sklearn library.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'Age'</span>, <span class="st">'AnnualIncome'</span>, <span class="st">'SpendingScore'</span>]]</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>wcss<span class="op">=</span> []</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters <span class="op">=</span> k, n_init<span class="op">=</span><span class="st">'auto'</span>, init <span class="op">=</span> <span class="st">'k-means++'</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    wcss.append(kmeans.inertia_)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>), wcss, linewidth <span class="op">=</span> <span class="dv">2</span>,  marker<span class="op">=</span><span class="st">'*'</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Elbow Plot</span><span class="ch">\n</span><span class="st">'</span>, fontsize <span class="op">=</span> <span class="dv">20</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'K'</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'WCSS (Within-Cluster Sum of Square)'</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-9-output-1.png" width="693" height="414"></p>
</div>
</div>
<p>From the elbow plot, we can infer that K=6 could be the best number of cluster. Let’s then use the number of clusters as 6 to train the K-Means and plot the distribution of predicted clusters using three dimension plot as follows:</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'Age'</span>, <span class="st">'AnnualIncome'</span>, <span class="st">'SpendingScore'</span>]]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters <span class="op">=</span> <span class="dv">6</span>, n_init<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> kmeans.fit_predict(X)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>X[<span class="st">'label'</span>] <span class="op">=</span> clusters</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter_3d(X, x<span class="op">=</span><span class="st">"AnnualIncome"</span>, y<span class="op">=</span><span class="st">"SpendingScore"</span>, z<span class="op">=</span><span class="st">"Age"</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>                    color <span class="op">=</span> <span class="st">'label'</span>, size <span class="op">=</span> <span class="st">'label'</span>, width<span class="op">=</span><span class="dv">750</span>, height<span class="op">=</span><span class="dv">600</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<div>                            <div id="0896a33b-365c-4610-af75-b5b2c663610c" class="plotly-graph-div" style="height:600px; width:750px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("0896a33b-365c-4610-af75-b5b2c663610c")) {                    Plotly.newPlot(                        "0896a33b-365c-4610-af75-b5b2c663610c",                        [{"hovertemplate":"AnnualIncome=%{x}\u003cbr\u003eSpendingScore=%{y}\u003cbr\u003eAge=%{z}\u003cbr\u003elabel=%{marker.color}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":[1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,2,4,1,5,1,4,2,5,5,5,2,5,5,2,2,2,2,2,5,2,2,5,2,2,2,5,2,2,5,5,2,2,2,2,2,5,2,5,5,2,2,5,2,2,5,2,2,5,5,2,2,5,2,5,5,5,2,5,2,5,5,2,2,5,2,5,2,2,2,2,2,5,5,5,5,5,2,2,2,2,5,5,5,0,5,0,3,0,3,0,3,0,5,0,3,0,3,0,3,0,3,0,5,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0],"coloraxis":"coloraxis","size":[1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,2,4,1,5,1,4,2,5,5,5,2,5,5,2,2,2,2,2,5,2,2,5,2,2,2,5,2,2,5,5,2,2,2,2,2,5,2,5,5,2,2,5,2,2,5,2,2,5,5,2,2,5,2,5,5,5,2,5,2,5,5,2,2,5,2,5,2,2,2,2,2,5,5,5,5,5,2,2,2,2,5,5,5,0,5,0,3,0,3,0,3,0,5,0,3,0,3,0,3,0,3,0,5,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0],"sizemode":"area","sizeref":0.0125,"symbol":"circle"},"mode":"markers","name":"","scene":"scene","showlegend":false,"x":[15,15,16,16,17,17,18,18,19,19,19,19,20,20,20,20,21,21,23,23,24,24,25,25,28,28,28,28,29,29,30,30,33,33,33,33,34,34,37,37,38,38,39,39,39,39,40,40,40,40,42,42,43,43,43,43,44,44,46,46,46,46,47,47,48,48,48,48,48,48,49,49,50,50,54,54,54,54,54,54,54,54,54,54,54,54,57,57,58,58,59,59,60,60,60,60,60,60,61,61,62,62,62,62,62,62,63,63,63,63,63,63,64,64,65,65,65,65,67,67,67,67,69,69,70,70,71,71,71,71,71,71,72,72,73,73,73,73,74,74,75,75,76,76,77,77,77,77,78,78,78,78,78,78,78,78,78,78,78,78,79,79,81,81,85,85,86,86,87,87,87,87,87,87,88,88,88,88,93,93,97,97,98,98,99,99,101,101,103,103,103,103,113,113,120,120,126,126,137,137],"y":[39,81,6,77,40,76,6,94,3,72,14,99,15,77,13,79,35,66,29,98,35,73,5,73,14,82,32,61,31,87,4,73,4,92,14,81,17,73,26,75,35,92,36,61,28,65,55,47,42,42,52,60,54,60,45,41,50,46,51,46,56,55,52,59,51,59,50,48,59,47,55,42,49,56,47,54,53,48,52,42,51,55,41,44,57,46,58,55,60,46,55,41,49,40,42,52,47,50,42,49,41,48,59,55,56,42,50,46,43,48,52,54,42,46,48,50,43,59,43,57,56,40,58,91,29,77,35,95,11,75,9,75,34,71,5,88,7,73,10,72,5,93,40,87,12,97,36,74,22,90,17,88,20,76,16,89,1,78,1,73,35,83,5,93,26,75,20,95,27,63,13,75,10,92,13,86,15,69,14,90,32,86,15,88,39,97,24,68,17,85,23,69,8,91,16,79,28,74,18,83],"z":[19,21,20,23,31,22,35,23,64,30,67,35,58,24,37,22,35,20,52,35,35,25,46,31,54,29,45,35,40,23,60,21,53,18,49,21,42,30,36,20,65,24,48,31,49,24,50,27,29,31,49,33,31,59,50,47,51,69,27,53,70,19,67,54,63,18,43,68,19,32,70,47,60,60,59,26,45,40,23,49,57,38,67,46,21,48,55,22,34,50,68,18,48,40,32,24,47,27,48,20,23,49,67,26,49,21,66,54,68,66,65,19,38,19,18,19,63,49,51,50,27,38,40,39,23,31,43,40,59,38,47,39,25,31,20,29,44,32,19,35,57,32,28,32,25,28,48,32,34,34,43,39,44,38,47,27,37,30,34,30,56,29,19,31,50,36,42,33,36,32,40,28,36,36,52,30,58,27,59,35,37,32,46,29,41,30,54,28,41,36,34,32,33,38,47,35,45,32,32,30],"type":"scatter3d"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"scene":{"domain":{"x":[0.0,1.0],"y":[0.0,1.0]},"xaxis":{"title":{"text":"AnnualIncome"}},"yaxis":{"title":{"text":"SpendingScore"}},"zaxis":{"title":{"text":"Age"}}},"coloraxis":{"colorbar":{"title":{"text":"label"}},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"legend":{"tracegroupgap":0,"itemsizing":"constant"},"margin":{"t":60},"height":600,"width":750},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('0896a33b-365c-4610-af75-b5b2c663610c');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>We are now going to use the DBSCAN to carry out the clustering analysis:</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="dv">11</span>, min_samples<span class="op">=</span><span class="dv">6</span>).fit(X)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>X[<span class="st">'label'</span>] <span class="op">=</span> clusters</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter_3d(X, x<span class="op">=</span><span class="st">"AnnualIncome"</span>, y<span class="op">=</span><span class="st">"SpendingScore"</span>, z<span class="op">=</span><span class="st">"Age"</span>,</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>                    color <span class="op">=</span> <span class="st">'label'</span>, size <span class="op">=</span> <span class="st">'label'</span>, width<span class="op">=</span><span class="dv">750</span>, height<span class="op">=</span><span class="dv">600</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<div>                            <div id="ea3a8512-22ea-4428-beff-6889f72c4443" class="plotly-graph-div" style="height:600px; width:750px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("ea3a8512-22ea-4428-beff-6889f72c4443")) {                    Plotly.newPlot(                        "ea3a8512-22ea-4428-beff-6889f72c4443",                        [{"hovertemplate":"AnnualIncome=%{x}\u003cbr\u003eSpendingScore=%{y}\u003cbr\u003eAge=%{z}\u003cbr\u003elabel=%{marker.color}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":[1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,2,4,1,5,1,4,2,5,5,5,2,5,5,2,2,2,2,2,5,2,2,5,2,2,2,5,2,2,5,5,2,2,2,2,2,5,2,5,5,2,2,5,2,2,5,2,2,5,5,2,2,5,2,5,5,5,2,5,2,5,5,2,2,5,2,5,2,2,2,2,2,5,5,5,5,5,2,2,2,2,5,5,5,0,5,0,3,0,3,0,3,0,5,0,3,0,3,0,3,0,3,0,5,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0],"coloraxis":"coloraxis","size":[1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,1,4,2,4,1,5,1,4,2,5,5,5,2,5,5,2,2,2,2,2,5,2,2,5,2,2,2,5,2,2,5,5,2,2,2,2,2,5,2,5,5,2,2,5,2,2,5,2,2,5,5,2,2,5,2,5,5,5,2,5,2,5,5,2,2,5,2,5,2,2,2,2,2,5,5,5,5,5,2,2,2,2,5,5,5,0,5,0,3,0,3,0,3,0,5,0,3,0,3,0,3,0,3,0,5,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0,3,0],"sizemode":"area","sizeref":0.0125,"symbol":"circle"},"mode":"markers","name":"","scene":"scene","showlegend":false,"x":[15,15,16,16,17,17,18,18,19,19,19,19,20,20,20,20,21,21,23,23,24,24,25,25,28,28,28,28,29,29,30,30,33,33,33,33,34,34,37,37,38,38,39,39,39,39,40,40,40,40,42,42,43,43,43,43,44,44,46,46,46,46,47,47,48,48,48,48,48,48,49,49,50,50,54,54,54,54,54,54,54,54,54,54,54,54,57,57,58,58,59,59,60,60,60,60,60,60,61,61,62,62,62,62,62,62,63,63,63,63,63,63,64,64,65,65,65,65,67,67,67,67,69,69,70,70,71,71,71,71,71,71,72,72,73,73,73,73,74,74,75,75,76,76,77,77,77,77,78,78,78,78,78,78,78,78,78,78,78,78,79,79,81,81,85,85,86,86,87,87,87,87,87,87,88,88,88,88,93,93,97,97,98,98,99,99,101,101,103,103,103,103,113,113,120,120,126,126,137,137],"y":[39,81,6,77,40,76,6,94,3,72,14,99,15,77,13,79,35,66,29,98,35,73,5,73,14,82,32,61,31,87,4,73,4,92,14,81,17,73,26,75,35,92,36,61,28,65,55,47,42,42,52,60,54,60,45,41,50,46,51,46,56,55,52,59,51,59,50,48,59,47,55,42,49,56,47,54,53,48,52,42,51,55,41,44,57,46,58,55,60,46,55,41,49,40,42,52,47,50,42,49,41,48,59,55,56,42,50,46,43,48,52,54,42,46,48,50,43,59,43,57,56,40,58,91,29,77,35,95,11,75,9,75,34,71,5,88,7,73,10,72,5,93,40,87,12,97,36,74,22,90,17,88,20,76,16,89,1,78,1,73,35,83,5,93,26,75,20,95,27,63,13,75,10,92,13,86,15,69,14,90,32,86,15,88,39,97,24,68,17,85,23,69,8,91,16,79,28,74,18,83],"z":[19,21,20,23,31,22,35,23,64,30,67,35,58,24,37,22,35,20,52,35,35,25,46,31,54,29,45,35,40,23,60,21,53,18,49,21,42,30,36,20,65,24,48,31,49,24,50,27,29,31,49,33,31,59,50,47,51,69,27,53,70,19,67,54,63,18,43,68,19,32,70,47,60,60,59,26,45,40,23,49,57,38,67,46,21,48,55,22,34,50,68,18,48,40,32,24,47,27,48,20,23,49,67,26,49,21,66,54,68,66,65,19,38,19,18,19,63,49,51,50,27,38,40,39,23,31,43,40,59,38,47,39,25,31,20,29,44,32,19,35,57,32,28,32,25,28,48,32,34,34,43,39,44,38,47,27,37,30,34,30,56,29,19,31,50,36,42,33,36,32,40,28,36,36,52,30,58,27,59,35,37,32,46,29,41,30,54,28,41,36,34,32,33,38,47,35,45,32,32,30],"type":"scatter3d"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"scene":{"domain":{"x":[0.0,1.0],"y":[0.0,1.0]},"xaxis":{"title":{"text":"AnnualIncome"}},"yaxis":{"title":{"text":"SpendingScore"}},"zaxis":{"title":{"text":"Age"}}},"coloraxis":{"colorbar":{"title":{"text":"label"}},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"legend":{"tracegroupgap":0,"itemsizing":"constant"},"margin":{"t":60},"height":600,"width":750},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('ea3a8512-22ea-4428-beff-6889f72c4443');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p><br></p>
<p>For DBSCAN we don’t need to choose the hyper parameter K anymore, the algorithm will divide the dataset into 5 clusters automatically, which is different than the result of K-Means (6 clusters).</p>
</section>
<section id="discussion-and-conclusion" class="level2">
<h2 class="anchored" data-anchor-id="discussion-and-conclusion">Discussion and Conclusion</h2>
<p>In this plot, we introduced the clustering algorithm as a classical type of unsupervised learning and applied two clustering techniques, namely K-Means and DBSCAN in the customer segmentation task. Our analysis and visualization shows the steps and differences between these two algorithms when applied in real world problems.</p>
<p>Both the K-Means and DBSCAN aim to group similar data points together into clusters based on the data characteristics. They are both unsupervised learning techniques, meaning they don’t rely on labeled training data and instead can discover patterns or structure within the data itself.</p>
<p>While K-Means and DBSCAN share lots of traits in nature, here we wanted to mention some of the key differences between K-Means and DBSCAN:</p>
<ul>
<li><p><strong>Algorithm Type:</strong></p>
<p><strong>K-Means</strong> is a centroid-based clustering algorithm. It aims to partition data into K clusters, where each cluster is represented by its centroid.</p>
<p><strong>DBSCAN</strong> is a density-based clustering algorithm. It groups together data points that are close to each other and have a sufficient number of neighboring points.</p></li>
<li><p><strong>Cluster Number:</strong></p>
<p><strong>K-Means</strong> requires the user to specify the number of clusters (K) beforehand, and it assigns each data point to the nearest centroid.</p>
<p><strong>DBSCAN</strong> does not require the user to specify the number of clusters. It automatically discovers clusters based on the density of data points.</p></li>
<li><p><strong>Handling Noisy Data:</strong></p>
<p><strong>K-Means</strong> sensitive to outliers and noise because it tries to assign all data points to a cluster, even if they do not belong to any clear cluster.</p>
<p><strong>DBSCAN</strong> can identify and label outliers as noise, making it more robust to outliers and better at handling data with varying densities.</p></li>
<li><p><strong>Parameter Sensitivity:</strong></p>
<p><strong>K-Means</strong> is sensitive to the initial placement of centroids, and the final result may depend on the initial cluster centers.</p>
<p><strong>DBSCAN</strong> is less sensitive to the choice of parameters, such as the density threshold and the minimum number of points required to form a cluster.</p></li>
</ul>
<p>In summary, K-Means is suitable for well-defined, spherical clusters with a predetermined number of clusters, while DBSCAN is more flexible, handling clusters of arbitrary shapes and automatically determining the number of clusters based on data density. The choice between them depends on the characteristics of the data and the desired properties of the clusters.</p>


<!-- -->

</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><a href="https://en.wikipedia.org/wiki/Cluster_analysis" class="uri">https://en.wikipedia.org/wiki/Cluster_analysis</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://en.wikipedia.org/wiki/Cluster_analysis" class="uri">https://en.wikipedia.org/wiki/Cluster_analysis</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a href="https://en.wikipedia.org/wiki/K-means_clustering" class="uri">https://en.wikipedia.org/wiki/K-means_clustering</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Beer, Anna; Draganov, Andrew; Hohma, Ellen; Jahn, Philipp; Frey, Christian M.M.; Assent, Ira (6 August 2023). <a href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599283">“Connecting the Dots -- Density-Connectivity Distance unifies DBSCAN, k-Center and Spectral Clustering”</a>. <em>Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>. ACM. pp.&nbsp;80–92. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a href="https://doi.org/10.1145%2F3580305.3599283">10.1145/3580305.3599283</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9798400701030" title="Special:BookSources/9798400701030">9798400701030</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a href="https://api.semanticscholar.org/CorpusID:260499476">260499476</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" class="uri">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html" class="uri">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p><a href="https://github.com/SteffiPeTaffy/machineLearningAZ/blob/master/Machine%20Learning%20A-Z%20Template%20Folder/Part%204%20-%20Clustering/Section%2025%20-%20Hierarchical%20Clustering/Mall_Customers.csv" class="uri">https://github.com/SteffiPeTaffy/machineLearningAZ/blob/master/Machine%20Learning%20A-Z%20Template%20Folder/Part%204%20-%20Clustering/Section%2025%20-%20Hierarchical%20Clustering/Mall_Customers.csv</a><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../blogs.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Blogs</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../blogs/regression/index.html" class="pagination-link">
        <span class="nav-page-text">Linear and Nonlinear Regression</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb12" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Clustering"</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Tong Zeng"</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-11-26"</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Clustering, Unsupervised Learning]</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "img/clustering.jpg"</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> Application of clustering for customer segmentation</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>::: column-screen</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="al">![](img/clustering.jpg)</span>{.content-header-full-img}</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;p</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-align:right; font-size:0.66em"</span><span class="kw">&gt;</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>Image source: https://www.freepik.com</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/p&gt;</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>What is clustering? Clustering in machine learning is an unsupervised learning technique that involves grouping a set of data points or objects into subsets, called clusters, based on the inherent patterns or similarities among the data<span class="ot">[^1]</span>. For example, if we have a dataset containing information about mall customers, including attributes such as 'Age,' 'Income,' and 'Spending Score,' we input this dataset into the clustering algorithm. The algorithm then generates several clusters, considering the dataset's characteristics and the parameters of the specific clustering algorithm employed.</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: &lt;https://en.wikipedia.org/wiki/Cluster_analysis&gt;</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Unsupervised Learning**</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>As clustering is the a typical type of unsupervised learning alglrithm, it is important to first understand what unsupervised learning.</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>Unsupervised learning is the conceptual counterpart of supervised learning. It is a category of machine learning where the algorithm is tasked with finding patterns or structures in input data without explicit guidance or labeled output. Unlike supervised learning, there are no predefined target labels for the algorithm to learn from. The goal is to explore the inherent structure within the data, making it a form of self-discovery.</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>In unsupervised learning, the algorithm seeks to identify relationships, groupings, or representations within the data to uncover hidden patterns or insights. This can involve tasks such as clustering, where similar data points are grouped together, or dimensionality reduction, where the goal is to reduce the number of features while preserving essential information.</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="fu">## Clustering in Machine Learning</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>Similar to unsupervised learning, the primary objective of clustering is to organize the data in such a way that items within the same cluster are more similar to each other than to those in other clusters. Clustering does not rely on predefined labels for the data; instead, it discovers the structure within the data itself. Some of the examples of clustering application are listed below:</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Customer Segmentation:** Grouping customers based on their purchasing behavior, preferences, or demographic information. For example,an e-commerce company might use clustering to identify segments of customers with similar buying patterns, allowing for targeted marketing strategies.</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Document Clustering:** Organizing a collection of documents into groups based on their content or topic. For example, news articles on a website can be clustered into topics such as sports, politics, and entertainment.</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Anomaly Detection:** Identifying unusual or unexpected patterns in data that do not conform to normal behavior. For example, monitoring network traffic and clustering unusual patterns to detect potential security threats.</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Social Network Analysis:** Identifying communities or groups within a social network based on interactions between users. For example, Clustering users on a social media platform based on their connections and shared interests.</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>Clustering is a versatile technique in machine learning that finds applications across various domains, contributing to data exploration, pattern discovery, and decision-making based on inherent similarities within the data.</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a><span class="fu">## Clustering Algorithms</span></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>As listed above, clustering could be applied in various applications. Different applications have different data characteristics which might require different clustering algorithms. Typically, the clustering algorithms could be categorized into five types<span class="ot">[^2]</span>:</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a><span class="ot">[^2]: &lt;https://en.wikipedia.org/wiki/Cluster_analysis&gt;</span></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Connectivity-based clustering:**</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>    Connectivity-based clustering focuses on the relationships or connections between data points in the feature space. It often involves methods that identify clusters based on the concept of connectivity which is essentially the distances between data points. One notable connectivity-based clustering algorithm is Hierarchical Agglomerative Clustering (HAC).</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Centroid-based clustering:**</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>    Centroid-based clustering is a type of clustering algorithm that organizes data points into clusters based on the proximity to the centroid of each cluster. The centroid is a representative point that minimizes the sum of squared distances from itself to all points in the cluster. This type of clustering is commonly used in applications where clusters can be well approximated by their central points. One typical centroid-based clustering is K-Means Clustering.</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Distribution-based clustering:**</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>    Distribution-based clustering, also known as model-based clustering, is a type of clustering algorithm that assumes that the data is generated from a mixture of probability distributions. The fundamental idea is that the data points are modeled as being generated from a combination of several underlying probability distributions, and the goal of the algorithm is to identify these distributions and assign data points to the most likely one. One popular algorithm in the category of distribution-based clustering is the Gaussian Mixture Model (GMM).</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Density-based clustering:**</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>    Density-based clustering is a type of clustering algorithm that groups data points based on their density in the feature space. Unlike centroid-based clustering, which relies on the notion of central points, density-based clustering identifies dense regions of points and separates them from sparser regions. A prominent example of a density-based clustering algorithm is DBSCAN (Density-Based Spatial Clustering of Applications with Noise).</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Grid-based clustering:**</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a>    Grid-based clustering is a type of clustering algorithm that divides the data space into a set of cells, forming a grid structure. The primary idea is to use this grid to efficiently organize and analyze the data points, identifying dense regions or clusters based on the distribution of points within the cells. Grid-based clustering methods are particularly useful when dealing with large datasets or datasets with varying point densities. One well-known example of a grid-based clustering algorithm is STING (STatistical INformation Grid).</span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a><span class="fu">### Applications in **Customer Segmentation**</span></span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a>In the section above, we briefly described five different types of clustering algorithms, but given the space, we can't discuss them all in details in this post. We plan to use the two most popular algorithms, K-Means as well as DBSCAN to solve a real world problem, namely and as mentioned before, the Customer Segmentation.</span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>In this Customer Segmentation task, we will use a data about the customers like the Customer ID, age, gender, income etc, the goal is break down the customers into a few distinct subgroups, so that, we can use the subgroups to understand the customers better and further apply different marketing strategy on different subgroups.</span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a><span class="fu">## Methods</span></span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a>In this post, we're going to use two of the most popular clustering algorithms, namely K-Means and DBSCAN for customer segmentation. The description of these two algorithms will be covered in this section.</span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-78"><a href="#cb12-78" aria-hidden="true" tabindex="-1"></a><span class="fu">### K-Means</span></span>
<span id="cb12-79"><a href="#cb12-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-80"><a href="#cb12-80" aria-hidden="true" tabindex="-1"></a>K-Means is a popular clustering algorithm that partitions a dataset into $K$ distinct, non-overlapping subsets (clusters). Each data point belongs to the cluster with the nearest mean, serving as the prototype of the cluster. The algorithm minimizes the intra-cluster variance, aiming to create cohesive and well-separated clusters.</span>
<span id="cb12-81"><a href="#cb12-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-82"><a href="#cb12-82" aria-hidden="true" tabindex="-1"></a>The optimization objective (loss function) introduced above could be expressed as<span class="ot">[^3]</span>:</span>
<span id="cb12-83"><a href="#cb12-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-84"><a href="#cb12-84" aria-hidden="true" tabindex="-1"></a><span class="ot">[^3]: &lt;https://en.wikipedia.org/wiki/K-means_clustering&gt;</span></span>
<span id="cb12-85"><a href="#cb12-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-86"><a href="#cb12-86" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-87"><a href="#cb12-87" aria-hidden="true" tabindex="-1"></a>{\displaystyle J= \sum_{i=1}^{k}\sum_{j=1}^{n}\left\|\ {x_j} -c_{i}\right\|^{2}}</span>
<span id="cb12-88"><a href="#cb12-88" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-89"><a href="#cb12-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-90"><a href="#cb12-90" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb12-91"><a href="#cb12-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-92"><a href="#cb12-92" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$J$ is the objective function which minimize the total squared distance of data points to their assigned cluster centroids.</span>
<span id="cb12-93"><a href="#cb12-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-94"><a href="#cb12-94" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$k$ is the number of clusters.</span>
<span id="cb12-95"><a href="#cb12-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-96"><a href="#cb12-96" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$n$ is the number of data points.</span>
<span id="cb12-97"><a href="#cb12-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-98"><a href="#cb12-98" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$x_j$ is a data point.</span>
<span id="cb12-99"><a href="#cb12-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-100"><a href="#cb12-100" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$c_i$ is the centroid of cluster $i$.</span>
<span id="cb12-101"><a href="#cb12-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-102"><a href="#cb12-102" aria-hidden="true" tabindex="-1"></a><span class="fu">### DBSCAN</span></span>
<span id="cb12-103"><a href="#cb12-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-104"><a href="#cb12-104" aria-hidden="true" tabindex="-1"></a>DBSCAN is a density-based clustering algorithm that partitions a dataset into clusters based on the density of data points. Unlike K-Means, DBSCAN does not require specifying the number of clusters beforehand and can discover clusters of arbitrary shapes. It is particularly effective at identifying clusters in datasets with varying densities and handling noise.</span>
<span id="cb12-105"><a href="#cb12-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-106"><a href="#cb12-106" aria-hidden="true" tabindex="-1"></a>DBSCAN optimizes the following loss function<span class="ot">[^4]</span>:</span>
<span id="cb12-107"><a href="#cb12-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-108"><a href="#cb12-108" aria-hidden="true" tabindex="-1"></a><span class="ot">[^4]: </span>Beer, Anna; Draganov, Andrew; Hohma, Ellen; Jahn, Philipp; Frey, Christian M.M.; Assent, Ira (6 August 2023). <span class="co">[</span><span class="ot">"Connecting the Dots \-- Density-Connectivity Distance unifies DBSCAN, k-Center and Spectral Clustering"</span><span class="co">](https://dl.acm.org/doi/pdf/10.1145/3580305.3599283)</span>. *Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining*. ACM. pp.&nbsp;80--92. <span class="co">[</span><span class="ot">doi</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):<span class="co">[</span><span class="ot">10.1145/3580305.3599283</span><span class="co">](https://doi.org/10.1145%2F3580305.3599283)</span>. <span class="co">[</span><span class="ot">ISBN</span><span class="co">]</span>(https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")&nbsp;<span class="co">[</span><span class="ot">9798400701030</span><span class="co">](https://en.wikipedia.org/wiki/Special:BookSources/9798400701030 "Special:BookSources/9798400701030")</span>. <span class="co">[</span><span class="ot">S2CID</span><span class="co">]</span>(https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")&nbsp;<span class="co">[</span><span class="ot">260499476</span><span class="co">](https://api.semanticscholar.org/CorpusID:260499476)</span></span>
<span id="cb12-109"><a href="#cb12-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-110"><a href="#cb12-110" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb12-111"><a href="#cb12-111" aria-hidden="true" tabindex="-1"></a>For any possible clustering ${\displaystyle C=<span class="sc">\{</span>C_{1},\ldots ,C_{l}<span class="sc">\}</span>}$ out of the set of all clusterings ${\displaystyle {\mathcal {C}}}$ it minimizes the number of clusters under the condition that every pair of points in a cluster is density-reachable, which corresponds to the original two properties "maximality" and "connectivity" of a cluster:</span>
<span id="cb12-112"><a href="#cb12-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-113"><a href="#cb12-113" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-114"><a href="#cb12-114" aria-hidden="true" tabindex="-1"></a>{\displaystyle \min _{C\subset {\mathcal {C}},~d_{db}(p,q)\leq \varepsilon ~\forall p,q\in C_{i}~\forall C_{i}\in C}|C|}</span>
<span id="cb12-115"><a href="#cb12-115" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-116"><a href="#cb12-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-117"><a href="#cb12-117" aria-hidden="true" tabindex="-1"></a>where ${\displaystyle d_{db}(p,q)}$ gives the smallest ${\displaystyle \varepsilon }$ such that two points $p$ and $q$ are density-connected.</span>
<span id="cb12-118"><a href="#cb12-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-119"><a href="#cb12-119" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;p</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-align: right; font-size: 0.6em"</span><span class="kw">&gt;</span></span>
<span id="cb12-120"><a href="#cb12-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-121"><a href="#cb12-121" aria-hidden="true" tabindex="-1"></a>source: <span class="ot">&lt;https://en.wikipedia.org/wiki/DBSCAN&gt;</span></span>
<span id="cb12-122"><a href="#cb12-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-123"><a href="#cb12-123" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/p&gt;</span></span>
<span id="cb12-124"><a href="#cb12-124" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-125"><a href="#cb12-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-126"><a href="#cb12-126" aria-hidden="true" tabindex="-1"></a>For both the K-Means<span class="ot">[^5]</span> and DBSCAN<span class="ot">[^6]</span>, we will use the implementation in the scikit-learn library.</span>
<span id="cb12-127"><a href="#cb12-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-128"><a href="#cb12-128" aria-hidden="true" tabindex="-1"></a><span class="ot">[^5]: &lt;https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html&gt;</span></span>
<span id="cb12-129"><a href="#cb12-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-130"><a href="#cb12-130" aria-hidden="true" tabindex="-1"></a><span class="ot">[^6]: &lt;https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html&gt;</span></span>
<span id="cb12-131"><a href="#cb12-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-132"><a href="#cb12-132" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data</span></span>
<span id="cb12-133"><a href="#cb12-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-134"><a href="#cb12-134" aria-hidden="true" tabindex="-1"></a>The data used in this post is the Mall Customers Data hosted on Github<span class="ot">[^7]</span>. The dataset is distributed in csv file and consist of 5 columns. The columns name and its meaning are explained as below:</span>
<span id="cb12-135"><a href="#cb12-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-136"><a href="#cb12-136" aria-hidden="true" tabindex="-1"></a><span class="ot">[^7]: &lt;https://github.com/SteffiPeTaffy/machineLearningAZ/blob/master/Machine%20Learning%20A-Z%20Template%20Folder/Part%204%20-%20Clustering/Section%2025%20-%20Hierarchical%20Clustering/Mall_Customers.csv&gt;</span></span>
<span id="cb12-137"><a href="#cb12-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-138"><a href="#cb12-138" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>CustomerID: A string represents the identification number of the customer.</span>
<span id="cb12-139"><a href="#cb12-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-140"><a href="#cb12-140" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Gender: A categorical variable consist of two levels, male or female.</span>
<span id="cb12-141"><a href="#cb12-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-142"><a href="#cb12-142" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Age: An integer variable denotes the age of a customer.</span>
<span id="cb12-143"><a href="#cb12-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-144"><a href="#cb12-144" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Annual Income: An integer variable represents the annual income in kilo \$.</span>
<span id="cb12-145"><a href="#cb12-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-146"><a href="#cb12-146" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Spending Score: An integer variable the customer being assigned based on their behavior and purchasing data.</span>
<span id="cb12-147"><a href="#cb12-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-148"><a href="#cb12-148" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exploratory Data Analysis</span></span>
<span id="cb12-149"><a href="#cb12-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-150"><a href="#cb12-150" aria-hidden="true" tabindex="-1"></a>Import the libraries we might use in this blog:</span>
<span id="cb12-151"><a href="#cb12-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-154"><a href="#cb12-154" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-155"><a href="#cb12-155" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-156"><a href="#cb12-156" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb12-157"><a href="#cb12-157" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-158"><a href="#cb12-158" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb12-159"><a href="#cb12-159" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-160"><a href="#cb12-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-161"><a href="#cb12-161" aria-hidden="true" tabindex="-1"></a>Now, load the data and rename the columns to get more readable names:</span>
<span id="cb12-162"><a href="#cb12-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-165"><a href="#cb12-165" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-166"><a href="#cb12-166" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data/Mall_Customers.csv"</span>).rename(columns<span class="op">=</span>{</span>
<span id="cb12-167"><a href="#cb12-167" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Genre"</span>:<span class="st">"Gender"</span>, </span>
<span id="cb12-168"><a href="#cb12-168" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Annual Income (k$)"</span>:<span class="st">"AnnualIncome"</span>,</span>
<span id="cb12-169"><a href="#cb12-169" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Spending Score (1-100)"</span>:<span class="st">"SpendingScore"</span></span>
<span id="cb12-170"><a href="#cb12-170" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb12-171"><a href="#cb12-171" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb12-172"><a href="#cb12-172" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-173"><a href="#cb12-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-174"><a href="#cb12-174" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Descriptive Statistics</span></span>
<span id="cb12-175"><a href="#cb12-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-176"><a href="#cb12-176" aria-hidden="true" tabindex="-1"></a>Let's take a look at the descriptive statistics:</span>
<span id="cb12-177"><a href="#cb12-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-180"><a href="#cb12-180" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-181"><a href="#cb12-181" aria-hidden="true" tabindex="-1"></a>df.describe()</span>
<span id="cb12-182"><a href="#cb12-182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-183"><a href="#cb12-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-186"><a href="#cb12-186" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-187"><a href="#cb12-187" aria-hidden="true" tabindex="-1"></a>df.isnull().<span class="bu">sum</span>()</span>
<span id="cb12-188"><a href="#cb12-188" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-189"><a href="#cb12-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-190"><a href="#cb12-190" aria-hidden="true" tabindex="-1"></a>There are no missing data, it is good for demonstration purpose since we can more focused on core parts, but please keep in mind that it is unlikely the scenario in real life applications where we put significant amount of time to clean and preprocessing the data before analysis and modeling stage.</span>
<span id="cb12-191"><a href="#cb12-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-192"><a href="#cb12-192" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Data Visualization</span></span>
<span id="cb12-193"><a href="#cb12-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-194"><a href="#cb12-194" aria-hidden="true" tabindex="-1"></a>There is one category filed named <span class="in">`Gender`</span>, it has two levels, male and female. There distribution of these two types are as follows:</span>
<span id="cb12-195"><a href="#cb12-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-198"><a href="#cb12-198" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-199"><a href="#cb12-199" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb12-200"><a href="#cb12-200" aria-hidden="true" tabindex="-1"></a>gender_level_count <span class="op">=</span> df[<span class="st">'Gender'</span>].value_counts()</span>
<span id="cb12-201"><a href="#cb12-201" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">'Male'</span>,<span class="st">'Female'</span>]</span>
<span id="cb12-202"><a href="#cb12-202" aria-hidden="true" tabindex="-1"></a>plt.pie(gender_level_count, labels<span class="op">=</span>labels, autopct<span class="op">=</span><span class="st">'%.0f</span><span class="sc">%%</span><span class="st">'</span>)</span>
<span id="cb12-203"><a href="#cb12-203" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb12-204"><a href="#cb12-204" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-205"><a href="#cb12-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-206"><a href="#cb12-206" aria-hidden="true" tabindex="-1"></a>There are slightly little more male than female. Let's then, analysis the other three numerical fields:</span>
<span id="cb12-207"><a href="#cb12-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-210"><a href="#cb12-210" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-211"><a href="#cb12-211" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-column: page</span></span>
<span id="cb12-212"><a href="#cb12-212" aria-hidden="true" tabindex="-1"></a>sns.pairplot(df[[<span class="st">"Gender"</span>, <span class="st">"Age"</span>, <span class="st">"AnnualIncome"</span>, <span class="st">"SpendingScore"</span>]], hue<span class="op">=</span><span class="st">'Gender'</span>, aspect<span class="op">=</span><span class="fl">1.5</span>, height<span class="op">=</span><span class="fl">2.85</span>)</span>
<span id="cb12-213"><a href="#cb12-213" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb12-214"><a href="#cb12-214" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-215"><a href="#cb12-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-216"><a href="#cb12-216" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb12-217"><a href="#cb12-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-218"><a href="#cb12-218" aria-hidden="true" tabindex="-1"></a>The plot above separates the data into male and female group and display the male group data distribution in blue and female group in yellow.</span>
<span id="cb12-219"><a href="#cb12-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-220"><a href="#cb12-220" aria-hidden="true" tabindex="-1"></a>The diagonal represents the data distribution of the corresponding field, we can infer that:</span>
<span id="cb12-221"><a href="#cb12-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-222"><a href="#cb12-222" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The distribution of all these fields is not perfectly normal distributed, but has a bell shape with one peak and descents at both left and right side.</span>
<span id="cb12-223"><a href="#cb12-223" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>There is not significant subgroups if we only looks at one field.</span>
<span id="cb12-224"><a href="#cb12-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-225"><a href="#cb12-225" aria-hidden="true" tabindex="-1"></a>If we examine each field individually:</span>
<span id="cb12-226"><a href="#cb12-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-227"><a href="#cb12-227" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Age group near 30-40 has the highest density.</span>
<span id="cb12-228"><a href="#cb12-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-229"><a href="#cb12-229" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Most of customers have income 40-90k.</span>
<span id="cb12-230"><a href="#cb12-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-231"><a href="#cb12-231" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Most of customers have spending score around 50.</span>
<span id="cb12-232"><a href="#cb12-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-233"><a href="#cb12-233" aria-hidden="true" tabindex="-1"></a>If we check the subplots in pairs, we can find that there are no significant relationship between the pairs, except for the relationship between <span class="in">`Annual Income`</span> and <span class="in">`Spending Score`</span> , the data points are clearly divided into five subgroups.</span>
<span id="cb12-234"><a href="#cb12-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-235"><a href="#cb12-235" aria-hidden="true" tabindex="-1"></a><span class="fu">## Experiments</span></span>
<span id="cb12-236"><a href="#cb12-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-237"><a href="#cb12-237" aria-hidden="true" tabindex="-1"></a>We now start clustering analysis with K-Means algorithm, we will use the sklearn library.</span>
<span id="cb12-238"><a href="#cb12-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-241"><a href="#cb12-241" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-242"><a href="#cb12-242" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb12-243"><a href="#cb12-243" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb12-244"><a href="#cb12-244" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-245"><a href="#cb12-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-248"><a href="#cb12-248" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-249"><a href="#cb12-249" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'Age'</span>, <span class="st">'AnnualIncome'</span>, <span class="st">'SpendingScore'</span>]]</span>
<span id="cb12-250"><a href="#cb12-250" aria-hidden="true" tabindex="-1"></a>wcss<span class="op">=</span> []</span>
<span id="cb12-251"><a href="#cb12-251" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>):</span>
<span id="cb12-252"><a href="#cb12-252" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters <span class="op">=</span> k, n_init<span class="op">=</span><span class="st">'auto'</span>, init <span class="op">=</span> <span class="st">'k-means++'</span>)</span>
<span id="cb12-253"><a href="#cb12-253" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X)</span>
<span id="cb12-254"><a href="#cb12-254" aria-hidden="true" tabindex="-1"></a>    wcss.append(kmeans.inertia_)</span>
<span id="cb12-255"><a href="#cb12-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-256"><a href="#cb12-256" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb12-257"><a href="#cb12-257" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>), wcss, linewidth <span class="op">=</span> <span class="dv">2</span>,  marker<span class="op">=</span><span class="st">'*'</span>)</span>
<span id="cb12-258"><a href="#cb12-258" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Elbow Plot</span><span class="ch">\n</span><span class="st">'</span>, fontsize <span class="op">=</span> <span class="dv">20</span>)</span>
<span id="cb12-259"><a href="#cb12-259" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'K'</span>)</span>
<span id="cb12-260"><a href="#cb12-260" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'WCSS (Within-Cluster Sum of Square)'</span>)</span>
<span id="cb12-261"><a href="#cb12-261" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb12-262"><a href="#cb12-262" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-263"><a href="#cb12-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-264"><a href="#cb12-264" aria-hidden="true" tabindex="-1"></a>From the elbow plot, we can infer that K=6 could be the best number of cluster. Let's then use the number of clusters as 6 to train the K-Means and plot the distribution of predicted clusters using three dimension plot as follows:</span>
<span id="cb12-265"><a href="#cb12-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-268"><a href="#cb12-268" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-269"><a href="#cb12-269" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb12-270"><a href="#cb12-270" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb12-271"><a href="#cb12-271" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'Age'</span>, <span class="st">'AnnualIncome'</span>, <span class="st">'SpendingScore'</span>]]</span>
<span id="cb12-272"><a href="#cb12-272" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters <span class="op">=</span> <span class="dv">6</span>, n_init<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb12-273"><a href="#cb12-273" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> kmeans.fit_predict(X)</span>
<span id="cb12-274"><a href="#cb12-274" aria-hidden="true" tabindex="-1"></a>X[<span class="st">'label'</span>] <span class="op">=</span> clusters</span>
<span id="cb12-275"><a href="#cb12-275" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter_3d(X, x<span class="op">=</span><span class="st">"AnnualIncome"</span>, y<span class="op">=</span><span class="st">"SpendingScore"</span>, z<span class="op">=</span><span class="st">"Age"</span>,</span>
<span id="cb12-276"><a href="#cb12-276" aria-hidden="true" tabindex="-1"></a>                    color <span class="op">=</span> <span class="st">'label'</span>, size <span class="op">=</span> <span class="st">'label'</span>, width<span class="op">=</span><span class="dv">750</span>, height<span class="op">=</span><span class="dv">600</span>)</span>
<span id="cb12-277"><a href="#cb12-277" aria-hidden="true" tabindex="-1"></a>fig.show()</span>
<span id="cb12-278"><a href="#cb12-278" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-279"><a href="#cb12-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-280"><a href="#cb12-280" aria-hidden="true" tabindex="-1"></a>We are now going to use the DBSCAN to carry out the clustering analysis:</span>
<span id="cb12-281"><a href="#cb12-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-284"><a href="#cb12-284" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-285"><a href="#cb12-285" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb12-286"><a href="#cb12-286" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb12-287"><a href="#cb12-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-288"><a href="#cb12-288" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="dv">11</span>, min_samples<span class="op">=</span><span class="dv">6</span>).fit(X)</span>
<span id="cb12-289"><a href="#cb12-289" aria-hidden="true" tabindex="-1"></a>X[<span class="st">'label'</span>] <span class="op">=</span> clusters</span>
<span id="cb12-290"><a href="#cb12-290" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter_3d(X, x<span class="op">=</span><span class="st">"AnnualIncome"</span>, y<span class="op">=</span><span class="st">"SpendingScore"</span>, z<span class="op">=</span><span class="st">"Age"</span>,</span>
<span id="cb12-291"><a href="#cb12-291" aria-hidden="true" tabindex="-1"></a>                    color <span class="op">=</span> <span class="st">'label'</span>, size <span class="op">=</span> <span class="st">'label'</span>, width<span class="op">=</span><span class="dv">750</span>, height<span class="op">=</span><span class="dv">600</span>)</span>
<span id="cb12-292"><a href="#cb12-292" aria-hidden="true" tabindex="-1"></a>fig.show()</span>
<span id="cb12-293"><a href="#cb12-293" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-294"><a href="#cb12-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-295"><a href="#cb12-295" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb12-296"><a href="#cb12-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-297"><a href="#cb12-297" aria-hidden="true" tabindex="-1"></a>For DBSCAN we don't need to choose the hyper parameter K anymore, the algorithm will divide the dataset into 5 clusters automatically, which is different than the result of K-Means (6 clusters).</span>
<span id="cb12-298"><a href="#cb12-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-299"><a href="#cb12-299" aria-hidden="true" tabindex="-1"></a><span class="fu">## Discussion and Conclusion</span></span>
<span id="cb12-300"><a href="#cb12-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-301"><a href="#cb12-301" aria-hidden="true" tabindex="-1"></a>In this plot, we introduced the clustering algorithm as a classical type of unsupervised learning and applied two clustering techniques, namely K-Means and DBSCAN in the customer segmentation task. Our analysis and visualization shows the steps and differences between these two algorithms when applied in real world problems.</span>
<span id="cb12-302"><a href="#cb12-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-303"><a href="#cb12-303" aria-hidden="true" tabindex="-1"></a>Both the K-Means and DBSCAN aim to group similar data points together into clusters based on the data characteristics. They are both unsupervised learning techniques, meaning they don't rely on labeled training data and instead can discover patterns or structure within the data itself.</span>
<span id="cb12-304"><a href="#cb12-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-305"><a href="#cb12-305" aria-hidden="true" tabindex="-1"></a>While K-Means and DBSCAN share lots of traits in nature, here we wanted to mention some of the key differences between K-Means and DBSCAN:</span>
<span id="cb12-306"><a href="#cb12-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-307"><a href="#cb12-307" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Algorithm Type:**</span>
<span id="cb12-308"><a href="#cb12-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-309"><a href="#cb12-309" aria-hidden="true" tabindex="-1"></a>    **K-Means** is a centroid-based clustering algorithm. It aims to partition data into K clusters, where each cluster is represented by its centroid.</span>
<span id="cb12-310"><a href="#cb12-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-311"><a href="#cb12-311" aria-hidden="true" tabindex="-1"></a>    **DBSCAN** is a density-based clustering algorithm. It groups together data points that are close to each other and have a sufficient number of neighboring points.</span>
<span id="cb12-312"><a href="#cb12-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-313"><a href="#cb12-313" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Cluster Number:**</span>
<span id="cb12-314"><a href="#cb12-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-315"><a href="#cb12-315" aria-hidden="true" tabindex="-1"></a>    **K-Means** requires the user to specify the number of clusters (K) beforehand, and it assigns each data point to the nearest centroid.</span>
<span id="cb12-316"><a href="#cb12-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-317"><a href="#cb12-317" aria-hidden="true" tabindex="-1"></a>    **DBSCAN** does not require the user to specify the number of clusters. It automatically discovers clusters based on the density of data points.</span>
<span id="cb12-318"><a href="#cb12-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-319"><a href="#cb12-319" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Handling Noisy Data:**</span>
<span id="cb12-320"><a href="#cb12-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-321"><a href="#cb12-321" aria-hidden="true" tabindex="-1"></a>    **K-Means** sensitive to outliers and noise because it tries to assign all data points to a cluster, even if they do not belong to any clear cluster.</span>
<span id="cb12-322"><a href="#cb12-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-323"><a href="#cb12-323" aria-hidden="true" tabindex="-1"></a>    **DBSCAN** can identify and label outliers as noise, making it more robust to outliers and better at handling data with varying densities.</span>
<span id="cb12-324"><a href="#cb12-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-325"><a href="#cb12-325" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Parameter Sensitivity:**</span>
<span id="cb12-326"><a href="#cb12-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-327"><a href="#cb12-327" aria-hidden="true" tabindex="-1"></a>    **K-Means** is sensitive to the initial placement of centroids, and the final result may depend on the initial cluster centers.</span>
<span id="cb12-328"><a href="#cb12-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-329"><a href="#cb12-329" aria-hidden="true" tabindex="-1"></a>    **DBSCAN** is less sensitive to the choice of parameters, such as the density threshold and the minimum number of points required to form a cluster.</span>
<span id="cb12-330"><a href="#cb12-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-331"><a href="#cb12-331" aria-hidden="true" tabindex="-1"></a>In summary, K-Means is suitable for well-defined, spherical clusters with a predetermined number of clusters, while DBSCAN is more flexible, handling clusters of arbitrary shapes and automatically determining the number of clusters based on data density. The choice between them depends on the characteristics of the data and the desired properties of the clusters.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">Copyright 2023, Tong Zeng</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>