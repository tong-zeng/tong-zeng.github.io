<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tong Zeng">
<meta name="dcterms.date" content="2023-11-22">
<meta name="description" content="Train classification models for dog diseases prediction">

<title>Tong Zeng - Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../blogs/probability/index.html" rel="next">
<link href="../../blogs/regression/index.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Tong Zeng</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../#news" rel="" target="">
 <span class="menu-text">News</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../#publications" rel="" target="">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../blogs.html" rel="" target="" aria-current="page">
 <span class="menu-text">Blogs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/tong-zeng/tong-zeng.github.io" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/zeng_tong" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:tongzeng@vt.edu" rel="" target=""><i class="bi bi-envelope" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../blogs/clustering/index.html">Blogs</a></li><li class="breadcrumb-item"><a href="../../blogs/classification/index.html">Classification</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Classification</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          Train classification models for dog diseases prediction
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Classification</div>
                <div class="quarto-category">Deep Learning</div>
                <div class="quarto-category">Supervised Learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Tong Zeng </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 22, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blogs</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Blogs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/clustering/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/regression/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear and Nonlinear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/classification/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/probability/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability Theory and Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/welcome/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome to Machine Learning Blog</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../blogs/anomaly-detection/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">News</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../news/second-news/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Index</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../news/first-news/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Index</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Publications</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../publications/bib2yml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bib2yml</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul>
  <li><a href="#classification-as-cognitive-process" id="toc-classification-as-cognitive-process" class="nav-link" data-scroll-target="#classification-as-cognitive-process">Classification as Cognitive Process</a></li>
  <li><a href="#classification-in-machine-learning" id="toc-classification-in-machine-learning" class="nav-link" data-scroll-target="#classification-in-machine-learning">Classification in Machine Learning</a></li>
  <li><a href="#applications-in-pet-disease-prediction" id="toc-applications-in-pet-disease-prediction" class="nav-link" data-scroll-target="#applications-in-pet-disease-prediction">Applications in Pet Disease Prediction</a></li>
  </ul></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology">Methodology</a>
  <ul>
  <li><a href="#supervised-learning" id="toc-supervised-learning" class="nav-link" data-scroll-target="#supervised-learning"><strong>Supervised Learning</strong></a></li>
  <li><a href="#classification-vs-regression" id="toc-classification-vs-regression" class="nav-link" data-scroll-target="#classification-vs-regression"><strong>Classification vs Regression</strong></a></li>
  <li><a href="#binary-vs-multiclass-classification" id="toc-binary-vs-multiclass-classification" class="nav-link" data-scroll-target="#binary-vs-multiclass-classification">Binary vs Multiclass classification</a></li>
  <li><a href="#neural-network-for-multiclass-classification" id="toc-neural-network-for-multiclass-classification" class="nav-link" data-scroll-target="#neural-network-for-multiclass-classification">Neural Network for Multiclass Classification</a></li>
  <li><a href="#evaluation-metrics" id="toc-evaluation-metrics" class="nav-link" data-scroll-target="#evaluation-metrics">Evaluation Metrics</a></li>
  </ul></li>
  <li><a href="#datasets" id="toc-datasets" class="nav-link" data-scroll-target="#datasets">Datasets</a>
  <ul>
  <li><a href="#description" id="toc-description" class="nav-link" data-scroll-target="#description">Description</a></li>
  <li><a href="#data-analysis" id="toc-data-analysis" class="nav-link" data-scroll-target="#data-analysis">Data Analysis</a>
  <ul class="collapse">
  <li><a href="#descriptive-statistics" id="toc-descriptive-statistics" class="nav-link" data-scroll-target="#descriptive-statistics">Descriptive Statistics</a></li>
  <li><a href="#visualization" id="toc-visualization" class="nav-link" data-scroll-target="#visualization">Visualization</a></li>
  </ul></li>
  <li><a href="#data-preprocessing" id="toc-data-preprocessing" class="nav-link" data-scroll-target="#data-preprocessing">Data Preprocessing</a></li>
  </ul></li>
  <li><a href="#experiments" id="toc-experiments" class="nav-link" data-scroll-target="#experiments">Experiments</a>
  <ul>
  <li><a href="#network-implementation" id="toc-network-implementation" class="nav-link" data-scroll-target="#network-implementation">Network Implementation</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">Training</a></li>
  <li><a href="#performance-evaluation" id="toc-performance-evaluation" class="nav-link" data-scroll-target="#performance-evaluation"><strong>Performance Evaluation</strong></a></li>
  </ul></li>
  <li><a href="#discussion-and-conclusions" id="toc-discussion-and-conclusions" class="nav-link" data-scroll-target="#discussion-and-conclusions">Discussion and Conclusions</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/tong-zeng/tong-zeng.github.io/blob/main/blogs/classification/index.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<div class="column-screen">
<p><img src="img/classification.jpg" class="content-header-full-img img-fluid"></p>
<p style="text-align:right; font-size:0.66em">
</p><p>Image source: https://www.freepik.com</p>
<p></p>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<section id="classification-as-cognitive-process" class="level3">
<h3 class="anchored" data-anchor-id="classification-as-cognitive-process">Classification as Cognitive Process</h3>
<p>Classification, along with counting and sorting, is a fundamental cognitive process that plays a crucial role in human thinking and understanding. It involves categorizing and organizing information into distinct groups or classes based on shared characteristics, properties, or relationships.</p>
<p>Many children learn to classify objects even before they talk and walk. For example, one of the earliest games our kids played was distinguishing between different categories of colors and shapes.</p>
</section>
<section id="classification-in-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="classification-in-machine-learning">Classification in Machine Learning</h3>
<p>Like the importance of categorization in human thinking, classification is one of the core components of computer science and applications. It providing a systematic way to categorize and make predictions based on input data, thus, it is esstentially a cornerstone of many machine learning algorithms and applications, for example:</p>
<ul>
<li><p><strong>Automated Decision-Making:</strong></p>
<p>Classification algorithms automate decision-making by learning patterns from labeled training data. Once trained, these algorithms can classify new, unseen data into predefined categories. This is valuable in applications where quick and accurate decisions are required, such as in fraud detection, customer support, and autonomous systems.</p></li>
<li><p><strong>Personalization and Recommendation Systems:</strong></p>
<p>Classification algorithms are widely used in recommendation systems to personalize content and make product recommendations. They classify users into groups based on their preferences and behavior, enabling platforms to suggest items that are likely to be of interest.</p></li>
<li><p><strong>Natural Language Processing (NLP):</strong></p>
<p>In NLP, classification is used for sentiment analysis, topic categorization, and spam detection. Classification models can analyze and categorize text data, providing valuable insights for applications in customer feedback analysis, content moderation, and more.</p></li>
<li><p><strong>Healthcare and Diagnostics:</strong></p>
<p>In healthcare, classification algorithms assist in diagnostics and treatment planning. They can classify medical images, patient records, and genetic data to support medical professionals in making informed decisions.</p></li>
<li><p><strong>Fraud Detection and Security:</strong></p>
<p>Classification algorithms are critical in fraud detection systems. They can classify transactions or user behavior patterns to identify anomalies and potential fraudulent activities in real-world.</p></li>
</ul>
</section>
<section id="applications-in-pet-disease-prediction" class="level3">
<h3 class="anchored" data-anchor-id="applications-in-pet-disease-prediction">Applications in Pet Disease Prediction</h3>
<p>Given the fundamental position of classification algorithms in machine learning theory and applications, in this post, we will learn and demonstrate the basic principles and application process of classification algorithms with the prediction of pet diseases.</p>
<p>Throughout the entire span of human civilization, there is a long history of companionship with pets. There has been a constant quest to comprehend the well-being of our animals. Especially today, with the high development of social and material civilization, there has been a constant quest to comprehend the well-being of our animals. Given that the animals cannot verbally communicate with us and demonstrate their health status, the demand for veterinary medicine has been raised to understand pets’ health conditions based on their behaviors and symptoms.</p>
<p>For those who have a dog may notice their dog has some discomfort, which requires a diagnosis from hospitals. Some of the common diseases in dogs are quite severe and need immediate action, so users could enter the symptoms of the dog into our proposed model, and the model will predict what kind of disease the dog has and provide proper recommendations to take further action.</p>
<p>In this case, machine learning/deep learning provides a promising approach to making people learn about the health conditions of their pets with plenty of data collected through various sources<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
</section>
</section>
<section id="methodology" class="level2">
<h2 class="anchored" data-anchor-id="methodology">Methodology</h2>
<section id="supervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="supervised-learning"><strong>Supervised Learning</strong></h3>
<p>Before we jump into classification, let’s take a look at a learning process in our real life.</p>
<p>Imagine you’re tackling a new mathematical concept. After working on a problem, you might check the solutions to verify your correctness. As you gain confidence in solving a specific problem type, you’ll eventually refrain from consulting the answers and independently tackle new questions that come your way.</p>
<p>Similar to human learning process, in Supervised Learning, the model acquires knowledge through examples too. Together with the input variable, we feed the model with the corresponding accurate labels. During the training phase, the model examines the association between our data and the respective labels, enabling it to discover patterns within the dataset.</p>
<p>Classification is a form of supervised machine learning in which the model endeavors to forecast the accurate label for a provided input dataset. The model undergoes training with the training data in the classification process, followed by an evaluation using test data, before it is applied to make predictions on novel, unseen data. A simple example could be the email classification. By training some sort of algorithms with lots of emails which labelled as spam or ham (no spam), the models can predict whether a incoming email is spam or ham.</p>
</section>
<section id="classification-vs-regression" class="level3">
<h3 class="anchored" data-anchor-id="classification-vs-regression"><strong>Classification vs Regression</strong></h3>
<p>There two main types of supervised learning algorithms, namely classification and regression. Although, they share lots of common characteristics, they are very different from each other.</p>
<ul>
<li><p>The prediction assignment becomes a classification task when the target variable is distinct. An example of this is discerning the inherent sentiment within a given text.</p></li>
<li><p>The predictive assignment becomes a regression task when the target variable is continuous. For instance, forecasting a person’s salary based on factors such as their educational background, prior work experience, geographical location, etc.</p></li>
</ul>
</section>
<section id="binary-vs-multiclass-classification" class="level3">
<h3 class="anchored" data-anchor-id="binary-vs-multiclass-classification">Binary vs Multiclass classification</h3>
<p>There are two main types of classifications:</p>
<ul>
<li><p>Binary classification involves categorizing data into two distinct classes or categories. An example can be predicting whether a credit card transaction is fraudulent or not, or determining if a patient has a particular medical condition.</p></li>
<li><p>Multiclass classification deals with sorting data into more than two classes or categories. An example can be recognizing handwritten digits (0-9), classifying different species of animals, or identifying the genre of a book.</p></li>
</ul>
<p>While some algorithms can be adapted for both tasks, certain algorithms are specifically designed for one type of classification. For instance, logistic regression is commonly used for binary classification, while decision trees and neural networks can handle both binary and multiclass scenarios.</p>
<p>In this post, we’re going to use the neural networks to conduct a multiclass classification task, specifically, predict whether a pet has one of the given 12 diseases.</p>
</section>
<section id="neural-network-for-multiclass-classification" class="level3">
<h3 class="anchored" data-anchor-id="neural-network-for-multiclass-classification">Neural Network for Multiclass Classification</h3>
<p>When apply neural network to solve a problem, design the network architecture and choice the right loss function are the most important task. In this section, we’re going to introduce the loss function but leave the network architecture design for next section.</p>
<p>For multiclass classification in a neural network, a common choice for the loss function is the <strong>Categorical Cross Entropy Loss</strong>, the equation is as follows:</p>
<p><span class="math display">
-\sum_{i=1}^N\sum_{c=1}^Cw_c\log\frac{exp(x_{n,c})}{\sum_{i=1}^Cexp(x_{n,i})}y_{n,c}
</span></p>
<p>where <span class="math inline">x</span> is the input, <span class="math inline">y</span> is the target, <span class="math inline">w</span> is the weight, <span class="math inline">C</span> is the number of classes, and <span class="math inline">N</span> denotes the number of training samples in the minibatch.</p>
<p>This equation reflects the negative log-likelihood of the correct class in a classification task, penalizing the model more when it is confidently wrong about a particular class. The softmax operation in the denominator ensures that the values in the exponential term form a valid probability distribution over all classes. The logarithm in the loss function penalizes deviations from the true class probabilities.</p>
</section>
<section id="evaluation-metrics" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-metrics">Evaluation Metrics</h3>
<p>For classification problems, the precision, recall and <span class="math inline">F_1</span> are most common used indicators for model performance evaluation.</p>
<p>According to wikipedia, the definition of these metrics as following<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>:</p>
<p><strong>Precision</strong> is the fraction of relevant instances among the retrieved instances. Written as a formula:</p>
<p><span class="math display">
{\displaystyle {\text{Precision}}={\frac {\text{Relevant retrieved instances}}{\text{All retrieved instances}}}}
</span></p>
<p><strong>Recall</strong> is the fraction of relevant instances that were retrieved. Written as a formula:</p>
<p><span class="math display">
{\displaystyle {\text{Recall}}={\frac {\text{Relevant retrieved instances}}{\text{All relevant instances}}}}
</span></p>
<p><span class="math inline">F_1</span> score is the harmonic mean of the precision and recall. Written as a formula:</p>
<p><span class="math display">
{\displaystyle F_{1}={\frac {2}{\mathrm {recall} ^{-1}+\mathrm {precision} ^{-1}}}=2{\frac {\mathrm {precision} \cdot \mathrm {recall} }{\mathrm {precision} +\mathrm {recall} }}={\frac {2\mathrm {tp} }{2\mathrm {tp} +\mathrm {fp} +\mathrm {fn} }}}
</span></p>
<p>where <span class="math inline">tp</span> is the true positives, <span class="math inline">fp</span> is the false positive, and <span class="math inline">fn</span> is the false negative.</p>
</section>
</section>
<section id="datasets" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="datasets">Datasets</h2>
<section id="description" class="level3">
<h3 class="anchored" data-anchor-id="description">Description</h3>
<p>In this post, we will use a dog disease dataset<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> containing 24000 entities with 17 symptoms and 12 diseases to conduct experiments. The dataset is in csv format, the symptoms and diseases are presented in text format, thus, we need to further convert the textual information into numerical representations. However, due to the length of this post, we’re not able to cover the feature engineering processing here, instead, we will focus on the data analysis and modeling process, which would be introduced in the next section.</p>
</section>
<section id="data-analysis" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="data-analysis">Data Analysis</h3>
<p>We first load all the python libraries we might use in the analysis:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score, accuracy_score, recall_score, precision_score</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, load the prepossessed (convert the textual data into numerical representation) csv file into pandas <code>DataFrame</code>:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/pre_processed.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s take a look at the first 5 rows:</p>
<div class="cell page-columns page-full" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display column-page" data-execution_count="3">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Unnamed: 0</th>
<th data-quarto-table-cell-role="th">Fever</th>
<th data-quarto-table-cell-role="th">Nasal Discharge</th>
<th data-quarto-table-cell-role="th">Loss of appetite</th>
<th data-quarto-table-cell-role="th">Weight Loss</th>
<th data-quarto-table-cell-role="th">Lameness</th>
<th data-quarto-table-cell-role="th">Breathing Difficulty</th>
<th data-quarto-table-cell-role="th">Swollen Lymph nodes</th>
<th data-quarto-table-cell-role="th">Lethargy</th>
<th data-quarto-table-cell-role="th">Depression</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">Hepatitis</th>
<th data-quarto-table-cell-role="th">Tetanus</th>
<th data-quarto-table-cell-role="th">Chronic kidney Disease</th>
<th data-quarto-table-cell-role="th">Diabetes</th>
<th data-quarto-table-cell-role="th">Gastrointestinal Disease</th>
<th data-quarto-table-cell-role="th">Allergies</th>
<th data-quarto-table-cell-role="th">Gingitivis</th>
<th data-quarto-table-cell-role="th">Cancers</th>
<th data-quarto-table-cell-role="th">Skin Rashes</th>
<th data-quarto-table-cell-role="th">Disease</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Tick fever</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Tick fever</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Tick fever</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>3</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Tick fever</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>4</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>Tick fever</td>
</tr>
</tbody>
</table>

<p>5 rows × 100 columns</p>
</div>
</div>
</div>
<p><br></p>
<p>As we can see in the table above, there are 98 features, and all the features are categorical which represents whether the dog has a certain symptom. The column <code>Disease</code> is the type of disease we want to predict.</p>
<section id="descriptive-statistics" class="level4">
<h4 class="anchored" data-anchor-id="descriptive-statistics">Descriptive Statistics</h4>
<p>We now take a look at the descriptive statistics of the dataset:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Unnamed: 0</th>
<th data-quarto-table-cell-role="th">Fever</th>
<th data-quarto-table-cell-role="th">Nasal Discharge</th>
<th data-quarto-table-cell-role="th">Loss of appetite</th>
<th data-quarto-table-cell-role="th">Weight Loss</th>
<th data-quarto-table-cell-role="th">Lameness</th>
<th data-quarto-table-cell-role="th">Breathing Difficulty</th>
<th data-quarto-table-cell-role="th">Swollen Lymph nodes</th>
<th data-quarto-table-cell-role="th">Lethargy</th>
<th data-quarto-table-cell-role="th">Depression</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">Parvovirus</th>
<th data-quarto-table-cell-role="th">Hepatitis</th>
<th data-quarto-table-cell-role="th">Tetanus</th>
<th data-quarto-table-cell-role="th">Chronic kidney Disease</th>
<th data-quarto-table-cell-role="th">Diabetes</th>
<th data-quarto-table-cell-role="th">Gastrointestinal Disease</th>
<th data-quarto-table-cell-role="th">Allergies</th>
<th data-quarto-table-cell-role="th">Gingitivis</th>
<th data-quarto-table-cell-role="th">Cancers</th>
<th data-quarto-table-cell-role="th">Skin Rashes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>...</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
<td>23999.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>11999.000000</td>
<td>0.104129</td>
<td>0.106171</td>
<td>0.282178</td>
<td>0.142214</td>
<td>0.072378</td>
<td>0.146839</td>
<td>0.035918</td>
<td>0.286887</td>
<td>0.138631</td>
<td>...</td>
<td>0.083337</td>
<td>0.083295</td>
<td>0.083337</td>
<td>0.083337</td>
<td>0.083337</td>
<td>0.083337</td>
<td>0.083337</td>
<td>0.083337</td>
<td>0.083337</td>
<td>0.083337</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>6928.058891</td>
<td>0.305435</td>
<td>0.308063</td>
<td>0.450069</td>
<td>0.349277</td>
<td>0.259118</td>
<td>0.353953</td>
<td>0.186090</td>
<td>0.452318</td>
<td>0.345568</td>
<td>...</td>
<td>0.276396</td>
<td>0.276334</td>
<td>0.276396</td>
<td>0.276396</td>
<td>0.276396</td>
<td>0.276396</td>
<td>0.276396</td>
<td>0.276396</td>
<td>0.276396</td>
<td>0.276396</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>5999.500000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>11999.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>17998.500000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>23998.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>...</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

<p>8 rows × 99 columns</p>
</div>
</div>
</div>
<p>From the table above, we can infer that the features are very sparse with most of them are zeros, this requires the model have the ability to effectively extract information from high sparse data.</p>
</section>
<section id="visualization" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="visualization">Visualization</h4>
<p>We wanted to examine the dependent variable first, this could be done by count how many records for each disease. We plot the histogram as follows:</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>sns.histplot(df[<span class="st">'Disease'</span>])</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">75</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-6-output-1.png" width="602" height="577"></p>
</div>
</div>
<p>From the figure above, we can see that there are 12 diseases and there are equally distributed.</p>
<p>It would be interesting to show the distribution of the symptoms, we thus plots a word cloud of the symptom names as following:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>count_series <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">"Unnamed: 0"</span>, <span class="st">"Disease"</span>]).<span class="bu">sum</span>(axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>count_df <span class="op">=</span> count_series.to_frame().reset_index().rename(columns <span class="op">=</span> {<span class="st">"index"</span>:<span class="st">"symptom"</span>, <span class="dv">0</span>:<span class="st">"frequency"</span>})</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>freq_list <span class="op">=</span> {}</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(count_df)):</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    freq_list[count_df[<span class="st">'symptom'</span>].iloc[index]] <span class="op">=</span> count_df[<span class="st">'frequency'</span>].iloc[index]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell page-columns page-full" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>wc <span class="op">=</span> WordCloud(width<span class="op">=</span><span class="dv">3840</span>, height<span class="op">=</span><span class="dv">2160</span>).generate_from_frequencies(freq_list)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">10</span>))</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.imshow(wc, interpolation<span class="op">=</span><span class="st">"bilinear"</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display column-page">
<p><img src="index_files/figure-html/cell-8-output-1.png" width="1333" height="758"></p>
</div>
</div>
</section>
</section>
<section id="data-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing">Data Preprocessing</h3>
<p>We then, further convert the pandas dataframe to the format fits the model training requirements. It mainly includes: separate the features and labels into different numpy array; split the data into train, validation and test set.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop([<span class="st">'Unnamed: 0'</span>, <span class="st">'Disease'</span>,<span class="st">'Tick fever'</span>,<span class="st">'Distemper'</span>, <span class="st">'Parvovirus'</span>,</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>               <span class="st">'Hepatitis'</span>, <span class="st">'Tetanus'</span>, <span class="st">'Chronic kidney Disease'</span>, <span class="st">'Diabetes'</span>,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>               <span class="st">'Gastrointestinal Disease'</span>, <span class="st">'Allergies'</span>, <span class="st">'Gingitivis'</span>, <span class="st">'Cancers'</span>,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>               <span class="st">'Skin Rashes'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[[<span class="st">'Tick fever'</span>, <span class="st">'Distemper'</span>, <span class="st">'Parvovirus'</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>          <span class="st">'Hepatitis'</span>, <span class="st">'Tetanus'</span>, <span class="st">'Chronic kidney Disease'</span>, <span class="st">'Diabetes'</span>,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>          <span class="st">'Gastrointestinal Disease'</span>, <span class="st">'Allergies'</span>, <span class="st">'Gingitivis'</span>, <span class="st">'Cancers'</span>,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>          <span class="st">'Skin Rashes'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>X_train_val, X_test, y_train_val, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">66</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(X_train_val, y_train_val, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">66</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show how many data in each set</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Length of train set:"</span>, <span class="bu">len</span>(X_train))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Length of validation set:"</span>, <span class="bu">len</span>(X_val))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Length of test set:"</span>, <span class="bu">len</span>(X_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Length of train set: 14399
Length of validation set: 4800
Length of test set: 4800</code></pre>
</div>
</div>
</section>
</section>
<section id="experiments" class="level2">
<h2 class="anchored" data-anchor-id="experiments">Experiments</h2>
<p>We will use the pytorch framework to build and train a neural network, thus, we need to use the pytorch ecosystem to format the dataset, build the network architecture, load and feed dataset model, etc. We will introduce all these steps in this section.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="network-implementation" class="level3">
<h3 class="anchored" data-anchor-id="network-implementation">Network Implementation</h3>
<p>Wrap the dataset into pytorch <code>Dataset</code> format:</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DogSymptomsDataset(Dataset):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, Y):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.X <span class="op">=</span> torch.tensor(X.values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.Y <span class="op">=</span> torch.tensor(Y.values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.X)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="va">self</span>.X[index], <span class="va">self</span>.Y[index])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Initialize the <code>DogSymptomsDataset</code> and <code>DataLoader</code> for the train, validation and test data.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> DogSymptomsDataset(X_train, y_train)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>val_ds <span class="op">=</span> DogSymptomsDataset(X_val, y_val)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>test_ds <span class="op">=</span> DogSymptomsDataset(X_test, y_test)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>trainloader <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>valloader <span class="op">=</span> DataLoader(val_ds, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>testloader <span class="op">=</span> DataLoader(test_ds, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The network structure mainly consist of several feedforward and dropoutas layer, we use <code>ReLU</code> as the activation function and implement the forward function for passing the data through network. The pytorch framework will take care of error back-propagation.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP(nn.Module):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>(MLP, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">86</span>, <span class="dv">256</span>),</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(),</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">256</span>, <span class="dv">128</span>),</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(),</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">128</span>, <span class="dv">64</span>),</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(),</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">64</span>, <span class="dv">12</span>),</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># nn.Softmax()</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span>.layers(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="training" class="level3">
<h3 class="anchored" data-anchor-id="training">Training</h3>
<p>The last missing puzzle now is implement the train and validation function which manages the whole training and validation process.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f1(pred_list, label_list):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  pred_all <span class="op">=</span> torch.cat(pred_list)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  label_all <span class="op">=</span> torch.cat(label_list)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  y_pred_classes <span class="op">=</span> np.argmax(pred_all.detach().numpy(), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  y_true_classes <span class="op">=</span> np.argmax(label_all.detach().numpy(), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  _f1 <span class="op">=</span> f1_score(y_true_classes, y_pred_classes, average<span class="op">=</span><span class="st">'weighted'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> _f1</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> validation(model):</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>  pred_list <span class="op">=</span> []</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>  label_list <span class="op">=</span> []</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  loss_list <span class="op">=</span> []</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>  loss_function <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(valloader):</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Get inputs</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>      inputs, targets <span class="op">=</span> data</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Perform forward pass</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>      outputs <span class="op">=</span> model(inputs)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>      loss <span class="op">=</span> loss_function(outputs, targets)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>      loss_list.append(loss.item())</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>      pred_list.append(outputs)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>      label_list.append(targets)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>  avg_loss <span class="op">=</span> <span class="bu">sum</span>(loss_list)<span class="op">/</span><span class="bu">len</span>(valloader)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>  avg_f1 <span class="op">=</span> f1(pred_list, label_list)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (avg_loss, avg_f1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train():</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  mlp <span class="op">=</span> MLP()</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  torch.manual_seed(<span class="dv">666</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  trainloader <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  loss_function <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  optimizer <span class="op">=</span> torch.optim.Adam(mlp.parameters(), lr<span class="op">=</span><span class="fl">2e-4</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  train_loss_list <span class="op">=</span> []</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  val_loss_list <span class="op">=</span> []</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  train_f1_list<span class="op">=</span>[]</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  val_f1_list<span class="op">=</span>[]</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print epoch</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Starting epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    loss_epoch_list <span class="op">=</span> []</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    pred_list <span class="op">=</span> []</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    label_list <span class="op">=</span> []</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    current_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate over the DataLoader for training data</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(trainloader):</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Get inputs</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>      inputs, targets <span class="op">=</span> data</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Zero the gradients</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>      optimizer.zero_grad()</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Perform forward pass</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>      outputs <span class="op">=</span> mlp(inputs)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>      pred_list.append(outputs)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>      label_list.append(targets)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Compute loss</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>      loss <span class="op">=</span> loss_function(outputs, targets)</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Perform backward pass</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>      loss.backward()</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Perform optimizationd</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>      optimizer.step()</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Print statistics</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>      loss_item <span class="op">=</span> loss.item()</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>      loss_epoch_list.append(loss_item)</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>      current_loss <span class="op">+=</span> loss_item</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (i <span class="op">!=</span><span class="dv">0</span>) <span class="kw">and</span> (i <span class="op">%</span> <span class="dv">50</span> <span class="op">==</span> <span class="dv">0</span>):</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>          train_loss_list.append(current_loss<span class="op">/</span><span class="dv">50</span>)</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>          train_f1 <span class="op">=</span> f1([outputs], [targets])</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>          train_f1_list.append(train_f1)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>          val_loss, val_f1 <span class="op">=</span> validation(mlp)</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>          val_loss_list.append(val_loss)</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>          val_f1_list.append(val_f1)</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="st">'Loss after mini-batch </span><span class="sc">%5d</span><span class="st">: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>                (i, current_loss<span class="op">/</span><span class="dv">50</span>))</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>          current_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">'Training process has finished.'</span>)</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (mlp, train_loss_list,val_loss_list,train_f1_list,val_f1_list)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now start the training process:</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>model, train_loss_list,val_loss_list,train_f1_list,val_f1_list <span class="op">=</span> train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="performance-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="performance-evaluation"><strong>Performance Evaluation</strong></h3>
<p>We are now have already completed the model training, it is time to use the model to make predict on our test set, then, calculate the precision, recall and <span class="math inline">F_1</span> score base on the predicted disease and the ground truth label.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test(model):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  pred_list <span class="op">=</span> []</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  label_list <span class="op">=</span> []</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(testloader):</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Get inputs</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>      inputs, targets <span class="op">=</span> data</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Perform forward pass</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>      outputs <span class="op">=</span> model(inputs)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>      pred_list.append(outputs)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>      label_list.append(targets)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>  pred_all <span class="op">=</span> torch.cat(pred_list)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>  label_all <span class="op">=</span> torch.cat(label_list)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>  y_pred_classes <span class="op">=</span> np.argmax(pred_all.detach().numpy(), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>  y_true_classes <span class="op">=</span> np.argmax(label_all.detach().numpy(), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>  avg_f1 <span class="op">=</span> f1(pred_list, label_list)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (avg_f1, y_pred_classes, y_true_classes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>avg_f1, y_pred_classes, y_true_classes <span class="op">=</span> test(model)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>report <span class="op">=</span> classification_report(y_true_classes, y_pred_classes,output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>report_labeled<span class="op">=</span>{}</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>dnames <span class="op">=</span> df[<span class="st">'Disease'</span>].unique().tolist()</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(dnames)):</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  report_labeled[dnames[i]] <span class="op">=</span> report[<span class="bu">str</span>(i)]</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>report_labeled[<span class="st">'macro avg'</span>] <span class="op">=</span> report[<span class="st">'macro avg'</span>]</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>report_labeled[<span class="st">'weighted avg'</span>] <span class="op">=</span> report[<span class="st">'weighted avg'</span>]</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(report_labeled).T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">precision</th>
<th data-quarto-table-cell-role="th">recall</th>
<th data-quarto-table-cell-role="th">f1-score</th>
<th data-quarto-table-cell-role="th">support</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Tick fever</td>
<td>0.995062</td>
<td>0.987745</td>
<td>0.991390</td>
<td>408.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Distemper</td>
<td>0.992481</td>
<td>0.997481</td>
<td>0.994975</td>
<td>397.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Parvovirus</td>
<td>0.992736</td>
<td>0.997567</td>
<td>0.995146</td>
<td>411.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Hepatitis</td>
<td>0.997455</td>
<td>0.997455</td>
<td>0.997455</td>
<td>393.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Tetanus</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>398.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Chronic kidney Disease</td>
<td>0.997468</td>
<td>0.997468</td>
<td>0.997468</td>
<td>395.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Diabetes</td>
<td>0.994898</td>
<td>1.000000</td>
<td>0.997442</td>
<td>390.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Gastrointestinal Disease</td>
<td>1.000000</td>
<td>0.997519</td>
<td>0.998758</td>
<td>403.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Allergies</td>
<td>1.000000</td>
<td>0.995074</td>
<td>0.997531</td>
<td>406.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Gingitivis</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>385.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Cancers</td>
<td>0.995122</td>
<td>0.995122</td>
<td>0.995122</td>
<td>410.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Skin Rashes</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>404.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">macro avg</td>
<td>0.997102</td>
<td>0.997119</td>
<td>0.997107</td>
<td>4800.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">weighted avg</td>
<td>0.997089</td>
<td>0.997083</td>
<td>0.997083</td>
<td>4800.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>As we can see from the table above, our neural network predicts the 12 disease at very high precision, recall and <span class="math inline">F_1</span> scores.</p>
<p>We can also plot the confusion matrix to have better understanding of the prediction performance:</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> metrics.confusion_matrix(y_true_classes, y_pred_classes)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>df_cm <span class="op">=</span> pd.DataFrame(conf_matrix, index<span class="op">=</span>df[<span class="st">'Disease'</span>].unique(), columns<span class="op">=</span>df[<span class="st">'Disease'</span>].unique())</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'F1-score% ='</span>, f1_score(y_true_classes, y_pred_classes, average<span class="op">=</span><span class="st">'weighted'</span>)<span class="op">*</span><span class="dv">100</span>, <span class="st">'|'</span>,</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Accuracy% ='</span>, accuracy_score(y_true_classes, y_pred_classes)<span class="op">*</span><span class="dv">100</span>, <span class="st">'|'</span>,</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Recall% ='</span>, recall_score(y_true_classes, y_pred_classes, average<span class="op">=</span><span class="st">'weighted'</span>)<span class="op">*</span><span class="dv">100</span>, <span class="st">'|'</span>,</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Precision% ='</span>, precision_score(y_true_classes, y_pred_classes, average<span class="op">=</span><span class="st">'weighted'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>,<span class="dv">6</span>))</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>sns.heatmap(df_cm)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>F1-score% = 99.70825899284065 | Accuracy% = 99.70833333333333 | Recall% = 99.70833333333333 | Precision% = 99.70885322303832</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-21-output-2.png" width="754" height="635"></p>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>ax.matshow(conf_matrix, cmap<span class="op">=</span>plt.cm.Blues, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(conf_matrix.shape[<span class="dv">0</span>]):</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(conf_matrix.shape[<span class="dv">1</span>]):</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        ax.text(x<span class="op">=</span>j, y<span class="op">=</span>i,s<span class="op">=</span>conf_matrix[i, j], va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'center'</span>, size<span class="op">=</span><span class="st">'xx-large'</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predictions'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Actuals'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix of ANN Model'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-22-output-1.png" width="666" height="693"></p>
</div>
</div>
<p>Further, we can visualize the the <code>loss</code> of the train and validation split during the whole training process, which is shown as follows:</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>train_loss <span class="op">=</span> train_loss_list</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> val_loss_list</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>train_acc <span class="op">=</span> train_f1_list</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>val_acc <span class="op">=</span> val_f1_list</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw loss plot</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>plt.plot(train_loss, label<span class="op">=</span><span class="st">'Training Loss'</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>plt.plot(val_loss, label<span class="op">=</span><span class="st">'Validation Loss'</span>)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Batch'</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Loss'</span>)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-23-output-1.png" width="663" height="671"></p>
</div>
</div>
<p>The <span class="math inline">F_1</span> score of the train and test split during the whole training process is shown as follows:</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw accuracy plot</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>plt.plot(train_acc, label<span class="op">=</span><span class="st">'Training Accuracy'</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>plt.plot(val_acc, label<span class="op">=</span><span class="st">'Validation Accuracy'</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Batch'</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Accuracy'</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-24-output-1.png" width="668" height="671"></p>
</div>
</div>
</section>
</section>
<section id="discussion-and-conclusions" class="level2">
<h2 class="anchored" data-anchor-id="discussion-and-conclusions">Discussion and Conclusions</h2>
<p>In this blog, we begin by introducing the basic concepts of classification and its importance in computer science and applications. Secondly, we introduce the background knowledge about classification such as supervised learning, the connection and difference between classification and regression, and the difference between binary and multiclass classification. After introducing the pet disease prediction use case, we provide a detailed description of the use of neural networks in multiclass classification, as well as the related evaluation indexes.</p>
<p>After a detailed analysis of the data, we modeled the data using neural networks, and carried out an evaluation of the trained model. The experiment result shows our model achieved <span class="math inline">F_1</span> score of over 99% in all 12 pet disease predictions.</p>
<p>While neural networks are powerful tools for many classification tasks, they are not without their shortcomings. Here are some common limitations and challenges associated with using neural networks for classification:</p>
<ul>
<li><p><strong>Data Requirements:</strong></p>
<p>Neural networks often require large amounts of labeled data for training to generalize well. In situations where labeled data is scarce, the model’s performance may suffer.</p></li>
<li><p><strong>Computational Complexity:</strong></p>
<p>Training deep neural networks can be computationally intensive, especially with large datasets and complex architectures. This can be a limitation for applications with resource constraints.</p></li>
<li><p><strong>Interpretability:</strong> Neural networks, particularly deep architectures, are often considered as “black-box” models, making it challenging to interpret and understand the decision-making process. Lack of interpretability can be a concern in fields where transparency and explainability are crucial.</p></li>
</ul>
<p>Despite these challenges, ongoing research and advancements in deep learning aim to address these limitations and enhance the performance, robustness, and interpretability of neural networks. Let’s keep learning!</p>


<!-- -->

</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Hwang, S., Shin, H. K., Park, J. M., Kwon, B., &amp; Kang, M. G. (2022). Classification of dog skin diseases using deep learning with images captured from multispectral imaging devices. Molecular &amp; Cellular Toxicology, 18(3), 299-309.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Debes, C., Wowra, J., Manzoor, S. et al.&nbsp;Predicting health outcomes in dogs using insurance claims data. Sci Rep 13, 9122 (2023). https://doi.org/10.1038/s41598-023-36023-5<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a href="https://en.wikipedia.org/wiki/Precision_and_recall" class="uri">https://en.wikipedia.org/wiki/Precision_and_recall</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a href="https://en.wikipedia.org/wiki/F-score" class="uri">https://en.wikipedia.org/wiki/F-score</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><a href="https://github.com/1zuu/Doggy-Disease-Detection/data" class="uri">https://github.com/1zuu/Doggy-Disease-Detection/</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../blogs/regression/index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Linear and Nonlinear Regression</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../blogs/probability/index.html" class="pagination-link">
        <span class="nav-page-text">Probability Theory and Random Variables</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb26" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Classification"</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Tong Zeng"</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-11-22"</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Classification, Deep Learning, Supervised Learning]</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "img/classification.jpg"</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> Train classification models for dog diseases prediction</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>::: column-screen</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="al">![](img/classification.jpg)</span>{.content-header-full-img}</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;p</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-align:right; font-size:0.66em"</span><span class="kw">&gt;</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>Image source: https://www.freepik.com</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/p&gt;</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a><span class="fu">### Classification as Cognitive Process</span></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>Classification, along with counting and sorting, is a fundamental cognitive process that plays a crucial role in human thinking and understanding. It involves categorizing and organizing information into distinct groups or classes based on shared characteristics, properties, or relationships.</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>Many children learn to classify objects even before they talk and walk. For example, one of the earliest games our kids played was distinguishing between different categories of colors and shapes.</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a><span class="fu">### Classification in Machine Learning</span></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>Like the importance of categorization in human thinking, classification is one of the core components of computer science and applications. It providing a systematic way to categorize and make predictions based on input data, thus, it is esstentially a cornerstone of many machine learning algorithms and applications, for example:</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Automated Decision-Making:**</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>    Classification algorithms automate decision-making by learning patterns from labeled training data. Once trained, these algorithms can classify new, unseen data into predefined categories. This is valuable in applications where quick and accurate decisions are required, such as in fraud detection, customer support, and autonomous systems.</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Personalization and Recommendation Systems:**</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>    Classification algorithms are widely used in recommendation systems to personalize content and make product recommendations. They classify users into groups based on their preferences and behavior, enabling platforms to suggest items that are likely to be of interest.</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Natural Language Processing (NLP):**</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>    In NLP, classification is used for sentiment analysis, topic categorization, and spam detection. Classification models can analyze and categorize text data, providing valuable insights for applications in customer feedback analysis, content moderation, and more.</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Healthcare and Diagnostics:**</span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a>    In healthcare, classification algorithms assist in diagnostics and treatment planning. They can classify medical images, patient records, and genetic data to support medical professionals in making informed decisions.</span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Fraud Detection and Security:**</span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a>    Classification algorithms are critical in fraud detection systems. They can classify transactions or user behavior patterns to identify anomalies and potential fraudulent activities in real-world.</span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a><span class="fu">### Applications in Pet Disease Prediction</span></span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a>Given the fundamental position of classification algorithms in machine learning theory and applications, in this post, we will learn and demonstrate the basic principles and application process of classification algorithms with the prediction of pet diseases.</span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a>Throughout the entire span of human civilization, there is a long history of companionship with pets. There has been a constant quest to comprehend the well-being of our animals. Especially today, with the high development of social and material civilization, there has been a constant quest to comprehend the well-being of our animals. Given that the animals cannot verbally communicate with us and demonstrate their health status, the demand for veterinary medicine has been raised to understand pets' health conditions based on their behaviors and symptoms.</span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a>For those who have a dog may notice their dog has some discomfort, which requires a diagnosis from hospitals. Some of the common diseases in dogs are quite severe and need immediate action, so users could enter the symptoms of the dog into our proposed model, and the model will predict what kind of disease the dog has and provide proper recommendations to take further action.</span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a>In this case, machine learning/deep learning provides a promising approach to making people learn about the health conditions of their pets with plenty of data collected through various sources<span class="ot">[^1]</span> <span class="ot">[^2]</span>.</span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: </span>Hwang, S., Shin, H. K., Park, J. M., Kwon, B., &amp; Kang, M. G. (2022). Classification of dog skin diseases using deep learning with images captured from multispectral imaging devices. Molecular &amp; Cellular Toxicology, 18(3), 299-309.</span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a><span class="ot">[^2]: </span>Debes, C., Wowra, J., Manzoor, S. et al. Predicting health outcomes in dogs using insurance claims data. Sci Rep 13, 9122 (2023). https://doi.org/10.1038/s41598-023-36023-5</span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a><span class="fu">## Methodology</span></span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Supervised Learning**</span></span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a>Before we jump into classification, let's take a look at a learning process in our real life.</span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a>Imagine you're tackling a new mathematical concept. After working on a problem, you might check the solutions to verify your correctness. As you gain confidence in solving a specific problem type, you'll eventually refrain from consulting the answers and independently tackle new questions that come your way.</span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a>Similar to human learning process, in Supervised Learning, the model acquires knowledge through examples too. Together with the input variable, we feed the model with the corresponding accurate labels. During the training phase, the model examines the association between our data and the respective labels, enabling it to discover patterns within the dataset.</span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a>Classification is a form of supervised machine learning in which the model endeavors to forecast the accurate label for a provided input dataset. The model undergoes training with the training data in the classification process, followed by an evaluation using test data, before it is applied to make predictions on novel, unseen data. A simple example could be the email classification. By training some sort of algorithms with lots of emails which labelled as spam or ham (no spam), the models can predict whether a incoming email is spam or ham.</span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Classification vs Regression**</span></span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a>There two main types of supervised learning algorithms, namely classification and regression. Although, they share lots of common characteristics, they are very different from each other.</span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The prediction assignment becomes a classification task when the target variable is distinct. An example of this is discerning the inherent sentiment within a given text.</span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-84"><a href="#cb26-84" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The predictive assignment becomes a regression task when the target variable is continuous. For instance, forecasting a person's salary based on factors such as their educational background, prior work experience, geographical location, etc.</span>
<span id="cb26-85"><a href="#cb26-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a><span class="fu">### Binary vs Multiclass classification</span></span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-88"><a href="#cb26-88" aria-hidden="true" tabindex="-1"></a>There are two main types of classifications:</span>
<span id="cb26-89"><a href="#cb26-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Binary classification involves categorizing data into two distinct classes or categories. An example can be predicting whether a credit card transaction is fraudulent or not, or determining if a patient has a particular medical condition.</span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Multiclass classification deals with sorting data into more than two classes or categories. An example can be recognizing handwritten digits (0-9), classifying different species of animals, or identifying the genre of a book.</span>
<span id="cb26-93"><a href="#cb26-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-94"><a href="#cb26-94" aria-hidden="true" tabindex="-1"></a>While some algorithms can be adapted for both tasks, certain algorithms are specifically designed for one type of classification. For instance, logistic regression is commonly used for binary classification, while decision trees and neural networks can handle both binary and multiclass scenarios.</span>
<span id="cb26-95"><a href="#cb26-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-96"><a href="#cb26-96" aria-hidden="true" tabindex="-1"></a>In this post, we're going to use the neural networks to conduct a multiclass classification task, specifically, predict whether a pet has one of the given 12 diseases.</span>
<span id="cb26-97"><a href="#cb26-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-98"><a href="#cb26-98" aria-hidden="true" tabindex="-1"></a><span class="fu">### Neural Network for Multiclass Classification</span></span>
<span id="cb26-99"><a href="#cb26-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-100"><a href="#cb26-100" aria-hidden="true" tabindex="-1"></a>When apply neural network to solve a problem, design the network architecture and choice the right loss function are the most important task. In this section, we're going to introduce the loss function but leave the network architecture design for next section.</span>
<span id="cb26-101"><a href="#cb26-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-102"><a href="#cb26-102" aria-hidden="true" tabindex="-1"></a>For multiclass classification in a neural network, a common choice for the loss function is the **Categorical Cross Entropy Loss**, the equation is as follows:</span>
<span id="cb26-103"><a href="#cb26-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-104"><a href="#cb26-104" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-105"><a href="#cb26-105" aria-hidden="true" tabindex="-1"></a>-\sum_{i=1}^N\sum_{c=1}^Cw_c\log\frac{exp(x_{n,c})}{\sum_{i=1}^Cexp(x_{n,i})}y_{n,c}</span>
<span id="cb26-106"><a href="#cb26-106" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-107"><a href="#cb26-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-108"><a href="#cb26-108" aria-hidden="true" tabindex="-1"></a>where $x$ is the input, $y$ is the target, $w$ is the weight, $C$ is the number of classes, and $N$ denotes the number of training samples in the minibatch.</span>
<span id="cb26-109"><a href="#cb26-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-110"><a href="#cb26-110" aria-hidden="true" tabindex="-1"></a>This equation reflects the negative log-likelihood of the correct class in a classification task, penalizing the model more when it is confidently wrong about a particular class. The softmax operation in the denominator ensures that the values in the exponential term form a valid probability distribution over all classes. The logarithm in the loss function penalizes deviations from the true class probabilities.</span>
<span id="cb26-111"><a href="#cb26-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-112"><a href="#cb26-112" aria-hidden="true" tabindex="-1"></a><span class="fu">### Evaluation Metrics</span></span>
<span id="cb26-113"><a href="#cb26-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-114"><a href="#cb26-114" aria-hidden="true" tabindex="-1"></a>For classification problems, the precision, recall and $F_1$ are most common used indicators for model performance evaluation.</span>
<span id="cb26-115"><a href="#cb26-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-116"><a href="#cb26-116" aria-hidden="true" tabindex="-1"></a>According to wikipedia, the definition of these metrics as following<span class="ot">[^3]</span> <span class="ot">[^4]</span>:</span>
<span id="cb26-117"><a href="#cb26-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-118"><a href="#cb26-118" aria-hidden="true" tabindex="-1"></a><span class="ot">[^3]: &lt;https://en.wikipedia.org/wiki/Precision_and_recall&gt;</span></span>
<span id="cb26-119"><a href="#cb26-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-120"><a href="#cb26-120" aria-hidden="true" tabindex="-1"></a><span class="ot">[^4]: &lt;https://en.wikipedia.org/wiki/F-score&gt;</span></span>
<span id="cb26-121"><a href="#cb26-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-122"><a href="#cb26-122" aria-hidden="true" tabindex="-1"></a>**Precision** is the fraction of relevant instances among the retrieved instances. Written as a formula:</span>
<span id="cb26-123"><a href="#cb26-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-124"><a href="#cb26-124" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-125"><a href="#cb26-125" aria-hidden="true" tabindex="-1"></a>{\displaystyle {\text{Precision}}={\frac {\text{Relevant retrieved instances}}{\text{All retrieved instances}}}}</span>
<span id="cb26-126"><a href="#cb26-126" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-127"><a href="#cb26-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-128"><a href="#cb26-128" aria-hidden="true" tabindex="-1"></a>**Recall** is the fraction of relevant instances that were retrieved. Written as a formula:</span>
<span id="cb26-129"><a href="#cb26-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-130"><a href="#cb26-130" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-131"><a href="#cb26-131" aria-hidden="true" tabindex="-1"></a>{\displaystyle {\text{Recall}}={\frac {\text{Relevant retrieved instances}}{\text{All relevant instances}}}}</span>
<span id="cb26-132"><a href="#cb26-132" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-133"><a href="#cb26-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-134"><a href="#cb26-134" aria-hidden="true" tabindex="-1"></a>$F_1$ score is the harmonic mean of the precision and recall. Written as a formula:</span>
<span id="cb26-135"><a href="#cb26-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-136"><a href="#cb26-136" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-137"><a href="#cb26-137" aria-hidden="true" tabindex="-1"></a>{\displaystyle F_{1}={\frac {2}{\mathrm {recall} ^{-1}+\mathrm {precision} ^{-1}}}=2{\frac {\mathrm {precision} \cdot \mathrm {recall} }{\mathrm {precision} +\mathrm {recall} }}={\frac {2\mathrm {tp} }{2\mathrm {tp} +\mathrm {fp} +\mathrm {fn} }}}</span>
<span id="cb26-138"><a href="#cb26-138" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-139"><a href="#cb26-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-140"><a href="#cb26-140" aria-hidden="true" tabindex="-1"></a>where $tp$ is the true positives, $fp$ is the false positive, and $fn$ is the false negative.</span>
<span id="cb26-141"><a href="#cb26-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-142"><a href="#cb26-142" aria-hidden="true" tabindex="-1"></a><span class="fu">## Datasets</span></span>
<span id="cb26-143"><a href="#cb26-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-144"><a href="#cb26-144" aria-hidden="true" tabindex="-1"></a><span class="fu">### Description</span></span>
<span id="cb26-145"><a href="#cb26-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-146"><a href="#cb26-146" aria-hidden="true" tabindex="-1"></a>In this post, we will use a dog disease dataset<span class="ot">[^5]</span> containing 24000 entities with 17 symptoms and 12 diseases to conduct experiments. The dataset is in csv format, the symptoms and diseases are presented in text format, thus, we need to further convert the textual information into numerical representations. However, due to the length of this post, we're not able to cover the feature engineering processing here, instead, we will focus on the data analysis and modeling process, which would be introduced in the next section.</span>
<span id="cb26-147"><a href="#cb26-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-148"><a href="#cb26-148" aria-hidden="true" tabindex="-1"></a><span class="ot">[^5]: </span><span class="co">[</span><span class="ot">https://github.com/1zuu/Doggy-Disease-Detection/</span><span class="co">](https://github.com/1zuu/Doggy-Disease-Detection/data)</span>{.uri}</span>
<span id="cb26-149"><a href="#cb26-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-150"><a href="#cb26-150" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Analysis</span></span>
<span id="cb26-151"><a href="#cb26-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-152"><a href="#cb26-152" aria-hidden="true" tabindex="-1"></a>We first load all the python libraries we might use in the analysis:</span>
<span id="cb26-153"><a href="#cb26-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-156"><a href="#cb26-156" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-157"><a href="#cb26-157" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb26-158"><a href="#cb26-158" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-159"><a href="#cb26-159" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-160"><a href="#cb26-160" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb26-161"><a href="#cb26-161" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb26-162"><a href="#cb26-162" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score, accuracy_score, recall_score, precision_score</span>
<span id="cb26-163"><a href="#cb26-163" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report</span>
<span id="cb26-164"><a href="#cb26-164" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb26-165"><a href="#cb26-165" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-166"><a href="#cb26-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-167"><a href="#cb26-167" aria-hidden="true" tabindex="-1"></a>Now, load the prepossessed (convert the textual data into numerical representation) csv file into pandas <span class="in">`DataFrame`</span>:</span>
<span id="cb26-168"><a href="#cb26-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-171"><a href="#cb26-171" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-172"><a href="#cb26-172" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/pre_processed.csv'</span>)</span>
<span id="cb26-173"><a href="#cb26-173" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-174"><a href="#cb26-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-175"><a href="#cb26-175" aria-hidden="true" tabindex="-1"></a>Let's take a look at the first 5 rows:</span>
<span id="cb26-176"><a href="#cb26-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-179"><a href="#cb26-179" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-180"><a href="#cb26-180" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-column: page</span></span>
<span id="cb26-181"><a href="#cb26-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-182"><a href="#cb26-182" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb26-183"><a href="#cb26-183" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-184"><a href="#cb26-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-185"><a href="#cb26-185" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br/&gt;</span></span>
<span id="cb26-186"><a href="#cb26-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-187"><a href="#cb26-187" aria-hidden="true" tabindex="-1"></a>As we can see in the table above, there are 98 features, and all the features are categorical which represents whether the dog has a certain symptom. The column <span class="in">`Disease`</span> is the type of disease we want to predict.</span>
<span id="cb26-188"><a href="#cb26-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-189"><a href="#cb26-189" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Descriptive Statistics</span></span>
<span id="cb26-190"><a href="#cb26-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-191"><a href="#cb26-191" aria-hidden="true" tabindex="-1"></a>We now take a look at the descriptive statistics of the dataset:</span>
<span id="cb26-192"><a href="#cb26-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-195"><a href="#cb26-195" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-196"><a href="#cb26-196" aria-hidden="true" tabindex="-1"></a>df.describe()</span>
<span id="cb26-197"><a href="#cb26-197" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-198"><a href="#cb26-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-199"><a href="#cb26-199" aria-hidden="true" tabindex="-1"></a>From the table above, we can infer that the features are very sparse with most of them are zeros, this requires the model have the ability to effectively extract information from high sparse data.</span>
<span id="cb26-200"><a href="#cb26-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-201"><a href="#cb26-201" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Visualization</span></span>
<span id="cb26-202"><a href="#cb26-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-203"><a href="#cb26-203" aria-hidden="true" tabindex="-1"></a>We wanted to examine the dependent variable first, this could be done by count how many records for each disease. We plot the histogram as follows:</span>
<span id="cb26-204"><a href="#cb26-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-207"><a href="#cb26-207" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-208"><a href="#cb26-208" aria-hidden="true" tabindex="-1"></a>sns.histplot(df[<span class="st">'Disease'</span>])</span>
<span id="cb26-209"><a href="#cb26-209" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">75</span>)</span>
<span id="cb26-210"><a href="#cb26-210" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-211"><a href="#cb26-211" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-212"><a href="#cb26-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-213"><a href="#cb26-213" aria-hidden="true" tabindex="-1"></a>From the figure above, we can see that there are 12 diseases and there are equally distributed.</span>
<span id="cb26-214"><a href="#cb26-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-215"><a href="#cb26-215" aria-hidden="true" tabindex="-1"></a>It would be interesting to show the distribution of the symptoms, we thus plots a word cloud of the symptom names as following:</span>
<span id="cb26-216"><a href="#cb26-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-219"><a href="#cb26-219" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-220"><a href="#cb26-220" aria-hidden="true" tabindex="-1"></a>count_series <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">"Unnamed: 0"</span>, <span class="st">"Disease"</span>]).<span class="bu">sum</span>(axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb26-221"><a href="#cb26-221" aria-hidden="true" tabindex="-1"></a>count_df <span class="op">=</span> count_series.to_frame().reset_index().rename(columns <span class="op">=</span> {<span class="st">"index"</span>:<span class="st">"symptom"</span>, <span class="dv">0</span>:<span class="st">"frequency"</span>})</span>
<span id="cb26-222"><a href="#cb26-222" aria-hidden="true" tabindex="-1"></a>freq_list <span class="op">=</span> {}</span>
<span id="cb26-223"><a href="#cb26-223" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(count_df)):</span>
<span id="cb26-224"><a href="#cb26-224" aria-hidden="true" tabindex="-1"></a>    freq_list[count_df[<span class="st">'symptom'</span>].iloc[index]] <span class="op">=</span> count_df[<span class="st">'frequency'</span>].iloc[index]</span>
<span id="cb26-225"><a href="#cb26-225" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-226"><a href="#cb26-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-229"><a href="#cb26-229" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-230"><a href="#cb26-230" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-column: page</span></span>
<span id="cb26-231"><a href="#cb26-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-232"><a href="#cb26-232" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud</span>
<span id="cb26-233"><a href="#cb26-233" aria-hidden="true" tabindex="-1"></a>wc <span class="op">=</span> WordCloud(width<span class="op">=</span><span class="dv">3840</span>, height<span class="op">=</span><span class="dv">2160</span>).generate_from_frequencies(freq_list)</span>
<span id="cb26-234"><a href="#cb26-234" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">10</span>))</span>
<span id="cb26-235"><a href="#cb26-235" aria-hidden="true" tabindex="-1"></a>plt.imshow(wc, interpolation<span class="op">=</span><span class="st">"bilinear"</span>)</span>
<span id="cb26-236"><a href="#cb26-236" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb26-237"><a href="#cb26-237" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-238"><a href="#cb26-238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-239"><a href="#cb26-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-240"><a href="#cb26-240" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Preprocessing</span></span>
<span id="cb26-241"><a href="#cb26-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-242"><a href="#cb26-242" aria-hidden="true" tabindex="-1"></a>We then, further convert the pandas dataframe to the format fits the model training requirements. It mainly includes: separate the features and labels into different numpy array; split the data into train, validation and test set.</span>
<span id="cb26-243"><a href="#cb26-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-246"><a href="#cb26-246" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-247"><a href="#cb26-247" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop([<span class="st">'Unnamed: 0'</span>, <span class="st">'Disease'</span>,<span class="st">'Tick fever'</span>,<span class="st">'Distemper'</span>, <span class="st">'Parvovirus'</span>,</span>
<span id="cb26-248"><a href="#cb26-248" aria-hidden="true" tabindex="-1"></a>               <span class="st">'Hepatitis'</span>, <span class="st">'Tetanus'</span>, <span class="st">'Chronic kidney Disease'</span>, <span class="st">'Diabetes'</span>,</span>
<span id="cb26-249"><a href="#cb26-249" aria-hidden="true" tabindex="-1"></a>               <span class="st">'Gastrointestinal Disease'</span>, <span class="st">'Allergies'</span>, <span class="st">'Gingitivis'</span>, <span class="st">'Cancers'</span>,</span>
<span id="cb26-250"><a href="#cb26-250" aria-hidden="true" tabindex="-1"></a>               <span class="st">'Skin Rashes'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-251"><a href="#cb26-251" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[[<span class="st">'Tick fever'</span>, <span class="st">'Distemper'</span>, <span class="st">'Parvovirus'</span>,</span>
<span id="cb26-252"><a href="#cb26-252" aria-hidden="true" tabindex="-1"></a>          <span class="st">'Hepatitis'</span>, <span class="st">'Tetanus'</span>, <span class="st">'Chronic kidney Disease'</span>, <span class="st">'Diabetes'</span>,</span>
<span id="cb26-253"><a href="#cb26-253" aria-hidden="true" tabindex="-1"></a>          <span class="st">'Gastrointestinal Disease'</span>, <span class="st">'Allergies'</span>, <span class="st">'Gingitivis'</span>, <span class="st">'Cancers'</span>,</span>
<span id="cb26-254"><a href="#cb26-254" aria-hidden="true" tabindex="-1"></a>          <span class="st">'Skin Rashes'</span>]]</span>
<span id="cb26-255"><a href="#cb26-255" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-256"><a href="#cb26-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-259"><a href="#cb26-259" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-260"><a href="#cb26-260" aria-hidden="true" tabindex="-1"></a>X_train_val, X_test, y_train_val, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">66</span>)</span>
<span id="cb26-261"><a href="#cb26-261" aria-hidden="true" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(X_train_val, y_train_val, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">66</span>)</span>
<span id="cb26-262"><a href="#cb26-262" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-263"><a href="#cb26-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-266"><a href="#cb26-266" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-267"><a href="#cb26-267" aria-hidden="true" tabindex="-1"></a><span class="co"># Show how many data in each set</span></span>
<span id="cb26-268"><a href="#cb26-268" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Length of train set:"</span>, <span class="bu">len</span>(X_train))</span>
<span id="cb26-269"><a href="#cb26-269" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Length of validation set:"</span>, <span class="bu">len</span>(X_val))</span>
<span id="cb26-270"><a href="#cb26-270" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Length of test set:"</span>, <span class="bu">len</span>(X_test))</span>
<span id="cb26-271"><a href="#cb26-271" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-272"><a href="#cb26-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-273"><a href="#cb26-273" aria-hidden="true" tabindex="-1"></a><span class="fu">## Experiments</span></span>
<span id="cb26-274"><a href="#cb26-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-275"><a href="#cb26-275" aria-hidden="true" tabindex="-1"></a>We will use the pytorch framework to build and train a neural network, thus, we need to use the pytorch ecosystem to format the dataset, build the network architecture, load and feed dataset model, etc. We will introduce all these steps in this section.</span>
<span id="cb26-276"><a href="#cb26-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-279"><a href="#cb26-279" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-280"><a href="#cb26-280" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb26-281"><a href="#cb26-281" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb26-282"><a href="#cb26-282" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb26-283"><a href="#cb26-283" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb26-284"><a href="#cb26-284" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-285"><a href="#cb26-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-286"><a href="#cb26-286" aria-hidden="true" tabindex="-1"></a><span class="fu">### Network Implementation</span></span>
<span id="cb26-287"><a href="#cb26-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-288"><a href="#cb26-288" aria-hidden="true" tabindex="-1"></a>Wrap the dataset into pytorch <span class="in">`Dataset`</span> format:</span>
<span id="cb26-289"><a href="#cb26-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-292"><a href="#cb26-292" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-293"><a href="#cb26-293" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DogSymptomsDataset(Dataset):</span>
<span id="cb26-294"><a href="#cb26-294" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, Y):</span>
<span id="cb26-295"><a href="#cb26-295" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.X <span class="op">=</span> torch.tensor(X.values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb26-296"><a href="#cb26-296" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.Y <span class="op">=</span> torch.tensor(Y.values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb26-297"><a href="#cb26-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-298"><a href="#cb26-298" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb26-299"><a href="#cb26-299" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.X)</span>
<span id="cb26-300"><a href="#cb26-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-301"><a href="#cb26-301" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span>
<span id="cb26-302"><a href="#cb26-302" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="va">self</span>.X[index], <span class="va">self</span>.Y[index])</span>
<span id="cb26-303"><a href="#cb26-303" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-304"><a href="#cb26-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-305"><a href="#cb26-305" aria-hidden="true" tabindex="-1"></a>Initialize the <span class="in">`DogSymptomsDataset`</span> and <span class="in">`DataLoader`</span> for the train, validation and test data.</span>
<span id="cb26-306"><a href="#cb26-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-309"><a href="#cb26-309" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-310"><a href="#cb26-310" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> DogSymptomsDataset(X_train, y_train)</span>
<span id="cb26-311"><a href="#cb26-311" aria-hidden="true" tabindex="-1"></a>val_ds <span class="op">=</span> DogSymptomsDataset(X_val, y_val)</span>
<span id="cb26-312"><a href="#cb26-312" aria-hidden="true" tabindex="-1"></a>test_ds <span class="op">=</span> DogSymptomsDataset(X_test, y_test)</span>
<span id="cb26-313"><a href="#cb26-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-314"><a href="#cb26-314" aria-hidden="true" tabindex="-1"></a>trainloader <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb26-315"><a href="#cb26-315" aria-hidden="true" tabindex="-1"></a>valloader <span class="op">=</span> DataLoader(val_ds, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb26-316"><a href="#cb26-316" aria-hidden="true" tabindex="-1"></a>testloader <span class="op">=</span> DataLoader(test_ds, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb26-317"><a href="#cb26-317" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-318"><a href="#cb26-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-319"><a href="#cb26-319" aria-hidden="true" tabindex="-1"></a>The network structure mainly consist of several feedforward and dropoutas layer, we use <span class="in">`ReLU`</span> as the activation function and implement the forward function for passing the data through network. The pytorch framework will take care of error back-propagation.</span>
<span id="cb26-320"><a href="#cb26-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-323"><a href="#cb26-323" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-324"><a href="#cb26-324" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP(nn.Module):</span>
<span id="cb26-325"><a href="#cb26-325" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb26-326"><a href="#cb26-326" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>(MLP, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb26-327"><a href="#cb26-327" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb26-328"><a href="#cb26-328" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">86</span>, <span class="dv">256</span>),</span>
<span id="cb26-329"><a href="#cb26-329" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb26-330"><a href="#cb26-330" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(),</span>
<span id="cb26-331"><a href="#cb26-331" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">256</span>, <span class="dv">128</span>),</span>
<span id="cb26-332"><a href="#cb26-332" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb26-333"><a href="#cb26-333" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(),</span>
<span id="cb26-334"><a href="#cb26-334" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">128</span>, <span class="dv">64</span>),</span>
<span id="cb26-335"><a href="#cb26-335" aria-hidden="true" tabindex="-1"></a>        nn.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb26-336"><a href="#cb26-336" aria-hidden="true" tabindex="-1"></a>        nn.ReLU(),</span>
<span id="cb26-337"><a href="#cb26-337" aria-hidden="true" tabindex="-1"></a>        nn.Linear(<span class="dv">64</span>, <span class="dv">12</span>),</span>
<span id="cb26-338"><a href="#cb26-338" aria-hidden="true" tabindex="-1"></a>        <span class="co"># nn.Softmax()</span></span>
<span id="cb26-339"><a href="#cb26-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-340"><a href="#cb26-340" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-341"><a href="#cb26-341" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb26-342"><a href="#cb26-342" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span>.layers(x)</span>
<span id="cb26-343"><a href="#cb26-343" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-344"><a href="#cb26-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-345"><a href="#cb26-345" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training</span></span>
<span id="cb26-346"><a href="#cb26-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-347"><a href="#cb26-347" aria-hidden="true" tabindex="-1"></a>The last missing puzzle now is implement the train and validation function which manages the whole training and validation process.</span>
<span id="cb26-348"><a href="#cb26-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-351"><a href="#cb26-351" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-352"><a href="#cb26-352" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f1(pred_list, label_list):</span>
<span id="cb26-353"><a href="#cb26-353" aria-hidden="true" tabindex="-1"></a>  pred_all <span class="op">=</span> torch.cat(pred_list)</span>
<span id="cb26-354"><a href="#cb26-354" aria-hidden="true" tabindex="-1"></a>  label_all <span class="op">=</span> torch.cat(label_list)</span>
<span id="cb26-355"><a href="#cb26-355" aria-hidden="true" tabindex="-1"></a>  y_pred_classes <span class="op">=</span> np.argmax(pred_all.detach().numpy(), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-356"><a href="#cb26-356" aria-hidden="true" tabindex="-1"></a>  y_true_classes <span class="op">=</span> np.argmax(label_all.detach().numpy(), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-357"><a href="#cb26-357" aria-hidden="true" tabindex="-1"></a>  _f1 <span class="op">=</span> f1_score(y_true_classes, y_pred_classes, average<span class="op">=</span><span class="st">'weighted'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb26-358"><a href="#cb26-358" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> _f1</span>
<span id="cb26-359"><a href="#cb26-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-360"><a href="#cb26-360" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> validation(model):</span>
<span id="cb26-361"><a href="#cb26-361" aria-hidden="true" tabindex="-1"></a>  pred_list <span class="op">=</span> []</span>
<span id="cb26-362"><a href="#cb26-362" aria-hidden="true" tabindex="-1"></a>  label_list <span class="op">=</span> []</span>
<span id="cb26-363"><a href="#cb26-363" aria-hidden="true" tabindex="-1"></a>  loss_list <span class="op">=</span> []</span>
<span id="cb26-364"><a href="#cb26-364" aria-hidden="true" tabindex="-1"></a>  loss_function <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb26-365"><a href="#cb26-365" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(valloader):</span>
<span id="cb26-366"><a href="#cb26-366" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Get inputs</span></span>
<span id="cb26-367"><a href="#cb26-367" aria-hidden="true" tabindex="-1"></a>      inputs, targets <span class="op">=</span> data</span>
<span id="cb26-368"><a href="#cb26-368" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Perform forward pass</span></span>
<span id="cb26-369"><a href="#cb26-369" aria-hidden="true" tabindex="-1"></a>      outputs <span class="op">=</span> model(inputs)</span>
<span id="cb26-370"><a href="#cb26-370" aria-hidden="true" tabindex="-1"></a>      loss <span class="op">=</span> loss_function(outputs, targets)</span>
<span id="cb26-371"><a href="#cb26-371" aria-hidden="true" tabindex="-1"></a>      loss_list.append(loss.item())</span>
<span id="cb26-372"><a href="#cb26-372" aria-hidden="true" tabindex="-1"></a>      pred_list.append(outputs)</span>
<span id="cb26-373"><a href="#cb26-373" aria-hidden="true" tabindex="-1"></a>      label_list.append(targets)</span>
<span id="cb26-374"><a href="#cb26-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-375"><a href="#cb26-375" aria-hidden="true" tabindex="-1"></a>  avg_loss <span class="op">=</span> <span class="bu">sum</span>(loss_list)<span class="op">/</span><span class="bu">len</span>(valloader)</span>
<span id="cb26-376"><a href="#cb26-376" aria-hidden="true" tabindex="-1"></a>  avg_f1 <span class="op">=</span> f1(pred_list, label_list)</span>
<span id="cb26-377"><a href="#cb26-377" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (avg_loss, avg_f1)</span>
<span id="cb26-378"><a href="#cb26-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-379"><a href="#cb26-379" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-380"><a href="#cb26-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-383"><a href="#cb26-383" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-384"><a href="#cb26-384" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train():</span>
<span id="cb26-385"><a href="#cb26-385" aria-hidden="true" tabindex="-1"></a>  mlp <span class="op">=</span> MLP()</span>
<span id="cb26-386"><a href="#cb26-386" aria-hidden="true" tabindex="-1"></a>  torch.manual_seed(<span class="dv">666</span>)</span>
<span id="cb26-387"><a href="#cb26-387" aria-hidden="true" tabindex="-1"></a>  trainloader <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span><span class="dv">32</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb26-388"><a href="#cb26-388" aria-hidden="true" tabindex="-1"></a>  loss_function <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb26-389"><a href="#cb26-389" aria-hidden="true" tabindex="-1"></a>  optimizer <span class="op">=</span> torch.optim.Adam(mlp.parameters(), lr<span class="op">=</span><span class="fl">2e-4</span>)</span>
<span id="cb26-390"><a href="#cb26-390" aria-hidden="true" tabindex="-1"></a>  train_loss_list <span class="op">=</span> []</span>
<span id="cb26-391"><a href="#cb26-391" aria-hidden="true" tabindex="-1"></a>  val_loss_list <span class="op">=</span> []</span>
<span id="cb26-392"><a href="#cb26-392" aria-hidden="true" tabindex="-1"></a>  train_f1_list<span class="op">=</span>[]</span>
<span id="cb26-393"><a href="#cb26-393" aria-hidden="true" tabindex="-1"></a>  val_f1_list<span class="op">=</span>[]</span>
<span id="cb26-394"><a href="#cb26-394" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb26-395"><a href="#cb26-395" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print epoch</span></span>
<span id="cb26-396"><a href="#cb26-396" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Starting epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb26-397"><a href="#cb26-397" aria-hidden="true" tabindex="-1"></a>    loss_epoch_list <span class="op">=</span> []</span>
<span id="cb26-398"><a href="#cb26-398" aria-hidden="true" tabindex="-1"></a>    pred_list <span class="op">=</span> []</span>
<span id="cb26-399"><a href="#cb26-399" aria-hidden="true" tabindex="-1"></a>    label_list <span class="op">=</span> []</span>
<span id="cb26-400"><a href="#cb26-400" aria-hidden="true" tabindex="-1"></a>    current_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb26-401"><a href="#cb26-401" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate over the DataLoader for training data</span></span>
<span id="cb26-402"><a href="#cb26-402" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(trainloader):</span>
<span id="cb26-403"><a href="#cb26-403" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Get inputs</span></span>
<span id="cb26-404"><a href="#cb26-404" aria-hidden="true" tabindex="-1"></a>      inputs, targets <span class="op">=</span> data</span>
<span id="cb26-405"><a href="#cb26-405" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Zero the gradients</span></span>
<span id="cb26-406"><a href="#cb26-406" aria-hidden="true" tabindex="-1"></a>      optimizer.zero_grad()</span>
<span id="cb26-407"><a href="#cb26-407" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Perform forward pass</span></span>
<span id="cb26-408"><a href="#cb26-408" aria-hidden="true" tabindex="-1"></a>      outputs <span class="op">=</span> mlp(inputs)</span>
<span id="cb26-409"><a href="#cb26-409" aria-hidden="true" tabindex="-1"></a>      pred_list.append(outputs)</span>
<span id="cb26-410"><a href="#cb26-410" aria-hidden="true" tabindex="-1"></a>      label_list.append(targets)</span>
<span id="cb26-411"><a href="#cb26-411" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Compute loss</span></span>
<span id="cb26-412"><a href="#cb26-412" aria-hidden="true" tabindex="-1"></a>      loss <span class="op">=</span> loss_function(outputs, targets)</span>
<span id="cb26-413"><a href="#cb26-413" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Perform backward pass</span></span>
<span id="cb26-414"><a href="#cb26-414" aria-hidden="true" tabindex="-1"></a>      loss.backward()</span>
<span id="cb26-415"><a href="#cb26-415" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Perform optimizationd</span></span>
<span id="cb26-416"><a href="#cb26-416" aria-hidden="true" tabindex="-1"></a>      optimizer.step()</span>
<span id="cb26-417"><a href="#cb26-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-418"><a href="#cb26-418" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Print statistics</span></span>
<span id="cb26-419"><a href="#cb26-419" aria-hidden="true" tabindex="-1"></a>      loss_item <span class="op">=</span> loss.item()</span>
<span id="cb26-420"><a href="#cb26-420" aria-hidden="true" tabindex="-1"></a>      loss_epoch_list.append(loss_item)</span>
<span id="cb26-421"><a href="#cb26-421" aria-hidden="true" tabindex="-1"></a>      current_loss <span class="op">+=</span> loss_item</span>
<span id="cb26-422"><a href="#cb26-422" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (i <span class="op">!=</span><span class="dv">0</span>) <span class="kw">and</span> (i <span class="op">%</span> <span class="dv">50</span> <span class="op">==</span> <span class="dv">0</span>):</span>
<span id="cb26-423"><a href="#cb26-423" aria-hidden="true" tabindex="-1"></a>          train_loss_list.append(current_loss<span class="op">/</span><span class="dv">50</span>)</span>
<span id="cb26-424"><a href="#cb26-424" aria-hidden="true" tabindex="-1"></a>          train_f1 <span class="op">=</span> f1([outputs], [targets])</span>
<span id="cb26-425"><a href="#cb26-425" aria-hidden="true" tabindex="-1"></a>          train_f1_list.append(train_f1)</span>
<span id="cb26-426"><a href="#cb26-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-427"><a href="#cb26-427" aria-hidden="true" tabindex="-1"></a>          val_loss, val_f1 <span class="op">=</span> validation(mlp)</span>
<span id="cb26-428"><a href="#cb26-428" aria-hidden="true" tabindex="-1"></a>          val_loss_list.append(val_loss)</span>
<span id="cb26-429"><a href="#cb26-429" aria-hidden="true" tabindex="-1"></a>          val_f1_list.append(val_f1)</span>
<span id="cb26-430"><a href="#cb26-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-431"><a href="#cb26-431" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="st">'Loss after mini-batch </span><span class="sc">%5d</span><span class="st">: </span><span class="sc">%.3f</span><span class="st">'</span> <span class="op">%</span></span>
<span id="cb26-432"><a href="#cb26-432" aria-hidden="true" tabindex="-1"></a>                (i, current_loss<span class="op">/</span><span class="dv">50</span>))</span>
<span id="cb26-433"><a href="#cb26-433" aria-hidden="true" tabindex="-1"></a>          current_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb26-434"><a href="#cb26-434" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">'Training process has finished.'</span>)</span>
<span id="cb26-435"><a href="#cb26-435" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (mlp, train_loss_list,val_loss_list,train_f1_list,val_f1_list)</span>
<span id="cb26-436"><a href="#cb26-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-437"><a href="#cb26-437" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-438"><a href="#cb26-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-439"><a href="#cb26-439" aria-hidden="true" tabindex="-1"></a>We now start the training process:</span>
<span id="cb26-440"><a href="#cb26-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-443"><a href="#cb26-443" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-444"><a href="#cb26-444" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb26-445"><a href="#cb26-445" aria-hidden="true" tabindex="-1"></a>model, train_loss_list,val_loss_list,train_f1_list,val_f1_list <span class="op">=</span> train()</span>
<span id="cb26-446"><a href="#cb26-446" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-447"><a href="#cb26-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-448"><a href="#cb26-448" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Performance Evaluation**</span></span>
<span id="cb26-449"><a href="#cb26-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-450"><a href="#cb26-450" aria-hidden="true" tabindex="-1"></a>We are now have already completed the model training, it is time to use the model to make predict on our test set, then, calculate the precision, recall and $F_1$ score base on the predicted disease and the ground truth label.</span>
<span id="cb26-451"><a href="#cb26-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-454"><a href="#cb26-454" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-455"><a href="#cb26-455" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test(model):</span>
<span id="cb26-456"><a href="#cb26-456" aria-hidden="true" tabindex="-1"></a>  pred_list <span class="op">=</span> []</span>
<span id="cb26-457"><a href="#cb26-457" aria-hidden="true" tabindex="-1"></a>  label_list <span class="op">=</span> []</span>
<span id="cb26-458"><a href="#cb26-458" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(testloader):</span>
<span id="cb26-459"><a href="#cb26-459" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Get inputs</span></span>
<span id="cb26-460"><a href="#cb26-460" aria-hidden="true" tabindex="-1"></a>      inputs, targets <span class="op">=</span> data</span>
<span id="cb26-461"><a href="#cb26-461" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Perform forward pass</span></span>
<span id="cb26-462"><a href="#cb26-462" aria-hidden="true" tabindex="-1"></a>      outputs <span class="op">=</span> model(inputs)</span>
<span id="cb26-463"><a href="#cb26-463" aria-hidden="true" tabindex="-1"></a>      pred_list.append(outputs)</span>
<span id="cb26-464"><a href="#cb26-464" aria-hidden="true" tabindex="-1"></a>      label_list.append(targets)</span>
<span id="cb26-465"><a href="#cb26-465" aria-hidden="true" tabindex="-1"></a>  pred_all <span class="op">=</span> torch.cat(pred_list)</span>
<span id="cb26-466"><a href="#cb26-466" aria-hidden="true" tabindex="-1"></a>  label_all <span class="op">=</span> torch.cat(label_list)</span>
<span id="cb26-467"><a href="#cb26-467" aria-hidden="true" tabindex="-1"></a>  y_pred_classes <span class="op">=</span> np.argmax(pred_all.detach().numpy(), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-468"><a href="#cb26-468" aria-hidden="true" tabindex="-1"></a>  y_true_classes <span class="op">=</span> np.argmax(label_all.detach().numpy(), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-469"><a href="#cb26-469" aria-hidden="true" tabindex="-1"></a>  avg_f1 <span class="op">=</span> f1(pred_list, label_list)</span>
<span id="cb26-470"><a href="#cb26-470" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (avg_f1, y_pred_classes, y_true_classes)</span>
<span id="cb26-471"><a href="#cb26-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-472"><a href="#cb26-472" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-473"><a href="#cb26-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-476"><a href="#cb26-476" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-477"><a href="#cb26-477" aria-hidden="true" tabindex="-1"></a>avg_f1, y_pred_classes, y_true_classes <span class="op">=</span> test(model)</span>
<span id="cb26-478"><a href="#cb26-478" aria-hidden="true" tabindex="-1"></a>report <span class="op">=</span> classification_report(y_true_classes, y_pred_classes,output_dict<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-479"><a href="#cb26-479" aria-hidden="true" tabindex="-1"></a>report_labeled<span class="op">=</span>{}</span>
<span id="cb26-480"><a href="#cb26-480" aria-hidden="true" tabindex="-1"></a>dnames <span class="op">=</span> df[<span class="st">'Disease'</span>].unique().tolist()</span>
<span id="cb26-481"><a href="#cb26-481" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(dnames)):</span>
<span id="cb26-482"><a href="#cb26-482" aria-hidden="true" tabindex="-1"></a>  report_labeled[dnames[i]] <span class="op">=</span> report[<span class="bu">str</span>(i)]</span>
<span id="cb26-483"><a href="#cb26-483" aria-hidden="true" tabindex="-1"></a>report_labeled[<span class="st">'macro avg'</span>] <span class="op">=</span> report[<span class="st">'macro avg'</span>]</span>
<span id="cb26-484"><a href="#cb26-484" aria-hidden="true" tabindex="-1"></a>report_labeled[<span class="st">'weighted avg'</span>] <span class="op">=</span> report[<span class="st">'weighted avg'</span>]</span>
<span id="cb26-485"><a href="#cb26-485" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(report_labeled).T</span>
<span id="cb26-486"><a href="#cb26-486" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-487"><a href="#cb26-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-488"><a href="#cb26-488" aria-hidden="true" tabindex="-1"></a>As we can see from the table above, our neural network predicts the 12 disease at very high precision, recall and $F_1$ scores.</span>
<span id="cb26-489"><a href="#cb26-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-490"><a href="#cb26-490" aria-hidden="true" tabindex="-1"></a>We can also plot the confusion matrix to have better understanding of the prediction performance:</span>
<span id="cb26-491"><a href="#cb26-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-494"><a href="#cb26-494" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-495"><a href="#cb26-495" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> metrics.confusion_matrix(y_true_classes, y_pred_classes)</span>
<span id="cb26-496"><a href="#cb26-496" aria-hidden="true" tabindex="-1"></a>df_cm <span class="op">=</span> pd.DataFrame(conf_matrix, index<span class="op">=</span>df[<span class="st">'Disease'</span>].unique(), columns<span class="op">=</span>df[<span class="st">'Disease'</span>].unique())</span>
<span id="cb26-497"><a href="#cb26-497" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'F1-score% ='</span>, f1_score(y_true_classes, y_pred_classes, average<span class="op">=</span><span class="st">'weighted'</span>)<span class="op">*</span><span class="dv">100</span>, <span class="st">'|'</span>,</span>
<span id="cb26-498"><a href="#cb26-498" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Accuracy% ='</span>, accuracy_score(y_true_classes, y_pred_classes)<span class="op">*</span><span class="dv">100</span>, <span class="st">'|'</span>,</span>
<span id="cb26-499"><a href="#cb26-499" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Recall% ='</span>, recall_score(y_true_classes, y_pred_classes, average<span class="op">=</span><span class="st">'weighted'</span>)<span class="op">*</span><span class="dv">100</span>, <span class="st">'|'</span>,</span>
<span id="cb26-500"><a href="#cb26-500" aria-hidden="true" tabindex="-1"></a>      <span class="st">'Precision% ='</span>, precision_score(y_true_classes, y_pred_classes, average<span class="op">=</span><span class="st">'weighted'</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb26-501"><a href="#cb26-501" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb26-502"><a href="#cb26-502" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>,<span class="dv">6</span>))</span>
<span id="cb26-503"><a href="#cb26-503" aria-hidden="true" tabindex="-1"></a>sns.heatmap(df_cm)</span>
<span id="cb26-504"><a href="#cb26-504" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-505"><a href="#cb26-505" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-506"><a href="#cb26-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-509"><a href="#cb26-509" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-510"><a href="#cb26-510" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb26-511"><a href="#cb26-511" aria-hidden="true" tabindex="-1"></a>ax.matshow(conf_matrix, cmap<span class="op">=</span>plt.cm.Blues, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb26-512"><a href="#cb26-512" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(conf_matrix.shape[<span class="dv">0</span>]):</span>
<span id="cb26-513"><a href="#cb26-513" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(conf_matrix.shape[<span class="dv">1</span>]):</span>
<span id="cb26-514"><a href="#cb26-514" aria-hidden="true" tabindex="-1"></a>        ax.text(x<span class="op">=</span>j, y<span class="op">=</span>i,s<span class="op">=</span>conf_matrix[i, j], va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'center'</span>, size<span class="op">=</span><span class="st">'xx-large'</span>)</span>
<span id="cb26-515"><a href="#cb26-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-516"><a href="#cb26-516" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predictions'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb26-517"><a href="#cb26-517" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Actuals'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb26-518"><a href="#cb26-518" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix of ANN Model'</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb26-519"><a href="#cb26-519" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-520"><a href="#cb26-520" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-521"><a href="#cb26-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-522"><a href="#cb26-522" aria-hidden="true" tabindex="-1"></a>Further, we can visualize the the <span class="in">`loss`</span> of the train and validation split during the whole training process, which is shown as follows:</span>
<span id="cb26-523"><a href="#cb26-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-526"><a href="#cb26-526" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-527"><a href="#cb26-527" aria-hidden="true" tabindex="-1"></a>train_loss <span class="op">=</span> train_loss_list</span>
<span id="cb26-528"><a href="#cb26-528" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> val_loss_list</span>
<span id="cb26-529"><a href="#cb26-529" aria-hidden="true" tabindex="-1"></a>train_acc <span class="op">=</span> train_f1_list</span>
<span id="cb26-530"><a href="#cb26-530" aria-hidden="true" tabindex="-1"></a>val_acc <span class="op">=</span> val_f1_list</span>
<span id="cb26-531"><a href="#cb26-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-532"><a href="#cb26-532" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw loss plot</span></span>
<span id="cb26-533"><a href="#cb26-533" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb26-534"><a href="#cb26-534" aria-hidden="true" tabindex="-1"></a>plt.plot(train_loss, label<span class="op">=</span><span class="st">'Training Loss'</span>)</span>
<span id="cb26-535"><a href="#cb26-535" aria-hidden="true" tabindex="-1"></a>plt.plot(val_loss, label<span class="op">=</span><span class="st">'Validation Loss'</span>)</span>
<span id="cb26-536"><a href="#cb26-536" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Batch'</span>)</span>
<span id="cb26-537"><a href="#cb26-537" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb26-538"><a href="#cb26-538" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb26-539"><a href="#cb26-539" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Loss'</span>)</span>
<span id="cb26-540"><a href="#cb26-540" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-541"><a href="#cb26-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-542"><a href="#cb26-542" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-543"><a href="#cb26-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-544"><a href="#cb26-544" aria-hidden="true" tabindex="-1"></a>The $F_1$ score of the train and test split during the whole training process is shown as follows:</span>
<span id="cb26-545"><a href="#cb26-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-548"><a href="#cb26-548" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-549"><a href="#cb26-549" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw accuracy plot</span></span>
<span id="cb26-550"><a href="#cb26-550" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb26-551"><a href="#cb26-551" aria-hidden="true" tabindex="-1"></a>plt.plot(train_acc, label<span class="op">=</span><span class="st">'Training Accuracy'</span>)</span>
<span id="cb26-552"><a href="#cb26-552" aria-hidden="true" tabindex="-1"></a>plt.plot(val_acc, label<span class="op">=</span><span class="st">'Validation Accuracy'</span>)</span>
<span id="cb26-553"><a href="#cb26-553" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Batch'</span>)</span>
<span id="cb26-554"><a href="#cb26-554" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb26-555"><a href="#cb26-555" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb26-556"><a href="#cb26-556" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Accuracy'</span>)</span>
<span id="cb26-557"><a href="#cb26-557" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-558"><a href="#cb26-558" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-559"><a href="#cb26-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-560"><a href="#cb26-560" aria-hidden="true" tabindex="-1"></a><span class="fu">## Discussion and Conclusions</span></span>
<span id="cb26-561"><a href="#cb26-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-562"><a href="#cb26-562" aria-hidden="true" tabindex="-1"></a>In this blog, we begin by introducing the basic concepts of classification and its importance in computer science and applications. Secondly, we introduce the background knowledge about classification such as supervised learning, the connection and difference between classification and regression, and the difference between binary and multiclass classification. After introducing the pet disease prediction use case, we provide a detailed description of the use of neural networks in multiclass classification, as well as the related evaluation indexes.</span>
<span id="cb26-563"><a href="#cb26-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-564"><a href="#cb26-564" aria-hidden="true" tabindex="-1"></a>After a detailed analysis of the data, we modeled the data using neural networks, and carried out an evaluation of the trained model. The experiment result shows our model achieved $F_1$ score of over 99% in all 12 pet disease predictions.</span>
<span id="cb26-565"><a href="#cb26-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-566"><a href="#cb26-566" aria-hidden="true" tabindex="-1"></a>While neural networks are powerful tools for many classification tasks, they are not without their shortcomings. Here are some common limitations and challenges associated with using neural networks for classification:</span>
<span id="cb26-567"><a href="#cb26-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-568"><a href="#cb26-568" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Data Requirements:**</span>
<span id="cb26-569"><a href="#cb26-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-570"><a href="#cb26-570" aria-hidden="true" tabindex="-1"></a>    Neural networks often require large amounts of labeled data for training to generalize well. In situations where labeled data is scarce, the model's performance may suffer.</span>
<span id="cb26-571"><a href="#cb26-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-572"><a href="#cb26-572" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Computational Complexity:**</span>
<span id="cb26-573"><a href="#cb26-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-574"><a href="#cb26-574" aria-hidden="true" tabindex="-1"></a>    Training deep neural networks can be computationally intensive, especially with large datasets and complex architectures. This can be a limitation for applications with resource constraints.</span>
<span id="cb26-575"><a href="#cb26-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-576"><a href="#cb26-576" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Interpretability:** Neural networks, particularly deep architectures, are often considered as "black-box" models, making it challenging to interpret and understand the decision-making process. Lack of interpretability can be a concern in fields where transparency and explainability are crucial.</span>
<span id="cb26-577"><a href="#cb26-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-578"><a href="#cb26-578" aria-hidden="true" tabindex="-1"></a>Despite these challenges, ongoing research and advancements in deep learning aim to address these limitations and enhance the performance, robustness, and interpretability of neural networks. Let's keep learning!</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">Copyright 2023, Tong Zeng</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>